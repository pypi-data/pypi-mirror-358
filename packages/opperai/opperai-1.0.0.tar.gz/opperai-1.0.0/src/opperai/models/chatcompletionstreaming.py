"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .chatcompletionassistantmessageparam import (
    ChatCompletionAssistantMessageParam,
    ChatCompletionAssistantMessageParamTypedDict,
)
from .chatcompletionaudioparam import (
    ChatCompletionAudioParam,
    ChatCompletionAudioParamTypedDict,
)
from .chatcompletiondevelopermessageparam import (
    ChatCompletionDeveloperMessageParam,
    ChatCompletionDeveloperMessageParamTypedDict,
)
from .chatcompletionfunctioncalloptionparam import (
    ChatCompletionFunctionCallOptionParam,
    ChatCompletionFunctionCallOptionParamTypedDict,
)
from .chatcompletionfunctionmessageparam import (
    ChatCompletionFunctionMessageParam,
    ChatCompletionFunctionMessageParamTypedDict,
)
from .chatcompletionnamedtoolchoiceparam import (
    ChatCompletionNamedToolChoiceParam,
    ChatCompletionNamedToolChoiceParamTypedDict,
)
from .chatcompletionpredictioncontentparam import (
    ChatCompletionPredictionContentParam,
    ChatCompletionPredictionContentParamTypedDict,
)
from .chatcompletionstreamoptionsparam import (
    ChatCompletionStreamOptionsParam,
    ChatCompletionStreamOptionsParamTypedDict,
)
from .chatcompletionsystemmessageparam import (
    ChatCompletionSystemMessageParam,
    ChatCompletionSystemMessageParamTypedDict,
)
from .chatcompletiontoolmessageparam import (
    ChatCompletionToolMessageParam,
    ChatCompletionToolMessageParamTypedDict,
)
from .chatcompletiontoolparam import (
    ChatCompletionToolParam,
    ChatCompletionToolParamTypedDict,
)
from .chatcompletionusermessageparam import (
    ChatCompletionUserMessageParam,
    ChatCompletionUserMessageParamTypedDict,
)
from .openai_types_chat_completion_create_params_function import (
    OpenaiTypesChatCompletionCreateParamsFunction,
    OpenaiTypesChatCompletionCreateParamsFunctionTypedDict,
)
from .responseformatjsonobject import (
    ResponseFormatJSONObject,
    ResponseFormatJSONObjectTypedDict,
)
from .responseformatjsonschema import (
    ResponseFormatJSONSchema,
    ResponseFormatJSONSchemaTypedDict,
)
from .responseformattext import ResponseFormatText, ResponseFormatTextTypedDict
from .tmodel import TModel, TModelTypedDict
from .websearchoptions import WebSearchOptions, WebSearchOptionsTypedDict
from enum import Enum
from opperai.types import BaseModel, Nullable, OptionalNullable, UNSET, UNSET_SENTINEL
from opperai.utils import validate_const
import pydantic
from pydantic import model_serializer
from pydantic.functional_validators import AfterValidator
from typing import Any, Dict, List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


ChatCompletionStreamingMessageTypedDict = TypeAliasType(
    "ChatCompletionStreamingMessageTypedDict",
    Union[
        ChatCompletionDeveloperMessageParamTypedDict,
        ChatCompletionSystemMessageParamTypedDict,
        ChatCompletionUserMessageParamTypedDict,
        ChatCompletionToolMessageParamTypedDict,
        ChatCompletionFunctionMessageParamTypedDict,
        ChatCompletionAssistantMessageParamTypedDict,
    ],
)


ChatCompletionStreamingMessage = TypeAliasType(
    "ChatCompletionStreamingMessage",
    Union[
        ChatCompletionDeveloperMessageParam,
        ChatCompletionSystemMessageParam,
        ChatCompletionUserMessageParam,
        ChatCompletionToolMessageParam,
        ChatCompletionFunctionMessageParam,
        ChatCompletionAssistantMessageParam,
    ],
)


class ChatCompletionStreamingFunctionCallEnum(str, Enum):
    NONE = "none"
    AUTO = "auto"


ChatCompletionStreamingFunctionCallUnionTypedDict = TypeAliasType(
    "ChatCompletionStreamingFunctionCallUnionTypedDict",
    Union[
        ChatCompletionFunctionCallOptionParamTypedDict,
        ChatCompletionStreamingFunctionCallEnum,
    ],
)


ChatCompletionStreamingFunctionCallUnion = TypeAliasType(
    "ChatCompletionStreamingFunctionCallUnion",
    Union[
        ChatCompletionFunctionCallOptionParam, ChatCompletionStreamingFunctionCallEnum
    ],
)


class ChatCompletionStreamingModality(str, Enum):
    TEXT = "text"
    AUDIO = "audio"


class ChatCompletionStreamingReasoningEffort(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


ChatCompletionStreamingResponseFormatTypedDict = TypeAliasType(
    "ChatCompletionStreamingResponseFormatTypedDict",
    Union[
        ResponseFormatTextTypedDict,
        ResponseFormatJSONObjectTypedDict,
        ResponseFormatJSONSchemaTypedDict,
    ],
)


ChatCompletionStreamingResponseFormat = TypeAliasType(
    "ChatCompletionStreamingResponseFormat",
    Union[ResponseFormatText, ResponseFormatJSONObject, ResponseFormatJSONSchema],
)


class ChatCompletionStreamingServiceTier(str, Enum):
    AUTO = "auto"
    DEFAULT = "default"
    FLEX = "flex"


ChatCompletionStreamingStopTypedDict = TypeAliasType(
    "ChatCompletionStreamingStopTypedDict", Union[str, List[str]]
)


ChatCompletionStreamingStop = TypeAliasType(
    "ChatCompletionStreamingStop", Union[str, List[str]]
)


class ChatCompletionStreamingToolChoiceEnum(str, Enum):
    NONE = "none"
    AUTO = "auto"
    REQUIRED = "required"


ChatCompletionStreamingToolChoiceUnionTypedDict = TypeAliasType(
    "ChatCompletionStreamingToolChoiceUnionTypedDict",
    Union[
        ChatCompletionNamedToolChoiceParamTypedDict,
        ChatCompletionStreamingToolChoiceEnum,
    ],
)


ChatCompletionStreamingToolChoiceUnion = TypeAliasType(
    "ChatCompletionStreamingToolChoiceUnion",
    Union[ChatCompletionNamedToolChoiceParam, ChatCompletionStreamingToolChoiceEnum],
)


class ChatCompletionStreamingTypedDict(TypedDict):
    messages: List[ChatCompletionStreamingMessageTypedDict]
    model: NotRequired[TModelTypedDict]
    audio: NotRequired[Nullable[ChatCompletionAudioParamTypedDict]]
    frequency_penalty: NotRequired[Nullable[float]]
    function_call: NotRequired[ChatCompletionStreamingFunctionCallUnionTypedDict]
    functions: NotRequired[List[OpenaiTypesChatCompletionCreateParamsFunctionTypedDict]]
    logit_bias: NotRequired[Nullable[Dict[str, int]]]
    logprobs: NotRequired[Nullable[bool]]
    max_completion_tokens: NotRequired[Nullable[int]]
    max_tokens: NotRequired[Nullable[int]]
    metadata: NotRequired[Nullable[Dict[str, str]]]
    modalities: NotRequired[Nullable[List[ChatCompletionStreamingModality]]]
    n: NotRequired[Nullable[int]]
    parallel_tool_calls: NotRequired[bool]
    prediction: NotRequired[Nullable[ChatCompletionPredictionContentParamTypedDict]]
    presence_penalty: NotRequired[Nullable[float]]
    reasoning_effort: NotRequired[Nullable[ChatCompletionStreamingReasoningEffort]]
    response_format: NotRequired[ChatCompletionStreamingResponseFormatTypedDict]
    seed: NotRequired[Nullable[int]]
    service_tier: NotRequired[Nullable[ChatCompletionStreamingServiceTier]]
    stop: NotRequired[Nullable[ChatCompletionStreamingStopTypedDict]]
    store: NotRequired[Nullable[bool]]
    stream_options: NotRequired[Nullable[ChatCompletionStreamOptionsParamTypedDict]]
    temperature: NotRequired[Nullable[float]]
    tool_choice: NotRequired[ChatCompletionStreamingToolChoiceUnionTypedDict]
    tools: NotRequired[List[ChatCompletionToolParamTypedDict]]
    top_logprobs: NotRequired[Nullable[int]]
    top_p: NotRequired[Nullable[float]]
    user: NotRequired[str]
    web_search_options: NotRequired[WebSearchOptionsTypedDict]
    stream: Literal[True]
    tags: NotRequired[Nullable[Dict[str, Any]]]
    parent_span_id: NotRequired[Nullable[str]]


class ChatCompletionStreaming(BaseModel):
    messages: List[ChatCompletionStreamingMessage]

    model: Optional[TModel] = None

    audio: OptionalNullable[ChatCompletionAudioParam] = UNSET

    frequency_penalty: OptionalNullable[float] = UNSET

    function_call: Optional[ChatCompletionStreamingFunctionCallUnion] = None

    functions: Optional[List[OpenaiTypesChatCompletionCreateParamsFunction]] = None

    logit_bias: OptionalNullable[Dict[str, int]] = UNSET

    logprobs: OptionalNullable[bool] = UNSET

    max_completion_tokens: OptionalNullable[int] = UNSET

    max_tokens: OptionalNullable[int] = UNSET

    metadata: OptionalNullable[Dict[str, str]] = UNSET

    modalities: OptionalNullable[List[ChatCompletionStreamingModality]] = UNSET

    n: OptionalNullable[int] = UNSET

    parallel_tool_calls: Optional[bool] = None

    prediction: OptionalNullable[ChatCompletionPredictionContentParam] = UNSET

    presence_penalty: OptionalNullable[float] = UNSET

    reasoning_effort: OptionalNullable[ChatCompletionStreamingReasoningEffort] = UNSET

    response_format: Optional[ChatCompletionStreamingResponseFormat] = None

    seed: OptionalNullable[int] = UNSET

    service_tier: OptionalNullable[ChatCompletionStreamingServiceTier] = UNSET

    stop: OptionalNullable[ChatCompletionStreamingStop] = UNSET

    store: OptionalNullable[bool] = UNSET

    stream_options: OptionalNullable[ChatCompletionStreamOptionsParam] = UNSET

    temperature: OptionalNullable[float] = UNSET

    tool_choice: Optional[ChatCompletionStreamingToolChoiceUnion] = None

    tools: Optional[List[ChatCompletionToolParam]] = None

    top_logprobs: OptionalNullable[int] = UNSET

    top_p: OptionalNullable[float] = UNSET

    user: Optional[str] = None

    web_search_options: Optional[WebSearchOptions] = None

    STREAM: Annotated[
        Annotated[Literal[True], AfterValidator(validate_const(True))],
        pydantic.Field(alias="stream"),
    ] = True

    tags: OptionalNullable[Dict[str, Any]] = UNSET

    parent_span_id: OptionalNullable[str] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "model",
            "audio",
            "frequency_penalty",
            "function_call",
            "functions",
            "logit_bias",
            "logprobs",
            "max_completion_tokens",
            "max_tokens",
            "metadata",
            "modalities",
            "n",
            "parallel_tool_calls",
            "prediction",
            "presence_penalty",
            "reasoning_effort",
            "response_format",
            "seed",
            "service_tier",
            "stop",
            "store",
            "stream_options",
            "temperature",
            "tool_choice",
            "tools",
            "top_logprobs",
            "top_p",
            "user",
            "web_search_options",
            "tags",
            "parent_span_id",
        ]
        nullable_fields = [
            "audio",
            "frequency_penalty",
            "logit_bias",
            "logprobs",
            "max_completion_tokens",
            "max_tokens",
            "metadata",
            "modalities",
            "n",
            "prediction",
            "presence_penalty",
            "reasoning_effort",
            "seed",
            "service_tier",
            "stop",
            "store",
            "stream_options",
            "temperature",
            "top_logprobs",
            "top_p",
            "tags",
            "parent_span_id",
        ]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m
