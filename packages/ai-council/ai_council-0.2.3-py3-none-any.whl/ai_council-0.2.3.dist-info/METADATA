Metadata-Version: 2.4
Name: ai-council
Version: 0.2.3
Summary: Multi-AI consensus tool: MCP server that queries multiple AI models (OpenAI, Claude, Gemini, custom APIs) in parallel, synthesizes responses for better accuracy, and reduces AI bias through ensemble decision-making
Project-URL: Homepage, https://github.com/0xAkuti/ai-council-mcp
Project-URL: Repository, https://github.com/0xAkuti/ai-council-mcp
Project-URL: Issues, https://github.com/0xAkuti/ai-council-mcp/issues
Author-email: Akuti <a40723201+0xAkuti@users.noreply.github.com>
License: MIT License
        
        Copyright (c) 2025 Akuti
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
License-File: LICENSE
Keywords: ai-aggregation,ai-api,ai-assistant,ai-automation,ai-benchmarking,ai-collaboration,ai-comparison,ai-consensus,ai-council,ai-evaluation,ai-middleware,ai-pipeline,ai-proxy,ai-research,ai-synthesis,ai-tools,ai-validation,anthropic,api-aggregation,async,bias-reduction,chatbot,claude,claude-desktop,cognition-wheel,concurrent,cursor-ai,decision-support,expert-system,gemini,gpt,llm-api,llm-evaluation,llm-orchestration,mcp,mcp-server,model-context-protocol,model-ensemble,model-fusion,multi-llm,multi-model,openai,openai-compatible,openrouter,parallel-ai,parallel-processing,perplexity,response-synthesis,together-ai,wisdom-of-crowds
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Python: >=3.10
Requires-Dist: httpx>=0.28.1
Requires-Dist: mcp>=1.9.4
Requires-Dist: openai>=1.91.0
Requires-Dist: pydantic-settings>=2.10.1
Requires-Dist: pydantic>=2.11.7
Requires-Dist: pyyaml>=6.0.2
Description-Content-Type: text/markdown

# AI Council MCP Server

> **Multi-AI Consensus Tool**: Query multiple AI models in parallel, synthesize responses for better accuracy, and reduce AI bias through ensemble decision-making.

AI Council is a powerful MCP (Model Context Protocol) server that harnesses the "wisdom of crowds" by consulting multiple AI models simultaneously. Get more reliable, comprehensive answers by combining insights from OpenAI, Claude, Gemini, and any OpenAI-compatible API.

## ‚ú® What is AI Council?

AI Council transforms how you interact with AI by:

- **üîÑ Parallel Processing**: Queries multiple AI models simultaneously (not sequentially)
- **üéØ Bias Reduction**: Uses anonymous code names to prevent synthesis bias
- **‚ö° Smart Synthesis**: One model synthesizes all responses into a comprehensive answer
- **üîß Universal Compatibility**: Works with OpenAI, OpenRouter, and any OpenAI-compatible API
- **üõ°Ô∏è Robust Error Handling**: Graceful degradation when individual models fail

**Perfect for**: Research questions, complex analysis, creative projects, technical decisions, and any task where multiple AI perspectives add value.

## üìã Requirements
- Python 3.10+
- **uv** installed ([installation guide](https://docs.astral.sh/uv/getting-started/installation))
- alternatively:
  - **pipx** installed ([installation guide](https://pipx.pypa.io/stable/installation)), update config 
    ```json
      "command": "pipx",
      "args": ["run", "ai-council"]
    ```
  - or manual install wiht `pip install ai-council`, and update config
      ```json
      "command": "ai-council",
      "args": []
    ```

## üöÄ Quick Start

1. Get your [OpenRouter](https://openrouter.ai/) api key

### Cursor IDE Setup

2. Open Cursor Settings ‚Üí MCP
3. Add new MCP server and set your api key:

```json
{
  "ai-council": {
    "command": "uvx",
    "args": ["ai-council"],
    "env": {
      "OPENROUTER_API_KEY": "..."
    }
  }
}
```

### Claude Desktop Setup

2. Edit `~/.claude_desktop_config.json` and set your api key:

```json
{
  "mcpServers": {
    "ai-council": {
      "command": "uvx",
      "args": ["ai-council"],
      "env": {
        "OPENROUTER_API_KEY": "..."
      }
    }
  }
}
```

**That's it!** Ask any complex question and the AI Council tool will automatically engage multiple models. 

By default it will use OpenRouter with Claude Sonnet 4, Gemini 2.5 Pro, and DeepSeek V3.

### CLI Arguments

Use command-line arguments for quick setup, add any of these to the `args` in you mcp config:

**Available CLI Arguments**:
- `--openai-api-key`: Your OpenAI API key
- `--openrouter-api-key`: Your OpenRouter API key  
- `--max-models`: Maximum models to query (default: 3)
- `--parallel-timeout`: Timeout in seconds (default: 60)
- `--log-level`: Logging level (DEBUG, INFO, WARNING, ERROR)
- `--config`: Path to custom config file

## ‚öôÔ∏è Advanced Configuration

For advanced setups, create a `config.yaml` file and link to it with `--config path/to/config.yaml`:

```yaml
# config.yaml
openai_api_key: "your_openai_key_here"
openrouter_api_key: "your_openrouter_key_here"
max_models: 3
parallel_timeout: 90 # in seconds
synthesis_model_selection: "random"  # or "first"

models:
  # use OpenAI API
  - name: "GPT-4o"
    provider: "openai" 
    model_id: "gpt-4o"
    enabled: true # optional, defaults to true
    
  # use OpenRouter API
  - name: "Claude Sonnet"
    provider: "openrouter"
    model_id: "anthropic/claude-3.5-sonnet"
    code_name: "Bob" # optional, auto assigned otherwise
  
  # or any custom OpenAI compatible API
  - name: "Perplexity"
    provider: "custom"
    model_id: "llama-3.1-sonar-large-128k-online"
    base_url: "https://api.perplexity.ai"
    api_key: "your_perplexity_key_here"
    
  # Local LLM (Ollama)
  - name: "Local Llama"
    provider: "custom" 
    model_id: "llama-3b"
    base_url: "http://localhost:11434"
    api_key: "key-if-needed"
```

## üìñ How It Works

AI Council uses a sophisticated three-phase approach:

### 1. **Parallel Consultation** 
- Simultaneously queries your configured AI models
- Maintains the same context and question for each model
- Handles failures gracefully (continues with successful responses)

### 2. **Anonymous Analysis**
- Assigns code names (Alpha, Beta, Gamma, etc.) to each model's response
- Prevents synthesis bias toward specific brands or providers
- Preserves response quality while removing model identity

### 3. **Smart Synthesis**
- Randomly selects one model to act as the synthesizer
- Synthesizer analyzes all anonymous responses
- Produces a comprehensive answer combining the best insights

## ü§ù Acknowledgments

This project was inspired by [Cognition Wheel](https://github.com/Hormold/cognition-wheel).

AI Council extends these ideas with:
- Enhanced configuration flexibility  
- OpenRouter support for many model options with a single api key
- Support for custom API endpoints
- Improved error handling and logging
- Using Python

