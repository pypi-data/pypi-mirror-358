Metadata-Version: 2.4
Name: automagik-spark
Version: 0.3.2
Summary: AutoMagik Spark - Automagion Engine with LangFlow integration
Home-page: https://github.com/namastexlabs/automagik-spark
Author: NamasteX Labs
Author-email: NamasteX Labs <support@namastexlabs.com>
License-Expression: MIT
Project-URL: Bug Tracker, https://github.com/namastexlabs/automagik-spark/issues
Project-URL: Documentation, https://github.com/namastexlabs/automagik-spark/tree/main/docs
Project-URL: Homepage, https://github.com/namastexlabs/automagik-spark
Project-URL: Repository, https://github.com/namastexlabs/automagik-spark
Keywords: automation,workflow,langflow,ai,llm
Classifier: Development Status :: 4 - Beta
Classifier: Environment :: Console
Classifier: Intended Audience :: Developers
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: System :: Systems Administration
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: click
Requires-Dist: alembic
Requires-Dist: sqlalchemy
Requires-Dist: psycopg2-binary
Requires-Dist: redis
Requires-Dist: aiohttp
Requires-Dist: pydantic
Requires-Dist: python-dotenv
Requires-Dist: pytz
Requires-Dist: croniter
Requires-Dist: httpx
Requires-Dist: tabulate
Requires-Dist: setuptools
Requires-Dist: asyncpg>=0.30.0
Requires-Dist: fastapi>=0.109.0
Requires-Dist: uvicorn[standard]>=0.27.0
Requires-Dist: psutil
Requires-Dist: rich
Requires-Dist: cryptography>=44.0.0
Requires-Dist: pytest>=8.3.4
Requires-Dist: aiosqlite>=0.20.0
Requires-Dist: pytest-asyncio>=0.25.3
Requires-Dist: pytest-mock>=3.14.0
Requires-Dist: celery>=5.4.0
Requires-Dist: tenacity>=9.0.0
Provides-Extra: dev
Requires-Dist: pytest>=8.3.4; extra == "dev"
Requires-Dist: pytest-asyncio>=0.23.5; extra == "dev"
Requires-Dist: pytest-cov>=6.0.0; extra == "dev"
Requires-Dist: aiosqlite>=0.19.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: mypy>=1.5.0; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

<p align="center">
  <img src=".github/images/automagik_logo.png" alt="AutoMagik Spark Logo" width="600"/>
</p>

# AutoMagik Spark

> **Because magic shouldn't be complicated. **

AutoMagik Spark is an automagion engine that seamlessly integrates with multiple [LangFlow](https://github.com/langflow-ai/langflow) instances. Deploy AI-driven flows, schedule one-time or recurring tasks, and monitor everything with minimal fuss‚Äîno coding required.

## üîó Ecosystem

- **[AutoMagik Agents](https://github.com/namastexlabs/automagik-agents)**: Develop production-level AI agents
- **[AutoMagik UI](https://github.com/namastexlabs/automagik-ui)**: Create agents using natural language with our dedicated UI

## üöÄ Installation

AutoMagik Spark provides two setup options:

### Prerequisites

- Linux-based system (Ubuntu/Debian recommended)
- Docker and Docker Compose (automatically installed on Ubuntu/Debian if not present)

### Local Production Setup

For a production-ready local environment:

```bash
./scripts/setup_local.sh
```

### Development Setup

For development with PostgreSQL and Redis Docker containers:

```bash
./scripts/setup_dev.sh
```

### What Happens During Setup

Both setup scripts will:
- Create necessary environment files
- Install Docker if needed (on Ubuntu/Debian)
- Set up all required services
- Install the CLI tool (optional)
- Guide you through the entire process

### After Installation

You'll have access to:
- **AutoMagik Spark API**: Running at [http://localhost:8883](http://localhost:8883)
- **PostgreSQL Database**: Available at `localhost:15432`
- **Worker Service**: Running and ready to process tasks
- **CLI Tool**: Installed (if chosen during setup)

### Verifying Your Installation

The setup automatically verifies all services, but you can also check manually:

```bash
# Access API documentation
open http://localhost:8883/api/v1/docs  # Interactive Swagger UI
open http://localhost:8883/api/v1/redoc # ReDoc documentation

# List flows (requires CLI installation)
source .venv/bin/activate
automagik-spark flow list
```

## üß© System Components

- **API Server**: Handles all HTTP requests and core logic
- **Worker**: Processes tasks and schedules
- **Database**: PostgreSQL with all required tables automatically created
- **LangFlow** (optional): Visual flow editor for creating AI workflows
- **CLI Tool** (optional): Command-line interface for managing flows and tasks

## üèóÔ∏è System Architecture

```mermaid
flowchart LR
    subgraph Services
      DB[PostgreSQL]
      LF1[LangFlow Instance 1]
      LF2[LangFlow Instance 2]
    end
    subgraph AutoMagik Spark
      CLI[CLI]
      API[API Server]
      CW[Celery Worker]
      W[Worker]
    end
    API -- uses --> DB
    API -- triggers --> CW
    W -- processes --> API
    API -- integrates with --> LF1
    API -- integrates with --> LF2
    CLI -- controls --> API
    API -- has UI --> UI[Automagik UI]
```

### Core Components Explained

- **API**: Core service handling requests and business logic
- **Worker**: Processes tasks and schedules
- **CLI**: Command-line tool for managing flows and tasks
- **PostgreSQL**: Stores flows, tasks, schedules, and other data
- **LangFlow**: Optional service for creating and editing flows

## üìö API Documentation

For complete API documentation, visit:
- **Swagger UI**: [http://localhost:8883/api/v1/docs](http://localhost:8883/api/v1/docs)
- **ReDoc**: [http://localhost:8883/api/v1/redoc](http://localhost:8883/api/v1/redoc)

## üõ†Ô∏è Next Steps

1. If you installed LangFlow, visit [http://localhost:17860](http://localhost:17860) to create your first flow
2. Use the API at [http://localhost:8883/api/v1/docs](http://localhost:8883/api/v1/docs) to manage your flows and tasks
3. Try out the CLI commands with `automagik-spark --help`
4. Monitor task execution through logs and API endpoints

## üó∫Ô∏è Roadmap

AutoMagik Spark's future development focuses on:
- TBA

---

<p align="center">
  <b>AutoMagik Spark: Bringing AI Automation to Life</b>
</p>
