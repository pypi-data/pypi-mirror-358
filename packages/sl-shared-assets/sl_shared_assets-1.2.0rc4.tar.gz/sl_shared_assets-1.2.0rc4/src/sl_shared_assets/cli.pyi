from pathlib import Path

from .tools import (
    ascend_tyche_data as ascend_tyche_data,
    verify_session_checksum as verify_session_checksum,
    generate_project_manifest as generate_project_manifest,
)
from .server import generate_server_credentials as generate_server_credentials
from .data_classes import (
    SessionData as SessionData,
    ExperimentState as ExperimentState,
    ProcessingTracker as ProcessingTracker,
    ProjectConfiguration as ProjectConfiguration,
    MesoscopeSystemConfiguration as MesoscopeSystemConfiguration,
    MesoscopeExperimentConfiguration as MesoscopeExperimentConfiguration,
    get_system_configuration_data as get_system_configuration_data,
    set_system_configuration_file as set_system_configuration_file,
)

def verify_session_integrity(session_path: str, create_processed_directories: bool, processed_data_root: Path) -> None:
    """Checks the integrity of the target session's raw data (contents of the raw_data directory).

    This command assumes that the data has been checksummed during acquisition and contains an ax_checksum.txt file
    that stores the data checksum generated before transferring the data to long-term storage destination. This function
    always verified the integrity of the 'raw_data' directory. It does not work with 'processed_data' or any other
    directories. If the session data was corrupted, the command removes the 'telomere.bin' file, marking the session as
    'incomplete' and automatically excluding it from all further automated processing runtimes. if the session data
    is intact, generates a 'verified.bin' marker file inside the session's raw_data folder.

    The command is also used by Sun lab data acquisition systems to generate the processed data hierarchy for each
    processed session. This use case is fully automated and should not be triggered manually by the user.
    """

def generate_project_manifest_file(
    project_path: str, output_directory: str, project_processed_path: str | None
) -> None:
    """Generates the manifest .feather file that provides information about the data-processing state of all available
    project sessions.

    The manifest file is typically used when batch-processing session data on the remote compute server. It contains the
    comprehensive snapshot of the available project's data in a table-compatible format that can also be transferred
    between machines (as it is cached in a file).
    """

def generate_system_configuration_file(output_directory: str, acquisition_system: str) -> None:
    """Generates a precursor system configuration file for the target acquisition system and configures all local
    Sun lab libraries to use that file to load the acquisition system configuration data.

    This command is typically used when setting up a new data acquisition system in the lab. The system configuration
    only needs to be specified on the machine (PC) that runs the sl-experiment library and manages the acquisition
    runtime if the system uses multiple machines (PCs). Once the system configuration .yaml file is created via this
    command, editing the configuration parameters in the file will automatically take effect during all following
    runtimes.
    """

def generate_server_credentials_file(output_directory: str, host: str, username: str, password: str) -> None:
    """Generates a new server_credentials.yaml file under the specified directory, using input information.

    This command is used to set up access to compute servers and clusters on new machines (PCs). The data stored inside
    the server_credentials.yaml file generated by this command is used by the Server and Job classes used in many Sun
    lab data processing libraries.
    """

def generate_project_configuration_file(project: str, surgery_log_id: str, water_restriction_log_id: str) -> None:
    """Generates a new project directory hierarchy and writes its configuration as a project_configuration.yaml file.

    This command creates new Sun lab projects. Until a project is created in this fashion, all data-acquisition and
    data-processing commands from sl-experiment and sl-forgery libraries targeting the project will not work. This
    command is intended to be called on the main computer of the data-acquisition system(s) used by the project. Note,
    this command assumes that the local machine (PC) is the main PC of the data acquisition system and has a valid
    acquisition system configuration .yaml file.
    """

def generate_experiment_configuration_file(project: str, experiment: str, state_count: int) -> None:
    """Generates a precursor experiment configuration .yaml file for the target experiment inside the project's
    configuration folder.

    This command assists users in creating new experiment configurations, by statically resolving the structure (layout)
    of the appropriate experiment configuration file for the acquisition system of the local machine (PC). Specifically,
    the generated precursor will contain the correct number of experiment state entries initialized to nonsensical
    default value. The user needs to manually edit the configuration file to properly specify their experiment runtime
    parameters and state transitions before running the experiment. In a sense, this command acts as an 'experiment
    template' generator.
    """

def ascend_tyche_directory(input_directory: str) -> None:
    """Restructures old Tyche project data to use the modern Sun lab data structure and uploads them to the processing
    server.

    This command is used to convert ('ascend') the old Tyche project data to the modern Sun lab structure. After
    ascension, the data can be processed and analyzed using all modern Sun lab (sl-) tools and libraries. Note, this
    process expects the input data to be preprocessed using an old Sun lab mesoscope data preprocessing pipeline. It
    will not work for any other project or data. Also, this command will only work on a machine (PC) that belongs to a
    valid Sun lab data acquisition system, such as VRPC of the Mesoscope-VR system.
    """
