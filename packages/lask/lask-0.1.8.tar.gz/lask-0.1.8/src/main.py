#!/usr/bin/env python3
"""
lask: A CLI tool to prompt ChatGPT and other LLMs from the terminal.
Usage:
    lask Your prompt here
This tool supports multiple LLM providers including OpenAI, Anthropic, and AWS Bedrock.
Configure your API keys and preferences in the ~/.lask-config file.

Features:
- Streaming responses: By default, responses are streamed in real-time as they're
  generated by the LLM. This can be disabled in the config with `streaming = false`.
"""

import sys
from typing import Union, Iterator

from src.config import LaskConfig
from src.providers import call_provider_api


def main() -> None:
    """
    Main entry point for the lask CLI tool.
    Parses command line arguments, loads configuration,
    and calls the appropriate provider API.
    """
    if len(sys.argv) < 2:
        print("Usage: lask 'Your prompt here'")
        sys.exit(1)

    # Load config from file
    config = LaskConfig.load()

    # Get the prompt from command line arguments
    prompt: str = " ".join(sys.argv[1:])

    # Determine which provider to use
    provider: str = config.get("provider", "openai").lower()

    # Check if provider is supported
    if provider not in LaskConfig.SUPPORTED_PROVIDERS:
        print(
            f"Error: Unsupported provider '{provider}'. Supported providers are: {', '.join(LaskConfig.SUPPORTED_PROVIDERS)}"
        )
        sys.exit(1)

    try:
        # Call the appropriate API based on the provider using the provider modules
        result: Union[str, Iterator[str]] = call_provider_api(provider, config, prompt)

        # Handle streaming vs non-streaming responses
        if isinstance(result, str):
            # Non-streaming response - full text is returned at once
            print(result)
        else:
            # Streaming response - print chunks as they arrive in real-time
            # This provides immediate feedback as the LLM generates content
            for chunk in result:
                # Print without buffering and without newline to create a continuous output
                print(chunk, end="", flush=True)
            print()  # Add a newline at the end of the complete response

    except ImportError as e:
        print(f"Error: {str(e)}")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()
