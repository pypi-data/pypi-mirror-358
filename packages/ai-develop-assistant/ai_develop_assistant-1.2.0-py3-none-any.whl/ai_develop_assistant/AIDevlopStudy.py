"""
MCP Server - AIéœ€æ±‚åˆ†æå’Œè®¾è®¡åŠ©æ‰‹
ååŠ©AIåˆçº§å¼€å‘è€…å®Œå–„éœ€æ±‚åˆ†æå’Œæ¶æ„è®¾è®¡

åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒå·¥å…·ï¼š
1. requirement_clarifier - éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹
2. requirement_manager - éœ€æ±‚æ–‡æ¡£ç®¡ç†å™¨  
3. architecture_designer - æ¶æ„è®¾è®¡ç”Ÿæˆå™¨
"""

import logging
import os
import json
from typing import Any, Dict, List
from datetime import datetime
from pathlib import Path

from mcp.server.fastmcp import FastMCP
from mcp.types import Tool, TextContent, Resource

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

mcp = FastMCP("StudyAIDevelop", description="AIéœ€æ±‚åˆ†æå’Œè®¾è®¡åŠ©æ‰‹")

# é…ç½®å­˜å‚¨ç›®å½•
def get_storage_dir():
    """è·å–å­˜å‚¨ç›®å½•ï¼Œä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®"""
    env_dir = os.getenv("MCP_STORAGE_DIR", "./mcp_data")
    storage_dir = Path(env_dir)
    storage_dir.mkdir(exist_ok=True)
    return storage_dir

# å…¨å±€éœ€æ±‚æ–‡æ¡£å­˜å‚¨ - ç»“æ„åŒ–è®¾è®¡
current_requirements = {
    "project_overview": [],
    "functional_requirements": [],
    "technical_requirements": [],
    "design_requirements": [],
    "deployment_requirements": [],
    "ai_constraints": [],
    "clarification_history": [],
    "architecture_designs": [],
    "last_updated": None,
    "project_id": None,
    "branch_status": {},  # åˆ†æ”¯å®ŒæˆçŠ¶æ€è·Ÿè¸ª

    # æ–°å¢ï¼šç»“æ„åŒ–éœ€æ±‚å­˜å‚¨
    "structured_requirements": {},  # {req_id: RequirementEntity}
    "requirement_relationships": [],  # éœ€æ±‚å…³è”å…³ç³»
    "module_mapping": {},  # éœ€æ±‚åˆ°æ¶æ„æ¨¡å—çš„æ˜ å°„
    "next_req_id": 1  # éœ€æ±‚IDè®¡æ•°å™¨
}

# éœ€æ±‚å®ä½“ç»“æ„
class RequirementEntity:
    """ç»“æ„åŒ–éœ€æ±‚å®ä½“"""
    def __init__(self, req_id: str, req_type: str, content: str,
                 priority: str = "medium", source: str = "user"):
        self.id = req_id
        self.type = req_type  # project_goal, functional, technical, ui_design
        self.content = content
        self.priority = priority  # high, medium, low
        self.source = source  # user, ai_inferred, derived
        self.related_ids = []  # å…³è”çš„å…¶ä»–éœ€æ±‚ID
        self.impacts = []  # å½±å“çš„æ¶æ„æ¨¡å—
        self.quality_score = 0.0
        self.created_at = datetime.now().isoformat()
        self.updated_at = datetime.now().isoformat()

    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "id": self.id,
            "type": self.type,
            "content": self.content,
            "priority": self.priority,
            "source": self.source,
            "related_ids": self.related_ids,
            "impacts": self.impacts,
            "quality_score": self.quality_score,
            "created_at": self.created_at,
            "updated_at": self.updated_at
        }

    @classmethod
    def from_dict(cls, data: dict):
        """ä»å­—å…¸åˆ›å»ºå®ä½“"""
        entity = cls(data["id"], data["type"], data["content"],
                    data.get("priority", "medium"), data.get("source", "user"))
        entity.related_ids = data.get("related_ids", [])
        entity.impacts = data.get("impacts", [])
        entity.quality_score = data.get("quality_score", 0.0)
        entity.created_at = data.get("created_at", datetime.now().isoformat())
        entity.updated_at = data.get("updated_at", datetime.now().isoformat())
        return entity

# éœ€æ±‚ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†æ¥å£
class RequirementManager:
    """éœ€æ±‚ç®¡ç†å™¨ - å¤„ç†ç»“æ„åŒ–éœ€æ±‚çš„å¢åˆ æ”¹æŸ¥å’Œå…³è”åˆ†æ"""

    @staticmethod
    def add_requirement(req_type: str, content: str, priority: str = "medium",
                       source: str = "user") -> str:
        """æ·»åŠ ç»“æ„åŒ–éœ€æ±‚"""
        req_id = f"{req_type}_{current_requirements['next_req_id']}"
        current_requirements['next_req_id'] += 1

        # åˆ›å»ºéœ€æ±‚å®ä½“
        entity = RequirementEntity(req_id, req_type, content, priority, source)

        # è®¡ç®—è´¨é‡åˆ†æ•°
        entity.quality_score = _evaluate_requirement_quality(content)

        # è‡ªåŠ¨åˆ†æå…³è”å…³ç³»
        RequirementManager._auto_detect_relationships(entity)

        # è‡ªåŠ¨æ¨æ–­æ¶æ„å½±å“
        RequirementManager._infer_architecture_impacts(entity)

        # å­˜å‚¨åˆ°ç»“æ„åŒ–å­˜å‚¨
        current_requirements["structured_requirements"][req_id] = entity

        # åŒæ—¶ä¿æŒå‘åå…¼å®¹ï¼Œå­˜å‚¨åˆ°åŸæœ‰æ ¼å¼
        RequirementManager._sync_to_legacy_format(entity)

        return req_id

    @staticmethod
    def get_requirement(req_id: str) -> RequirementEntity:
        """è·å–éœ€æ±‚å®ä½“"""
        entity_data = current_requirements["structured_requirements"].get(req_id)
        if isinstance(entity_data, dict):
            return RequirementEntity.from_dict(entity_data)
        return entity_data

    @staticmethod
    def get_requirements_by_type(req_type: str) -> list:
        """æŒ‰ç±»å‹è·å–éœ€æ±‚"""
        return [entity for entity in current_requirements["structured_requirements"].values()
                if (isinstance(entity, RequirementEntity) and entity.type == req_type) or
                   (isinstance(entity, dict) and entity.get("type") == req_type)]

    @staticmethod
    def add_relationship(req_id1: str, req_id2: str, relationship_type: str = "related"):
        """æ·»åŠ éœ€æ±‚å…³è”å…³ç³»"""
        relationship = {
            "from_id": req_id1,
            "to_id": req_id2,
            "type": relationship_type,
            "created_at": datetime.now().isoformat()
        }
        current_requirements["requirement_relationships"].append(relationship)

        # æ›´æ–°éœ€æ±‚å®ä½“çš„å…³è”åˆ—è¡¨
        req1 = RequirementManager.get_requirement(req_id1)
        req2 = RequirementManager.get_requirement(req_id2)

        if req1 and req2_id not in req1.related_ids:
            req1.related_ids.append(req_id2)
        if req2 and req_id1 not in req2.related_ids:
            req2.related_ids.append(req_id1)

    @staticmethod
    def get_related_requirements(req_id: str) -> list:
        """è·å–ç›¸å…³éœ€æ±‚"""
        entity = RequirementManager.get_requirement(req_id)
        if not entity:
            return []

        related = []
        for related_id in entity.related_ids:
            related_entity = RequirementManager.get_requirement(related_id)
            if related_entity:
                related.append(related_entity)

        return related

    @staticmethod
    def _auto_detect_relationships(new_entity: RequirementEntity):
        """è‡ªåŠ¨æ£€æµ‹éœ€æ±‚å…³è”å…³ç³»"""
        for existing_id, existing_entity in current_requirements["structured_requirements"].items():
            if existing_id == new_entity.id:
                continue

            # åŸºäºå†…å®¹ç›¸ä¼¼åº¦æ£€æµ‹å…³è”
            similarity = RequirementManager._calculate_similarity(
                new_entity.content,
                existing_entity.content if isinstance(existing_entity, RequirementEntity)
                else existing_entity.get("content", "")
            )

            if similarity > 0.3:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                RequirementManager.add_relationship(new_entity.id, existing_id, "related")

    @staticmethod
    def _calculate_similarity(content1: str, content2: str) -> float:
        """è®¡ç®—å†…å®¹ç›¸ä¼¼åº¦"""
        words1 = set(content1.lower().split())
        words2 = set(content2.lower().split())

        if not words1 or not words2:
            return 0.0

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        return len(intersection) / len(union) if union else 0.0

    @staticmethod
    def _infer_architecture_impacts(entity: RequirementEntity):
        """æ¨æ–­æ¶æ„å½±å“"""
        impact_keywords = {
            "user_interface": ["ç•Œé¢", "é¡µé¢", "äº¤äº’", "æ˜¾ç¤º", "è¾“å…¥"],
            "business_logic": ["ä¸šåŠ¡", "é€»è¾‘", "è§„åˆ™", "æµç¨‹", "å¤„ç†"],
            "data_layer": ["æ•°æ®", "å­˜å‚¨", "æ•°æ®åº“", "æŒä¹…åŒ–", "æŸ¥è¯¢"],
            "api_layer": ["æ¥å£", "API", "æœåŠ¡", "è°ƒç”¨", "é›†æˆ"],
            "security": ["å®‰å…¨", "æƒé™", "è®¤è¯", "æˆæƒ", "åŠ å¯†"],
            "performance": ["æ€§èƒ½", "é€Ÿåº¦", "ä¼˜åŒ–", "ç¼“å­˜", "å¹¶å‘"]
        }

        content_lower = entity.content.lower()
        for module, keywords in impact_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                entity.impacts.append(module)

    @staticmethod
    def _sync_to_legacy_format(entity: RequirementEntity):
        """åŒæ­¥åˆ°åŸæœ‰æ ¼å¼ï¼Œä¿æŒå‘åå…¼å®¹"""
        type_mapping = {
            "project_goal": "project_overview",
            "functional": "functional_requirements",
            "technical": "technical_requirements",
            "ui_design": "design_requirements",
            "deployment": "deployment_requirements"
        }

        legacy_key = type_mapping.get(entity.type, "functional_requirements")
        if entity.content not in current_requirements[legacy_key]:
            current_requirements[legacy_key].append(entity.content)

# å­˜å‚¨ç®¡ç†ç±»
class RequirementStorage:
    def __init__(self):
        self.storage_dir = get_storage_dir()
        self.requirements_file = self.storage_dir / "requirements.json"
        self.history_file = self.storage_dir / "history.json"
        self.load_requirements()

    def load_requirements(self):
        """åŠ è½½å·²ä¿å­˜çš„éœ€æ±‚æ–‡æ¡£ - æ”¯æŒç»“æ„åŒ–æ•°æ®"""
        global current_requirements
        try:
            if self.requirements_file.exists():
                with open(self.requirements_file, 'r', encoding='utf-8') as f:
                    saved_data = json.load(f)

                    # æ¢å¤ç»“æ„åŒ–éœ€æ±‚å¯¹è±¡
                    if "structured_requirements" in saved_data:
                        structured_reqs = {}
                        for req_id, req_data in saved_data["structured_requirements"].items():
                            if isinstance(req_data, dict) and "id" in req_data:
                                structured_reqs[req_id] = RequirementEntity.from_dict(req_data)
                            else:
                                structured_reqs[req_id] = req_data
                        saved_data["structured_requirements"] = structured_reqs

                    current_requirements.update(saved_data)
                logger.info(f"âœ… å·²åŠ è½½éœ€æ±‚æ–‡æ¡£: {self.requirements_file}")
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½éœ€æ±‚æ–‡æ¡£å¤±è´¥: {e}")

    def save_requirements(self):
        """ä¿å­˜éœ€æ±‚æ–‡æ¡£åˆ°æ–‡ä»¶ - æ”¯æŒç»“æ„åŒ–æ•°æ®"""
        try:
            current_requirements["last_updated"] = datetime.now().isoformat()

            # è½¬æ¢ç»“æ„åŒ–éœ€æ±‚ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
            serializable_reqs = {}
            for req_id, entity in current_requirements["structured_requirements"].items():
                if isinstance(entity, RequirementEntity):
                    serializable_reqs[req_id] = entity.to_dict()
                else:
                    serializable_reqs[req_id] = entity

            # åˆ›å»ºå¯åºåˆ—åŒ–çš„å‰¯æœ¬
            save_data = current_requirements.copy()
            save_data["structured_requirements"] = serializable_reqs

            with open(self.requirements_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… éœ€æ±‚æ–‡æ¡£å·²ä¿å­˜: {self.requirements_file}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜éœ€æ±‚æ–‡æ¡£å¤±è´¥: {e}")

    def save_history_entry(self, entry_type: str, content: str, metadata: dict = None):
        """ä¿å­˜å†å²è®°å½•æ¡ç›®"""
        try:
            history_entry = {
                "timestamp": datetime.now().isoformat(),
                "type": entry_type,
                "content": content,
                "metadata": metadata or {}
            }

            history = []
            if self.history_file.exists():
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)

            history.append(history_entry)

            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… å†å²è®°å½•å·²ä¿å­˜: {entry_type}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

    def export_final_document(self):
        """å¯¼å‡ºæœ€ç»ˆçš„å®Œæ•´éœ€æ±‚å’Œæ¶æ„æ–‡æ¡£"""
        try:
            final_doc = {
                "project_summary": {
                    "generated_at": datetime.now().isoformat(),
                    "project_id": current_requirements.get("project_id"),
                    "last_updated": current_requirements.get("last_updated")
                },
                "requirements": current_requirements,
                "export_format": "markdown"
            }

            export_file = self.storage_dir / f"final_document_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(export_file, 'w', encoding='utf-8') as f:
                json.dump(final_doc, f, ensure_ascii=False, indent=2)

            # åŒæ—¶ç”ŸæˆMarkdownæ ¼å¼
            md_file = self.storage_dir / f"final_document_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            self.generate_markdown_report(md_file)

            logger.info(f"âœ… æœ€ç»ˆæ–‡æ¡£å·²å¯¼å‡º: {export_file}")
            return str(export_file)
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºæœ€ç»ˆæ–‡æ¡£å¤±è´¥: {e}")
            return None

    def generate_markdown_report(self, md_file: Path):
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        try:
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write("# ğŸš€ AIå¼€å‘é¡¹ç›®éœ€æ±‚ä¸æ¶æ„æ–‡æ¡£\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

                # é¡¹ç›®æ¦‚è¿°
                if current_requirements.get("project_overview"):
                    f.write("## ğŸ“‹ é¡¹ç›®æ¦‚è¿°\n\n")
                    for item in current_requirements["project_overview"]:
                        f.write(f"- {item}\n")
                    f.write("\n")

                # åŠŸèƒ½éœ€æ±‚
                if current_requirements.get("functional_requirements"):
                    f.write("## âš™ï¸ åŠŸèƒ½éœ€æ±‚\n\n")
                    for item in current_requirements["functional_requirements"]:
                        f.write(f"- {item}\n")
                    f.write("\n")

                # æŠ€æœ¯éœ€æ±‚
                if current_requirements.get("technical_requirements"):
                    f.write("## ğŸ”§ æŠ€æœ¯éœ€æ±‚\n\n")
                    for item in current_requirements["technical_requirements"]:
                        f.write(f"- {item}\n")
                    f.write("\n")

                # æ¶æ„è®¾è®¡
                if current_requirements.get("architecture_designs"):
                    f.write("## ğŸ—ï¸ æ¶æ„è®¾è®¡\n\n")
                    for design in current_requirements["architecture_designs"]:
                        f.write(f"{design}\n\n")

                # æ¾„æ¸…å†å²
                if current_requirements.get("clarification_history"):
                    f.write("## ğŸ“ éœ€æ±‚æ¾„æ¸…å†å²\n\n")
                    for item in current_requirements["clarification_history"]:
                        f.write(f"- {item}\n")
                    f.write("\n")

            logger.info(f"âœ… MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {md_file}")
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆMarkdownæŠ¥å‘Šå¤±è´¥: {e}")

# åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨
storage = RequirementStorage()

# æ™ºèƒ½æ¾„æ¸…ç­–ç•¥æ¨¡å—
class IntelligentClarificationEngine:
    """æ™ºèƒ½æ¾„æ¸…å¼•æ“ - è´Ÿè´£ç”Ÿæˆé«˜è´¨é‡çš„æ¾„æ¸…é—®é¢˜"""

    @staticmethod
    def analyze_project_characteristics(user_input: str, context: str, existing_requirements: dict) -> dict:
        """åˆ†æé¡¹ç›®ç‰¹å¾å’Œæ ¸å¿ƒéœ€æ±‚"""
        return {
            "project_type": IntelligentClarificationEngine._identify_project_type(user_input),
            "complexity_level": IntelligentClarificationEngine._assess_complexity(user_input),
            "key_features": IntelligentClarificationEngine._extract_key_features(user_input),
            "missing_critical_info": IntelligentClarificationEngine._identify_critical_gaps(user_input, existing_requirements)
        }

    @staticmethod
    def _identify_project_type(user_input: str) -> str:
        """è¯†åˆ«é¡¹ç›®ç±»å‹"""
        keywords = {
            "web": ["ç½‘ç«™", "web", "åœ¨çº¿", "å¹³å°", "ç³»ç»Ÿ"],
            "mobile": ["app", "æ‰‹æœº", "ç§»åŠ¨", "å®‰å“", "ios"],
            "desktop": ["æ¡Œé¢", "pc", "è½¯ä»¶", "å®¢æˆ·ç«¯"],
            "miniprogram": ["å°ç¨‹åº", "å¾®ä¿¡", "æ”¯ä»˜å®"]
        }

        user_lower = user_input.lower()
        for project_type, words in keywords.items():
            if any(word in user_lower for word in words):
                return project_type
        return "general"

    @staticmethod
    def _assess_complexity(user_input: str) -> str:
        """è¯„ä¼°é¡¹ç›®å¤æ‚åº¦"""
        complex_indicators = ["ai", "æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "å¤§æ•°æ®", "åˆ†å¸ƒå¼", "å¾®æœåŠ¡", "å®æ—¶", "é«˜å¹¶å‘"]
        user_lower = user_input.lower()

        if any(indicator in user_lower for indicator in complex_indicators):
            return "high"
        elif len(user_input.split()) > 10:
            return "medium"
        return "low"

    @staticmethod
    def _extract_key_features(user_input: str) -> list:
        """æå–å…³é”®åŠŸèƒ½ç‰¹å¾"""
        feature_keywords = {
            "ç”¨æˆ·ç®¡ç†": ["ç”¨æˆ·", "ç™»å½•", "æ³¨å†Œ", "è´¦å·"],
            "æ•°æ®å¤„ç†": ["æ•°æ®", "å­˜å‚¨", "å¤„ç†", "åˆ†æ"],
            "äº¤äº’åŠŸèƒ½": ["èŠå¤©", "è¯„è®º", "æ¶ˆæ¯", "é€šçŸ¥"],
            "å†…å®¹ç®¡ç†": ["å‘å¸ƒ", "ç¼–è¾‘", "ç®¡ç†", "å†…å®¹"]
        }

        features = []
        user_lower = user_input.lower()
        for feature, keywords in feature_keywords.items():
            if any(keyword in user_lower for keyword in keywords):
                features.append(feature)
        return features

    @staticmethod
    def _identify_critical_gaps(user_input: str, existing_requirements: dict) -> list:
        """è¯†åˆ«å…³é”®ä¿¡æ¯ç¼ºå£"""
        gaps = []

        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘ç›®æ ‡ç”¨æˆ·ä¿¡æ¯
        if not any("ç”¨æˆ·" in str(req) for req in existing_requirements.get("project_overview", [])):
            gaps.append("target_users")

        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘æŠ€æœ¯åå¥½
        if not existing_requirements.get("technical_requirements"):
            gaps.append("tech_preferences")

        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘åŠŸèƒ½ç»†èŠ‚
        if not existing_requirements.get("functional_requirements"):
            gaps.append("functional_details")

        return gaps

    @staticmethod
    def get_current_branch(context: str, user_input: str) -> str:
        """è¯†åˆ«å½“å‰è®¨è®ºçš„åˆ†æ”¯ - æ™ºèƒ½ä¼˜å…ˆçº§"""
        context_lower = context.lower()
        input_lower = user_input.lower()
        combined_text = context_lower + " " + input_lower

        # åˆ†æ”¯å…³é”®è¯æƒé‡æ˜ å°„
        branch_weights = {
            "project_goals": ["ç›®æ ‡", "ç”¨æˆ·", "é—®é¢˜", "ä»·å€¼", "ä¸ºä»€ä¹ˆ", "è§£å†³"],
            "functional_design": ["åŠŸèƒ½", "ç‰¹æ€§", "æ“ä½œ", "æµç¨‹", "ä¸šåŠ¡", "æ€ä¹ˆåš"],
            "technical_preferences": ["æŠ€æœ¯", "æ¡†æ¶", "æ€§èƒ½", "è¯­è¨€", "æ•°æ®åº“", "æ¶æ„"],
            "ui_design": ["ç•Œé¢", "ui", "äº¤äº’", "è®¾è®¡", "æ ·å¼", "ç”¨æˆ·ä½“éªŒ"]
        }

        # è®¡ç®—å„åˆ†æ”¯åŒ¹é…åˆ†æ•°
        branch_scores = {}
        for branch, keywords in branch_weights.items():
            score = sum(2 if keyword in combined_text else 0 for keyword in keywords)
            branch_scores[branch] = score

        # å¦‚æœæœ‰æ˜ç¡®åŒ¹é…ï¼Œè¿”å›æœ€é«˜åˆ†åˆ†æ”¯
        max_score = max(branch_scores.values()) if branch_scores else 0
        if max_score > 0:
            return max(branch_scores.items(), key=lambda x: x[1])[0]

        # å¦åˆ™è¿”å›æœ€éœ€è¦å®Œå–„çš„åˆ†æ”¯
        return IntelligentClarificationEngine._calculate_next_priority()

    @staticmethod
    def _calculate_next_priority() -> str:
        """è®¡ç®—ä¸‹ä¸€ä¸ªä¼˜å…ˆçº§æœ€é«˜çš„åˆ†æ”¯"""
        # è·å–å„åˆ†æ”¯å®Œæ•´æ€§
        branch_status = IntelligentClarificationEngine.check_branch_completeness(current_requirements)
        branch_scores = branch_status.get("branch_scores", {})

        # ä¼˜å…ˆçº§æƒé‡ï¼ˆåˆ†æ•°è¶Šä½ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        priority_weights = {
            "project_goals": 1.0,      # æœ€é«˜ä¼˜å…ˆçº§
            "functional_design": 0.9,
            "technical_preferences": 0.7,
            "ui_design": 0.6
        }

        # è®¡ç®—ä¼˜å…ˆçº§åˆ†æ•°ï¼ˆå®Œæ•´åº¦è¶Šä½ï¼Œæƒé‡è¶Šé«˜ï¼Œä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        priority_scores = {}
        for branch in priority_weights:
            completeness = branch_scores.get(branch, 0.0)
            weight = priority_weights[branch]
            # ä¼˜å…ˆçº§åˆ†æ•° = æƒé‡ * (1 - å®Œæ•´åº¦)
            priority_scores[branch] = weight * (1 - completeness)

        # è¿”å›ä¼˜å…ˆçº§åˆ†æ•°æœ€é«˜çš„åˆ†æ”¯
        return max(priority_scores.items(), key=lambda x: x[1])[0]

    @staticmethod
    def check_branch_completeness(requirements: dict) -> dict:
        """æ£€æŸ¥å„åˆ†æ”¯å®Œæ•´æ€§ - åŠ¨æ€æ ‡å‡†"""

        # åŠ¨æ€è¯„ä¼°åˆ†æ”¯å®Œæ•´æ€§ï¼ˆåŸºäºè´¨é‡è€Œéæ•°é‡ï¼‰
        branch_scores = {}

        # é¡¹ç›®ç›®æ ‡åˆ†æ”¯
        project_reqs = requirements.get("project_overview", [])
        branch_scores["project_goals"] = IntelligentClarificationEngine._evaluate_branch_quality(
            project_reqs, min_count=1, quality_threshold=0.5
        )

        # åŠŸèƒ½è®¾è®¡åˆ†æ”¯
        functional_reqs = requirements.get("functional_requirements", [])
        branch_scores["functional_design"] = IntelligentClarificationEngine._evaluate_branch_quality(
            functional_reqs, min_count=1, quality_threshold=0.4  # é™ä½è¦æ±‚
        )

        # æŠ€æœ¯åå¥½åˆ†æ”¯
        tech_reqs = requirements.get("technical_requirements", [])
        branch_scores["technical_preferences"] = IntelligentClarificationEngine._evaluate_branch_quality(
            tech_reqs, min_count=1, quality_threshold=0.3
        )

        # UIè®¾è®¡åˆ†æ”¯
        design_reqs = requirements.get("design_requirements", [])
        branch_scores["ui_design"] = IntelligentClarificationEngine._evaluate_branch_quality(
            design_reqs, min_count=1, quality_threshold=0.3
        )

        # è®¡ç®—å®Œæˆçš„åˆ†æ”¯
        completed_branches = [branch for branch, score in branch_scores.items() if score >= 0.6]
        incomplete_branches = [branch for branch, score in branch_scores.items() if score < 0.6]

        completion_rate = len(completed_branches) / len(branch_scores)

        return {
            "all_complete": completion_rate >= 0.75,  # 75%å®Œæˆå³å¯
            "incomplete_branches": incomplete_branches,
            "completion_rate": completion_rate,
            "branch_scores": branch_scores
        }

    @staticmethod
    def _evaluate_branch_quality(requirements: list, min_count: int, quality_threshold: float) -> float:
        """è¯„ä¼°åˆ†æ”¯è´¨é‡"""
        if len(requirements) < min_count:
            return 0.0

        if not requirements:
            return 0.0

        # è®¡ç®—å¹³å‡è´¨é‡
        total_quality = sum(_evaluate_requirement_quality(req) for req in requirements)
        avg_quality = total_quality / len(requirements)

        # ç»“åˆæ•°é‡å’Œè´¨é‡
        count_score = min(len(requirements) / min_count, 1.0)
        quality_score = avg_quality

        return (count_score + quality_score) / 2

# éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹å·¥å…·
@mcp.tool()
def requirement_clarifier(user_input: str, context: str = "") -> str:
    """æ™ºèƒ½éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹ - æ·±åº¦åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œç”Ÿæˆé«˜è´¨é‡æ¾„æ¸…é—®é¢˜"""

    # ä¿å­˜æ¾„æ¸…å†å²
    _save_clarification_history(user_input, context)

    # æ™ºèƒ½åˆ†æé¡¹ç›®ç‰¹å¾
    project_analysis = IntelligentClarificationEngine.analyze_project_characteristics(
        user_input, context, current_requirements
    )

    # ç”Ÿæˆæ™ºèƒ½åŒ–åˆ†ææç¤º
    analysis_prompt = _generate_intelligent_analysis_prompt(user_input, context, project_analysis)

    # æ·»åŠ å¼ºåˆ¶è¿­ä»£æ§åˆ¶æ£€æŸ¥
    completeness_check = _check_requirements_completeness()

    if not completeness_check["is_sufficient"]:
        # éœ€æ±‚ä¸è¶³ï¼Œå¼ºåˆ¶ç»§ç»­æ¾„æ¸…
        next_priority = IntelligentClarificationEngine._calculate_next_priority()
        analysis_prompt += f"\n\nâš ï¸ **éœ€æ±‚å®Œæ•´æ€§æ£€æŸ¥**ï¼š{completeness_check['status_summary']}"
        analysis_prompt += f"\nğŸ¯ **å»ºè®®ä¼˜å…ˆæ¾„æ¸…**ï¼š{next_priority} ç±»å‹çš„éœ€æ±‚"
        analysis_prompt += f"\nğŸ“‹ **é‡è¦æé†’**ï¼šè¯·ç»§ç»­æä¾›æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œå½“å‰éœ€æ±‚è¿˜ä¸è¶³ä»¥è¿›è¡Œæ¶æ„è®¾è®¡ã€‚"
    else:
        # éœ€æ±‚å……è¶³ï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
        analysis_prompt += f"\n\nâœ… **éœ€æ±‚å®Œæ•´æ€§æ£€æŸ¥**ï¼š{completeness_check['status_summary']}"
        analysis_prompt += f"\nğŸ‰ **çŠ¶æ€æ›´æ–°**ï¼šéœ€æ±‚å·²åŸºæœ¬å®Œå–„ï¼Œå¯ä»¥ä½¿ç”¨ requirement_manager ä¿å­˜å¹¶è€ƒè™‘è¿›å…¥æ¶æ„è®¾è®¡é˜¶æ®µã€‚"

    return analysis_prompt

def _save_clarification_history(user_input: str, context: str):
    """ä¿å­˜æ¾„æ¸…å†å²è®°å½•"""
    current_requirements["clarification_history"].append({
        "timestamp": datetime.now().isoformat(),
        "user_input": user_input,
        "context": context
    })
    storage.save_history_entry("requirement_clarification", user_input, {"context": context})
    storage.save_requirements()

def _generate_intelligent_analysis_prompt(user_input: str, context: str, project_analysis: dict) -> str:
    """ç”Ÿæˆæ™ºèƒ½åŒ–åˆ†ææç¤ºè¯"""

    # è·å–å·²æœ‰éœ€æ±‚ä¿¡æ¯å’Œåˆ†æ”¯çŠ¶æ€
    existing_info = _get_existing_requirements_summary()
    current_branch = IntelligentClarificationEngine.get_current_branch(context, user_input)
    branch_status = IntelligentClarificationEngine.check_branch_completeness(current_requirements)

    # æ£€æµ‹ç”¨æˆ·æ˜¯å¦è¦æ±‚AIè‡ªä¸»è®¾è®¡
    auto_design_keywords = ["å¸¸è§„", "æ ‡å‡†", "æ™®é€š", "ä¸€èˆ¬", "ä½ å†³å®š", "aiå†³å®š", "è‡ªå·±è®¾è®¡"]
    is_auto_design = any(keyword in user_input.lower() for keyword in auto_design_keywords)

    return f"""# ğŸ§  æ™ºèƒ½éœ€æ±‚åˆ†æä»»åŠ¡ - åˆ†æ”¯æ„ŸçŸ¥æ¨¡å¼

## ğŸ“ ç”¨æˆ·è¾“å…¥åˆ†æ
**åŸå§‹è¾“å…¥**: {user_input}
**ä¸Šä¸‹æ–‡**: {context}
**å½“å‰åˆ†æ”¯**: {current_branch}
**é¡¹ç›®ç±»å‹**: {project_analysis['project_type']}
**å¤æ‚åº¦**: {project_analysis['complexity_level']}
**è¯†åˆ«ç‰¹å¾**: {', '.join(project_analysis['key_features'])}
**ç”¨æˆ·æˆæƒè‡ªä¸»è®¾è®¡**: {"æ˜¯" if is_auto_design else "å¦"}

## ğŸ“‹ å·²æœ‰éœ€æ±‚ä¿¡æ¯
{existing_info}

## ğŸŒ¿ åˆ†æ”¯å®Œæ•´æ€§çŠ¶æ€
- **å®Œæˆç‡**: {branch_status['completion_rate']:.0%}
- **æœªå®Œæˆåˆ†æ”¯**: {', '.join(branch_status['incomplete_branches']) if branch_status['incomplete_branches'] else 'æ— '}
- **å½“å‰åˆ†æ”¯çŠ¶æ€**: {"è®¨è®ºä¸­" if current_branch in branch_status['incomplete_branches'] else "å·²å®Œæˆ"}

## ğŸ¯ åˆ†æ”¯æ„ŸçŸ¥æ™ºèƒ½åˆ†ææŒ‡ä»¤

### ç¬¬ä¸€æ­¥ï¼šåˆ†æ”¯çŠ¶æ€å¤„ç†
{"**ç”¨æˆ·æˆæƒè‡ªä¸»è®¾è®¡å½“å‰åˆ†æ”¯**" if is_auto_design else "**ç”¨æˆ·æä¾›å…·ä½“ä¿¡æ¯**"}

{f'''
**è‡ªä¸»è®¾è®¡æŒ‡ä»¤**ï¼š
- ä»…å¯¹å½“å‰åˆ†æ”¯({current_branch})è¿›è¡Œåˆç†çš„æ ‡å‡†åŒ–è®¾è®¡
- è®¾è®¡å®Œæˆåï¼Œæ£€æŸ¥å…¶ä»–æœªå®Œæˆåˆ†æ”¯
- ç»å¯¹ç¦æ­¢è·³è½¬åˆ°æ¶æ„è®¾è®¡é˜¶æ®µ
- å¿…é¡»æé†’ç”¨æˆ·è¿˜æœ‰å…¶ä»–åˆ†æ”¯éœ€è¦è®¨è®º
''' if is_auto_design else '''
**ä¿¡æ¯æ¾„æ¸…æŒ‡ä»¤**ï¼š
- æ·±åº¦åˆ†æç”¨æˆ·åœ¨å½“å‰åˆ†æ”¯çš„å…·ä½“éœ€æ±‚
- è¯†åˆ«å½“å‰åˆ†æ”¯çš„å…³é”®ç¼ºå¤±ä¿¡æ¯
- ç”Ÿæˆé’ˆå¯¹å½“å‰åˆ†æ”¯çš„é«˜è´¨é‡æ¾„æ¸…é—®é¢˜
'''}

### ç¬¬äºŒæ­¥ï¼šå…¨å±€å®Œæ•´æ€§æ£€æŸ¥
**é‡è¦åŸåˆ™ï¼šå§‹ç»ˆä¿æŒå…¨å±€è§†é‡ï¼Œé˜²æ­¢é—å¿˜å…¶ä»–åˆ†æ”¯**

- å½“å‰è®¨è®ºåˆ†æ”¯ï¼š{current_branch}
- æœªå®Œæˆåˆ†æ”¯ï¼š{', '.join(branch_status['incomplete_branches']) if branch_status['incomplete_branches'] else 'æ— '}
- å®Œæˆç‡ï¼š{branch_status['completion_rate']:.0%}

### ç¬¬ä¸‰æ­¥ï¼šæ™ºèƒ½é—®é¢˜ç”Ÿæˆç­–ç•¥
**é’ˆå¯¹å½“å‰åˆ†æ”¯ç”Ÿæˆ2-3ä¸ªæœ€é‡è¦çš„é—®é¢˜**ï¼š

{f'''
**å½“å‰åˆ†æ”¯({current_branch})çš„å…³é”®æ¾„æ¸…ç‚¹**ï¼š
- å¦‚æœæ˜¯åŠŸèƒ½è®¾è®¡ï¼šå…·ä½“çš„åŠŸèƒ½æµç¨‹ã€ç”¨æˆ·æ“ä½œæ–¹å¼ã€æ•°æ®å¤„ç†é€»è¾‘
- å¦‚æœæ˜¯æŠ€æœ¯åå¥½ï¼šå…·ä½“çš„æŠ€æœ¯æ ˆé€‰æ‹©ã€æ€§èƒ½è¦æ±‚ã€é›†æˆéœ€æ±‚
- å¦‚æœæ˜¯UIè®¾è®¡ï¼šå…·ä½“çš„ç•Œé¢é£æ ¼ã€äº¤äº’æ–¹å¼ã€ç”¨æˆ·ä½“éªŒåå¥½
- å¦‚æœæ˜¯é¡¹ç›®ç›®æ ‡ï¼šå…·ä½“çš„ç”¨æˆ·ç¾¤ä½“ã€æ ¸å¿ƒä»·å€¼ã€è§£å†³çš„é—®é¢˜
''' if not is_auto_design else f'''
**è‡ªä¸»è®¾è®¡{current_branch}åˆ†æ”¯**ï¼š
- åŸºäºå·²æœ‰ä¿¡æ¯è¿›è¡Œåˆç†çš„æ ‡å‡†åŒ–è®¾è®¡
- è®¾è®¡å†…å®¹è¦å…·ä½“ã€å¯å®æ–½
- é¿å…è¿‡äºå¤æ‚æˆ–è¿‡äºç®€å•çš„æ–¹æ¡ˆ
'''}

## ğŸ“¤ è¾“å‡ºæ ¼å¼è¦æ±‚

**ğŸ” åˆ†æ”¯æ„ŸçŸ¥åˆ†æç»“æœ**ï¼š
- **å½“å‰åˆ†æ”¯**ï¼š{current_branch}
- **åˆ†æ”¯å®ŒæˆçŠ¶æ€**ï¼š{branch_status['completion_rate']:.0%}
- **å·²æ˜ç¡®ä¿¡æ¯**ï¼š[ç”¨æˆ·åœ¨å½“å‰åˆ†æ”¯å·²æ¸…æ¥šè¡¨è¾¾çš„éœ€æ±‚]
- **åˆ†æ”¯å…³é”®ç¼ºå£**ï¼š[å½“å‰åˆ†æ”¯ç¼ºå¤±çš„å…³é”®ä¿¡æ¯]

{f'''
**ğŸ¤– AIè‡ªä¸»è®¾è®¡ç»“æœ**ï¼š
[å¯¹{current_branch}åˆ†æ”¯è¿›è¡Œå…·ä½“çš„æ ‡å‡†åŒ–è®¾è®¡]

**âš ï¸ é‡è¦æé†’**ï¼š
- å½“å‰ä»…å®Œæˆäº†{current_branch}åˆ†æ”¯çš„è®¾è®¡
- è¿˜æœ‰ä»¥ä¸‹åˆ†æ”¯éœ€è¦è®¨è®ºï¼š{', '.join(branch_status['incomplete_branches'])}
- è¯·ç»§ç»­æ¾„æ¸…å…¶ä»–åˆ†æ”¯ï¼Œä¸è¦æ€¥äºè¿›å…¥æ¶æ„è®¾è®¡
''' if is_auto_design else f'''
**â“ é’ˆå¯¹{current_branch}åˆ†æ”¯çš„æ¾„æ¸…é—®é¢˜**ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰ï¼š
1. [æœ€é‡è¦çš„é—®é¢˜ - è¯´æ˜ä¸ºä»€ä¹ˆé‡è¦ï¼Œæä¾›å…·ä½“é€‰é¡¹]
2. [ç¬¬äºŒé‡è¦çš„é—®é¢˜ - è¯´æ˜å¯¹æ¶æ„çš„å½±å“ï¼Œç»™å‡ºç¤ºä¾‹]
3. [ç¬¬ä¸‰ä¸ªé—®é¢˜ - å¦‚æœå¿…è¦ï¼Œè§£é‡Šæ¾„æ¸…çš„ä»·å€¼]
'''}

**ğŸŒ¿ å…¨å±€è¿›åº¦æé†’**ï¼š
- å·²å®Œæˆåˆ†æ”¯ï¼š{len([b for b in ['project_goals', 'functional_design', 'technical_preferences', 'ui_design'] if b not in branch_status['incomplete_branches']])}ä¸ª
- å¾…å®Œæˆåˆ†æ”¯ï¼š{len(branch_status['incomplete_branches'])}ä¸ª
- {"âœ… æ‰€æœ‰åˆ†æ”¯å·²å®Œæˆï¼Œå¯ä»¥è€ƒè™‘æ¶æ„è®¾è®¡" if branch_status['all_complete'] else f"â³ è¿˜éœ€å®Œæˆï¼š{', '.join(branch_status['incomplete_branches'])}"}

**ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨æŒ‡å—**ï¼š
{f"è¯·ä½¿ç”¨ requirement_manager ä¿å­˜{current_branch}åˆ†æ”¯çš„è®¾è®¡ç»“æœï¼Œç„¶åç»§ç»­æ¾„æ¸…å…¶ä»–åˆ†æ”¯" if is_auto_design else f"è¯·å›ç­”{current_branch}åˆ†æ”¯çš„æ¾„æ¸…é—®é¢˜ï¼Œç„¶åä½¿ç”¨ requirement_manager ä¿å­˜"}

---
*ğŸ”„ åˆ†æ”¯å®Œæˆåï¼Œè¯·ä½¿ç”¨ requirement_manager å·¥å…·ä¿å­˜ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æŸ¥å…¶ä»–åˆ†æ”¯*
"""

def _get_existing_requirements_summary() -> str:
    """è·å–å·²æœ‰éœ€æ±‚ä¿¡æ¯æ‘˜è¦"""
    summary_parts = []

    if current_requirements.get("project_overview"):
        summary_parts.append(f"é¡¹ç›®æ¦‚è¿°: {len(current_requirements['project_overview'])} æ¡")

    if current_requirements.get("functional_requirements"):
        summary_parts.append(f"åŠŸèƒ½éœ€æ±‚: {len(current_requirements['functional_requirements'])} æ¡")

    if current_requirements.get("technical_requirements"):
        summary_parts.append(f"æŠ€æœ¯éœ€æ±‚: {len(current_requirements['technical_requirements'])} æ¡")

    if not summary_parts:
        return "æš‚æ— å·²ä¿å­˜çš„éœ€æ±‚ä¿¡æ¯"

    return " | ".join(summary_parts)

# æ™ºèƒ½éœ€æ±‚ç®¡ç†æ¨¡å—
class IntelligentRequirementManager:
    """æ™ºèƒ½éœ€æ±‚ç®¡ç†å™¨ - è´Ÿè´£éœ€æ±‚åˆ†ç±»ã€å»é‡ã€éªŒè¯"""

    # æ‰©å±•çš„ç±»åˆ«æ˜ å°„
    CATEGORY_MAPPING = {
        "é¡¹ç›®æ¦‚è¿°": "project_overview",
        "é¡¹ç›®ç›®æ ‡": "project_overview",
        "æ ¸å¿ƒåŠŸèƒ½éœ€æ±‚": "functional_requirements",
        "åŠŸèƒ½éœ€æ±‚": "functional_requirements",
        "åŠŸèƒ½å’ŒUIéœ€æ±‚": "functional_requirements",
        "UIè®¾è®¡éœ€æ±‚": "design_requirements",
        "ç”¨æˆ·ä½“éªŒéœ€æ±‚": "design_requirements",
        "æŠ€æœ¯éœ€æ±‚": "technical_requirements",
        "æŠ€æœ¯æ ˆåå¥½": "technical_requirements",
        "æ€§èƒ½éœ€æ±‚": "technical_requirements",
        "è®¾è®¡éœ€æ±‚": "design_requirements",
        "éƒ¨ç½²éœ€æ±‚": "deployment_requirements",
        "è¿ç»´éœ€æ±‚": "deployment_requirements",
        "AIçº¦æŸ": "ai_constraints",
        "ä¸šåŠ¡çº¦æŸ": "ai_constraints"
    }

    @staticmethod
    def smart_categorize(content: str, suggested_category: str) -> str:
        """æ™ºèƒ½åˆ†ç±»éœ€æ±‚å†…å®¹"""
        # é¦–å…ˆå°è¯•å»ºè®®çš„ç±»åˆ«
        if suggested_category in IntelligentRequirementManager.CATEGORY_MAPPING:
            return IntelligentRequirementManager.CATEGORY_MAPPING[suggested_category]

        # åŸºäºå†…å®¹å…³é”®è¯æ™ºèƒ½åˆ†ç±»
        content_lower = content.lower()

        if any(keyword in content_lower for keyword in ["ç›®æ ‡", "ç”¨æˆ·ç¾¤", "è§£å†³", "ä»·å€¼"]):
            return "project_overview"
        elif any(keyword in content_lower for keyword in ["åŠŸèƒ½", "ç‰¹æ€§", "æ“ä½œ", "æµç¨‹"]):
            return "functional_requirements"
        elif any(keyword in content_lower for keyword in ["æŠ€æœ¯", "æ¡†æ¶", "æ•°æ®åº“", "api"]):
            return "technical_requirements"
        elif any(keyword in content_lower for keyword in ["ç•Œé¢", "ui", "äº¤äº’", "ä½“éªŒ"]):
            return "design_requirements"
        elif any(keyword in content_lower for keyword in ["éƒ¨ç½²", "æœåŠ¡å™¨", "è¿ç»´", "ç›‘æ§"]):
            return "deployment_requirements"

        return "functional_requirements"  # é»˜è®¤åˆ†ç±»

    @staticmethod
    def check_duplicate(content: str, category: str, existing_requirements: dict) -> dict:
        """æ£€æŸ¥é‡å¤éœ€æ±‚"""
        category_items = existing_requirements.get(category, [])

        for item in category_items:
            existing_content = item.get('content', '') if isinstance(item, dict) else str(item)

            # ç®€å•çš„ç›¸ä¼¼åº¦æ£€æŸ¥
            if IntelligentRequirementManager._calculate_similarity(content, existing_content) > 0.8:
                return {
                    "is_duplicate": True,
                    "similar_content": existing_content,
                    "timestamp": item.get('timestamp', 'unknown') if isinstance(item, dict) else 'unknown'
                }

        return {"is_duplicate": False}

    @staticmethod
    def _calculate_similarity(text1: str, text2: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())

        if not words1 or not words2:
            return 0.0

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        return len(intersection) / len(union)

    @staticmethod
    def validate_requirement(content: str, category: str) -> dict:
        """éªŒè¯éœ€æ±‚å†…å®¹çš„å®Œæ•´æ€§"""
        issues = []
        suggestions = []

        if len(content.strip()) < 10:
            issues.append("éœ€æ±‚æè¿°è¿‡äºç®€çŸ­")
            suggestions.append("è¯·æä¾›æ›´è¯¦ç»†çš„æè¿°")

        if category == "technical_requirements" and not any(tech in content.lower() for tech in ["æŠ€æœ¯", "æ¡†æ¶", "æ•°æ®åº“", "api", "æ¶æ„"]):
            issues.append("æŠ€æœ¯éœ€æ±‚ç¼ºå°‘å…·ä½“æŠ€æœ¯ç»†èŠ‚")
            suggestions.append("è¯·æ˜ç¡®å…·ä½“çš„æŠ€æœ¯é€‰å‹æˆ–çº¦æŸ")

        return {
            "is_valid": len(issues) == 0,
            "issues": issues,
            "suggestions": suggestions
        }

# éœ€æ±‚æ–‡æ¡£ç®¡ç†å™¨å·¥å…·
@mcp.tool()
def requirement_manager(clarified_info: str, category: str) -> str:
    """æ™ºèƒ½éœ€æ±‚æ–‡æ¡£ç®¡ç†å™¨ - ç»“æ„åŒ–å­˜å‚¨ã€å…³è”åˆ†æã€æ¨¡å—æ˜ å°„"""

    # æ™ºèƒ½åˆ†ç±»
    storage_category = IntelligentRequirementManager.smart_categorize(clarified_info, category)

    # æ£€æŸ¥é‡å¤
    duplicate_check = IntelligentRequirementManager.check_duplicate(
        clarified_info, storage_category, current_requirements
    )

    # éªŒè¯éœ€æ±‚
    validation_result = IntelligentRequirementManager.validate_requirement(clarified_info, storage_category)

    # å¦‚æœå‘ç°é‡å¤ï¼Œæä¾›é€‰æ‹©
    if duplicate_check["is_duplicate"]:
        return f"""# âš ï¸ å‘ç°ç›¸ä¼¼éœ€æ±‚

## ğŸ” é‡å¤æ£€æµ‹ç»“æœ
- **æ–°éœ€æ±‚**: {clarified_info}
- **å·²æœ‰éœ€æ±‚**: {duplicate_check['similar_content']}
- **æ·»åŠ æ—¶é—´**: {duplicate_check['timestamp']}

## ğŸ¤” å¤„ç†å»ºè®®
1. å¦‚æœæ˜¯è¡¥å……ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜"è¡¥å……ï¼š"
2. å¦‚æœæ˜¯ä¿®æ­£ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜"ä¿®æ­£ï¼š"
3. å¦‚æœç¡®å®æ˜¯æ–°éœ€æ±‚ï¼Œè¯·é‡æ–°è°ƒç”¨å¹¶è¯´æ˜å·®å¼‚

è¯·é‡æ–°æ•´ç†åå†æ¬¡æäº¤ã€‚
"""

    # å¦‚æœéªŒè¯å¤±è´¥ï¼Œæä¾›æ”¹è¿›å»ºè®®
    if not validation_result["is_valid"]:
        return f"""# âŒ éœ€æ±‚éªŒè¯å¤±è´¥

## ğŸ” å‘ç°çš„é—®é¢˜
{chr(10).join(f"- {issue}" for issue in validation_result['issues'])}

## ğŸ’¡ æ”¹è¿›å»ºè®®
{chr(10).join(f"- {suggestion}" for suggestion in validation_result['suggestions'])}

è¯·å®Œå–„éœ€æ±‚æè¿°åé‡æ–°æäº¤ã€‚
"""

    # ç»“æ„åŒ–ä¿å­˜éœ€æ±‚
    req_id = RequirementManager.add_requirement(
        req_type=storage_category,
        content=clarified_info,
        priority="medium",  # å¯ä»¥åç»­æ™ºèƒ½æ¨æ–­
        source="user"
    )

    # ä¿å­˜åˆ°æ–‡ä»¶
    storage.save_history_entry("requirement_update", clarified_info, {
        "category": category,
        "storage_category": storage_category,
        "requirement_id": req_id
    })
    storage.save_requirements()

    # åˆ†æå…³è”å…³ç³»å’Œæ¶æ„å½±å“
    entity = RequirementManager.get_requirement(req_id)
    related_reqs = RequirementManager.get_related_requirements(req_id)

    # ç”Ÿæˆç»“æ„åŒ–çŠ¶æ€æŠ¥å‘Š
    return _generate_structured_requirement_report(req_id, entity, related_reqs, category, storage_category)

def _generate_structured_requirement_report(req_id: str, entity: RequirementEntity,
                                          related_reqs: list, category: str, storage_category: str) -> str:
    """ç”Ÿæˆç»“æ„åŒ–éœ€æ±‚æŠ¥å‘Š"""

    # ç»Ÿè®¡ç»“æ„åŒ–éœ€æ±‚
    structured_count = len(current_requirements["structured_requirements"])
    relationships_count = len(current_requirements["requirement_relationships"])

    # åˆ†ææ¶æ„å½±å“
    impact_summary = ", ".join(entity.impacts) if entity.impacts else "æš‚æ— æ˜ç¡®å½±å“"

    # å…³è”éœ€æ±‚æ‘˜è¦
    related_summary = []
    for related in related_reqs[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªç›¸å…³éœ€æ±‚
        related_summary.append(f"- {related.id}: {related.content[:30]}...")

    return f"""# âœ… ç»“æ„åŒ–éœ€æ±‚æ–‡æ¡£æ›´æ–°å®Œæˆ

## ğŸ“ éœ€æ±‚è¯¦æƒ…
- **éœ€æ±‚ID**: {req_id}
- **ç±»å‹**: {storage_category}
- **å†…å®¹**: {entity.content}
- **ä¼˜å…ˆçº§**: {entity.priority}
- **è´¨é‡åˆ†æ•°**: {entity.quality_score:.2f}
- **åˆ›å»ºæ—¶é—´**: {entity.created_at}

## ğŸ”— å…³è”åˆ†æ
- **ç›¸å…³éœ€æ±‚æ•°é‡**: {len(related_reqs)}
{chr(10).join(related_summary) if related_summary else "- æš‚æ— ç›¸å…³éœ€æ±‚"}

## ğŸ—ï¸ æ¶æ„å½±å“
- **å½±å“æ¨¡å—**: {impact_summary}
- **è®¾è®¡å»ºè®®**: åŸºäºæ­¤éœ€æ±‚ï¼Œå»ºè®®å…³æ³¨ {impact_summary} çš„æ¨¡å—åŒ–è®¾è®¡

## ğŸ“Š æ•´ä½“çŠ¶æ€
- **ç»“æ„åŒ–éœ€æ±‚æ€»æ•°**: {structured_count}
- **éœ€æ±‚å…³è”å…³ç³»**: {relationships_count}
- **æ¨¡å—åŒ–ç¨‹åº¦**: {"é«˜" if len(entity.impacts) >= 2 else "ä¸­" if len(entity.impacts) == 1 else "å¾…åˆ†æ"}

## ğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®
{_generate_intelligent_next_steps()}

---
ğŸ’¡ **æ¨¡å—åŒ–è®¾è®¡æç¤º**: æ­¤éœ€æ±‚å·²è‡ªåŠ¨åˆ†ææ¶æ„å½±å“ï¼Œæœ‰åŠ©äºåç»­çš„ä½è€¦åˆã€æ¨¡å—åŒ–æ¶æ„è®¾è®¡ã€‚
"""

# éœ€æ±‚å…³è”åˆ†æå·¥å…·
@mcp.tool()
def analyze_requirement_relationships() -> str:
    """åˆ†æéœ€æ±‚å…³è”å…³ç³»å’Œæ¶æ„å½±å“ - æ”¯æ’‘æ¨¡å—åŒ–è®¾è®¡"""

    structured_reqs = current_requirements["structured_requirements"]
    relationships = current_requirements["requirement_relationships"]

    if not structured_reqs:
        return "æš‚æ— ç»“æ„åŒ–éœ€æ±‚æ•°æ®ï¼Œè¯·å…ˆä½¿ç”¨ requirement_manager æ·»åŠ éœ€æ±‚ã€‚"

    # åˆ†ææ¨¡å—å½±å“åˆ†å¸ƒ
    module_impact_analysis = _analyze_module_impacts(structured_reqs)

    # åˆ†æéœ€æ±‚å…³è”ç½‘ç»œ
    relationship_analysis = _analyze_relationship_network(structured_reqs, relationships)

    # ç”Ÿæˆæ¨¡å—åŒ–è®¾è®¡å»ºè®®
    modularity_suggestions = _generate_modularity_suggestions(module_impact_analysis, relationship_analysis)

    return f"""# ğŸ”— éœ€æ±‚å…³è”åˆ†ææŠ¥å‘Š

## ğŸ“Š æ¨¡å—å½±å“åˆ†æ
{module_impact_analysis}

## ğŸŒ éœ€æ±‚å…³è”ç½‘ç»œ
{relationship_analysis}

## ğŸ—ï¸ æ¨¡å—åŒ–è®¾è®¡å»ºè®®
{modularity_suggestions}

## ğŸ’¡ æ¶æ„è®¾è®¡æŒ‡å¯¼
åŸºäºéœ€æ±‚å…³è”åˆ†æï¼Œå»ºè®®é‡‡ç”¨ä»¥ä¸‹æ¶æ„åŸåˆ™ï¼š
- **é«˜å†…èš**: ç›¸å…³éœ€æ±‚å½’å¹¶åˆ°åŒä¸€æ¨¡å—
- **ä½è€¦åˆ**: å‡å°‘æ¨¡å—é—´çš„å¼ºä¾èµ–å…³ç³»
- **å•ä¸€èŒè´£**: æ¯ä¸ªæ¨¡å—ä¸“æ³¨ç‰¹å®šçš„ä¸šåŠ¡é¢†åŸŸ
- **æ¥å£éš”ç¦»**: é€šè¿‡æ¸…æ™°çš„æ¥å£å®šä¹‰æ¨¡å—è¾¹ç•Œ

---
ğŸ“‹ **ä½¿ç”¨å»ºè®®**: æ­¤åˆ†æç»“æœå¯ç›´æ¥ç”¨äºæ¶æ„è®¾è®¡é˜¶æ®µçš„æ¨¡å—åˆ’åˆ†å’Œæ¥å£è®¾è®¡ã€‚
"""

def _analyze_module_impacts(structured_reqs: dict) -> str:
    """åˆ†ææ¨¡å—å½±å“åˆ†å¸ƒ"""
    module_counts = {}
    module_requirements = {}

    for req_id, entity in structured_reqs.items():
        if isinstance(entity, dict):
            impacts = entity.get("impacts", [])
        else:
            impacts = entity.impacts

        for impact in impacts:
            module_counts[impact] = module_counts.get(impact, 0) + 1
            if impact not in module_requirements:
                module_requirements[impact] = []
            module_requirements[impact].append(req_id)

    if not module_counts:
        return "æš‚æ— æ¨¡å—å½±å“æ•°æ®"

    analysis = "### æ¨¡å—å½±å“ç»Ÿè®¡\n"
    for module, count in sorted(module_counts.items(), key=lambda x: x[1], reverse=True):
        analysis += f"- **{module}**: {count} ä¸ªéœ€æ±‚\n"
        # æ˜¾ç¤ºç›¸å…³éœ€æ±‚ID
        req_ids = module_requirements[module][:3]  # æœ€å¤šæ˜¾ç¤º3ä¸ª
        analysis += f"  - ç›¸å…³éœ€æ±‚: {', '.join(req_ids)}\n"

    return analysis

def _analyze_relationship_network(structured_reqs: dict, relationships: list) -> str:
    """åˆ†æéœ€æ±‚å…³è”ç½‘ç»œ"""
    if not relationships:
        return "æš‚æ— éœ€æ±‚å…³è”å…³ç³»"

    # ç»Ÿè®¡å…³è”åº¦
    connection_counts = {}
    for relationship in relationships:
        from_id = relationship["from_id"]
        to_id = relationship["to_id"]
        connection_counts[from_id] = connection_counts.get(from_id, 0) + 1
        connection_counts[to_id] = connection_counts.get(to_id, 0) + 1

    # æ‰¾å‡ºå…³è”åº¦æœ€é«˜çš„éœ€æ±‚
    top_connected = sorted(connection_counts.items(), key=lambda x: x[1], reverse=True)[:5]

    analysis = "### éœ€æ±‚å…³è”ç»Ÿè®¡\n"
    analysis += f"- **æ€»å…³è”å…³ç³»**: {len(relationships)} ä¸ª\n"
    analysis += f"- **æ¶‰åŠéœ€æ±‚**: {len(connection_counts)} ä¸ª\n\n"

    analysis += "### é«˜å…³è”åº¦éœ€æ±‚\n"
    for req_id, count in top_connected:
        analysis += f"- **{req_id}**: {count} ä¸ªå…³è”\n"

    return analysis

def _generate_modularity_suggestions(module_analysis: str, relationship_analysis: str) -> str:
    """ç”Ÿæˆæ¨¡å—åŒ–è®¾è®¡å»ºè®®"""
    suggestions = []

    # åŸºäºæ¨¡å—å½±å“åˆ†æçš„å»ºè®®
    if "user_interface" in module_analysis and "business_logic" in module_analysis:
        suggestions.append("å»ºè®®é‡‡ç”¨ MVC æˆ– MVVM æ¶æ„æ¨¡å¼ï¼Œåˆ†ç¦»ç•Œé¢å’Œä¸šåŠ¡é€»è¾‘")

    if "data_layer" in module_analysis:
        suggestions.append("å»ºè®®è®¾è®¡ç‹¬ç«‹çš„æ•°æ®è®¿é—®å±‚ï¼Œä½¿ç”¨ Repository æ¨¡å¼")

    if "api_layer" in module_analysis:
        suggestions.append("å»ºè®®è®¾è®¡ RESTful API å±‚ï¼Œæä¾›ç»Ÿä¸€çš„æœåŠ¡æ¥å£")

    if "security" in module_analysis:
        suggestions.append("å»ºè®®è®¾è®¡ç‹¬ç«‹çš„å®‰å…¨æ¨¡å—ï¼Œå¤„ç†è®¤è¯å’Œæˆæƒ")

    # åŸºäºå…³è”å…³ç³»çš„å»ºè®®
    if "é«˜å…³è”åº¦éœ€æ±‚" in relationship_analysis:
        suggestions.append("é«˜å…³è”åº¦éœ€æ±‚å»ºè®®å½’å¹¶åˆ°åŒä¸€æ¨¡å—ï¼Œå‡å°‘æ¨¡å—é—´é€šä¿¡")

    if not suggestions:
        suggestions.append("åŸºäºå½“å‰éœ€æ±‚åˆ†æï¼Œå»ºè®®é‡‡ç”¨åˆ†å±‚æ¶æ„è®¾è®¡")

    return "\n".join(f"- {suggestion}" for suggestion in suggestions)

def _generate_requirement_update_report(category: str, storage_category: str, content: str) -> str:
    """ç”Ÿæˆéœ€æ±‚æ›´æ–°æŠ¥å‘Š"""
    # ç»Ÿè®¡ä¿¡æ¯
    total_requirements = sum(len(current_requirements[key]) for key in [
        "project_overview", "functional_requirements", "technical_requirements",
        "design_requirements", "deployment_requirements", "ai_constraints"
    ])

    # æ™ºèƒ½ä¸‹ä¸€æ­¥å»ºè®®
    next_steps = _generate_intelligent_next_steps()

    return f"""# âœ… éœ€æ±‚æ–‡æ¡£æ™ºèƒ½æ›´æ–°å®Œæˆ

## ğŸ“ æ›´æ–°è¯¦æƒ…
- **åŸå§‹ç±»åˆ«**: {category}
- **æ™ºèƒ½åˆ†ç±»**: {storage_category}
- **å†…å®¹**: {content}
- **æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š å½“å‰éœ€æ±‚çŠ¶æ€
- **æ€»éœ€æ±‚æ¡ç›®**: {total_requirements}
- **é¡¹ç›®æ¦‚è¿°**: {len(current_requirements['project_overview'])} æ¡
- **åŠŸèƒ½éœ€æ±‚**: {len(current_requirements['functional_requirements'])} æ¡
- **æŠ€æœ¯éœ€æ±‚**: {len(current_requirements['technical_requirements'])} æ¡
- **è®¾è®¡éœ€æ±‚**: {len(current_requirements['design_requirements'])} æ¡

## ğŸ¯ æ™ºèƒ½å»ºè®®
{next_steps}

## ğŸ’¾ å­˜å‚¨ä¿¡æ¯
- âœ… éœ€æ±‚å·²ä¿å­˜: `{storage.requirements_file}`
- âœ… å†å²å·²è®°å½•: `{storage.history_file}`
"""

def _generate_intelligent_next_steps() -> str:
    """ç”Ÿæˆæ™ºèƒ½åŒ–çš„ä¸‹ä¸€æ­¥å»ºè®®"""
    # ä½¿ç”¨ç°æœ‰çš„åˆ†æ”¯å®Œæ•´æ€§æ£€æŸ¥
    branch_status = IntelligentClarificationEngine.check_branch_completeness(current_requirements)

    suggestions = []

    # åŸºäºåˆ†æ”¯çŠ¶æ€ç»™å‡ºå»ºè®®
    if "project_goals" in branch_status['incomplete_branches']:
        suggestions.append("ğŸ“‹ å»ºè®®æ¾„æ¸…é¡¹ç›®ç›®æ ‡å’Œç”¨æˆ·ç¾¤ä½“")

    if "functional_design" in branch_status['incomplete_branches']:
        suggestions.append("âš™ï¸ å»ºè®®è¯¦ç»†æ¾„æ¸…æ ¸å¿ƒåŠŸèƒ½è®¾è®¡")

    if "technical_preferences" in branch_status['incomplete_branches']:
        suggestions.append("ğŸ”§ å»ºè®®æ¾„æ¸…æŠ€æœ¯æ ˆåå¥½å’Œæ€§èƒ½è¦æ±‚")

    if "ui_design" in branch_status['incomplete_branches']:
        suggestions.append("ğŸ¨ å»ºè®®æ¾„æ¸…UI/UXè®¾è®¡åå¥½")

    # å¦‚æœæ‰€æœ‰åˆ†æ”¯å®Œæˆï¼Œå»ºè®®æ¶æ„è®¾è®¡
    if branch_status['all_complete']:
        suggestions.append("ğŸ—ï¸ æ‰€æœ‰éœ€æ±‚åˆ†æ”¯å·²å®Œæˆï¼Œå¯ä»¥å¼€å§‹æ¶æ„è®¾è®¡")
    else:
        suggestions.append(f"â³ å®Œæˆåº¦ï¼š{branch_status['completion_rate']:.0%}ï¼Œç»§ç»­å®Œå–„æœªå®Œæˆåˆ†æ”¯")

    return "\n".join(f"- {suggestion}" for suggestion in suggestions) if suggestions else "- ç»§ç»­ä½¿ç”¨ requirement_clarifier å®Œå–„éœ€æ±‚ä¿¡æ¯"

# æ™ºèƒ½æ¶æ„è®¾è®¡æ¨¡å—
class IntelligentArchitectureDesigner:
    """æ™ºèƒ½æ¶æ„è®¾è®¡å™¨ - åŸºäºéœ€æ±‚ç”Ÿæˆå®šåˆ¶åŒ–æ¶æ„æ–¹æ¡ˆ"""

    @staticmethod
    def analyze_requirements_for_architecture(requirements: dict) -> dict:
        """åˆ†æéœ€æ±‚å¹¶æå–æ¶æ„å…³é”®ä¿¡æ¯"""
        analysis = {
            "project_type": "web",  # é»˜è®¤
            "complexity_indicators": [],
            "key_features": [],
            "tech_preferences": [],
            "performance_requirements": [],
            "integration_needs": []
        }

        # åˆ†ææ‰€æœ‰éœ€æ±‚å†…å®¹
        all_content = []
        for category in ["project_overview", "functional_requirements", "technical_requirements", "design_requirements"]:
            for item in requirements.get(category, []):
                content = item.get('content', '') if isinstance(item, dict) else str(item)
                all_content.append(content.lower())

        combined_content = " ".join(all_content)

        # è¯†åˆ«é¡¹ç›®ç±»å‹
        if any(keyword in combined_content for keyword in ["api", "åç«¯", "æœåŠ¡"]):
            analysis["project_type"] = "backend"
        elif any(keyword in combined_content for keyword in ["å‰ç«¯", "ç•Œé¢", "ui"]):
            analysis["project_type"] = "frontend"
        elif any(keyword in combined_content for keyword in ["å…¨æ ˆ", "ç½‘ç«™", "å¹³å°"]):
            analysis["project_type"] = "fullstack"

        # è¯†åˆ«å¤æ‚åº¦æŒ‡æ ‡
        complexity_keywords = {
            "high_concurrency": ["é«˜å¹¶å‘", "å¤§é‡ç”¨æˆ·", "å®æ—¶"],
            "data_intensive": ["å¤§æ•°æ®", "æ•°æ®åˆ†æ", "å­˜å‚¨"],
            "ai_integration": ["ai", "æ™ºèƒ½", "æœºå™¨å­¦ä¹ "],
            "microservices": ["å¾®æœåŠ¡", "åˆ†å¸ƒå¼", "é›†ç¾¤"]
        }

        for indicator, keywords in complexity_keywords.items():
            if any(keyword in combined_content for keyword in keywords):
                analysis["complexity_indicators"].append(indicator)

        # æå–å…³é”®åŠŸèƒ½
        feature_keywords = {
            "user_management": ["ç”¨æˆ·", "ç™»å½•", "æ³¨å†Œ", "æƒé™"],
            "content_management": ["å†…å®¹", "å‘å¸ƒ", "ç¼–è¾‘", "ç®¡ç†"],
            "real_time_communication": ["èŠå¤©", "æ¶ˆæ¯", "é€šçŸ¥", "å®æ—¶"],
            "data_processing": ["æ•°æ®å¤„ç†", "åˆ†æ", "ç»Ÿè®¡", "æŠ¥è¡¨"],
            "file_handling": ["æ–‡ä»¶", "ä¸Šä¼ ", "ä¸‹è½½", "å­˜å‚¨"],
            "payment": ["æ”¯ä»˜", "è®¢å•", "äº¤æ˜“", "ç»“ç®—"]
        }

        for feature, keywords in feature_keywords.items():
            if any(keyword in combined_content for keyword in keywords):
                analysis["key_features"].append(feature)

        return analysis

    @staticmethod
    def generate_tech_stack_recommendations(analysis: dict) -> dict:
        """åŸºäºåˆ†æç»“æœç”ŸæˆæŠ€æœ¯æ ˆæ¨è"""
        recommendations = {
            "frontend": [],
            "backend": [],
            "database": [],
            "infrastructure": [],
            "reasoning": []
        }

        # å‰ç«¯æ¨è
        if analysis["project_type"] in ["frontend", "fullstack"]:
            if "real_time_communication" in analysis["key_features"]:
                recommendations["frontend"] = ["React + Socket.io", "Vue 3 + WebSocket"]
                recommendations["reasoning"].append("å®æ—¶é€šä¿¡éœ€æ±‚æ¨èæ”¯æŒWebSocketçš„å‰ç«¯æ¡†æ¶")
            else:
                recommendations["frontend"] = ["React 18", "Vue 3", "Next.js 15"]

        # åç«¯æ¨è
        if analysis["project_type"] in ["backend", "fullstack"]:
            if "high_concurrency" in analysis["complexity_indicators"]:
                recommendations["backend"] = ["FastAPI + Uvicorn", "Node.js + Express", "Go + Gin"]
                recommendations["reasoning"].append("é«˜å¹¶å‘éœ€æ±‚æ¨èé«˜æ€§èƒ½å¼‚æ­¥æ¡†æ¶")
            elif "ai_integration" in analysis["complexity_indicators"]:
                recommendations["backend"] = ["FastAPI", "Django + DRF", "Flask"]
                recommendations["reasoning"].append("AIé›†æˆæ¨èPythonç”Ÿæ€ç³»ç»Ÿ")
            else:
                recommendations["backend"] = ["FastAPI", "Express.js", "Spring Boot"]

        # æ•°æ®åº“æ¨è
        if "data_intensive" in analysis["complexity_indicators"]:
            recommendations["database"] = ["PostgreSQL + Redis", "MongoDB + Redis"]
            recommendations["reasoning"].append("æ•°æ®å¯†é›†å‹åº”ç”¨æ¨èé«˜æ€§èƒ½æ•°æ®åº“ç»„åˆ")
        elif "real_time_communication" in analysis["key_features"]:
            recommendations["database"] = ["PostgreSQL + Redis", "MySQL + Redis"]
            recommendations["reasoning"].append("å®æ—¶é€šä¿¡éœ€è¦ç¼“å­˜æ”¯æŒ")
        else:
            recommendations["database"] = ["PostgreSQL", "MySQL", "SQLite"]

        return recommendations

    @staticmethod
    def generate_module_structure(analysis: dict) -> dict:
        """ç”Ÿæˆæ¨¡å—ç»“æ„å»ºè®®"""
        modules = {
            "core_modules": [],
            "optional_modules": [],
            "integration_modules": []
        }

        # æ ¸å¿ƒæ¨¡å—
        if "user_management" in analysis["key_features"]:
            modules["core_modules"].append({
                "name": "ç”¨æˆ·ç®¡ç†æ¨¡å—",
                "responsibilities": ["ç”¨æˆ·æ³¨å†Œ/ç™»å½•", "æƒé™æ§åˆ¶", "ç”¨æˆ·èµ„æ–™ç®¡ç†"],
                "apis": ["POST /auth/login", "POST /auth/register", "GET /users/profile"]
            })

        if "content_management" in analysis["key_features"]:
            modules["core_modules"].append({
                "name": "å†…å®¹ç®¡ç†æ¨¡å—",
                "responsibilities": ["å†…å®¹CRUD", "å†…å®¹å®¡æ ¸", "å†…å®¹åˆ†ç±»"],
                "apis": ["GET /content", "POST /content", "PUT /content/:id"]
            })

        if "real_time_communication" in analysis["key_features"]:
            modules["core_modules"].append({
                "name": "å®æ—¶é€šä¿¡æ¨¡å—",
                "responsibilities": ["æ¶ˆæ¯æ¨é€", "åœ¨çº¿çŠ¶æ€", "èŠå¤©è®°å½•"],
                "apis": ["WebSocket /ws/chat", "GET /messages", "POST /messages"]
            })

        # å¯é€‰æ¨¡å—
        if "file_handling" in analysis["key_features"]:
            modules["optional_modules"].append({
                "name": "æ–‡ä»¶ç®¡ç†æ¨¡å—",
                "responsibilities": ["æ–‡ä»¶ä¸Šä¼ ", "æ–‡ä»¶å­˜å‚¨", "æ–‡ä»¶è®¿é—®æ§åˆ¶"]
            })

        if "payment" in analysis["key_features"]:
            modules["optional_modules"].append({
                "name": "æ”¯ä»˜æ¨¡å—",
                "responsibilities": ["æ”¯ä»˜å¤„ç†", "è®¢å•ç®¡ç†", "äº¤æ˜“è®°å½•"]
            })

        return modules

# æ¶æ„è®¾è®¡ç”Ÿæˆå™¨å·¥å…·
@mcp.tool()
def architecture_designer(design_focus: str = "full_architecture") -> str:
    """æ™ºèƒ½æ¶æ„è®¾è®¡ç”Ÿæˆå™¨ - åŸºäºéœ€æ±‚åˆ†æç”Ÿæˆå®šåˆ¶åŒ–æ¶æ„æ–¹æ¡ˆ"""

    # æ£€æŸ¥éœ€æ±‚å®Œæ•´æ€§å’ŒAIç†è§£æ·±åº¦
    completeness_check = _check_requirements_completeness()
    if not completeness_check["is_sufficient"]:
        branch_status = completeness_check["branch_status"]
        understanding = completeness_check["understanding_check"]

        return f"""# âš ï¸ éœ€æ±‚ä¿¡æ¯ä¸è¶³æˆ–AIç†è§£æ·±åº¦ä¸å¤Ÿï¼Œæ— æ³•ç”Ÿæˆé«˜è´¨é‡æ¶æ„è®¾è®¡

## ğŸ” å½“å‰çŠ¶æ€åˆ†æ
{completeness_check["status_summary"]}

## ğŸŒ¿ åˆ†æ”¯å®ŒæˆçŠ¶æ€
- **å·²å®Œæˆåˆ†æ”¯**: {len([b for b in ['project_goals', 'functional_design', 'technical_preferences', 'ui_design'] if b not in branch_status['incomplete_branches']])}ä¸ª
- **æœªå®Œæˆåˆ†æ”¯**: {', '.join(branch_status['incomplete_branches']) if branch_status['incomplete_branches'] else 'æ— '}
- **å®Œæˆç‡**: {branch_status['completion_rate']:.0%}

## ğŸ§  AIç†è§£æ·±åº¦è¯„ä¼°
- **ç†è§£æ°´å¹³**: {understanding['confidence_level']}
- **ç½®ä¿¡åº¦**: {understanding['confidence_score']:.0%}
- **å¾…è§£å†³é—®é¢˜**: {chr(10).join(f"  - {q}" for q in understanding['remaining_questions']) if understanding['remaining_questions'] else 'æ— '}

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨
{"è¯·ä½¿ç”¨ requirement_clarifier ç»§ç»­å®Œå–„æœªå®Œæˆçš„åˆ†æ”¯" if branch_status['incomplete_branches'] else "è¯·ä½¿ç”¨ requirement_clarifier æ·±åŒ–éœ€æ±‚ç†è§£"}

**AIè‡ªæ£€ç»“æœ**: æˆ‘å¯¹å½“å‰éœ€æ±‚çš„ç†è§£è¿˜ä¸å¤Ÿæ·±å…¥ï¼Œæ— æ³•ç”Ÿæˆé«˜è´¨é‡çš„æ¶æ„è®¾è®¡ã€‚éœ€è¦æ›´å¤šä¿¡æ¯æ¥ç¡®ä¿æ¶æ„æ–¹æ¡ˆçš„å‡†ç¡®æ€§ã€‚
"""

    # æ™ºèƒ½åˆ†æéœ€æ±‚
    requirements_analysis = IntelligentArchitectureDesigner.analyze_requirements_for_architecture(current_requirements)

    # ç”ŸæˆæŠ€æœ¯æ ˆæ¨è
    tech_recommendations = IntelligentArchitectureDesigner.generate_tech_stack_recommendations(requirements_analysis)

    # ç”Ÿæˆæ¨¡å—ç»“æ„
    module_structure = IntelligentArchitectureDesigner.generate_module_structure(requirements_analysis)

    # ç”Ÿæˆå®šåˆ¶åŒ–æ¶æ„è®¾è®¡
    architecture_design = _generate_customized_architecture_design(
        design_focus, requirements_analysis, tech_recommendations, module_structure
    )

    # ä¿å­˜æ¶æ„è®¾è®¡
    _save_architecture_design(design_focus, architecture_design)

    return architecture_design

def _check_requirements_completeness() -> dict:
    """æ£€æŸ¥éœ€æ±‚å®Œæ•´æ€§ - åŠ¨æ€è¯„ä¼°"""
    branch_status = IntelligentClarificationEngine.check_branch_completeness(current_requirements)

    # åŠ¨æ€è´¨é‡è¯„ä¼°
    quality_check = _dynamic_quality_check()

    # é™ä½é˜ˆå€¼ï¼Œä½¿ç”¨åŠ¨æ€æ ‡å‡†
    min_completion_rate = 0.6  # ä»100%é™ä½åˆ°60%
    min_quality_score = 0.5    # ä»75%é™ä½åˆ°50%

    is_sufficient = (
        branch_status['completion_rate'] >= min_completion_rate and
        quality_check['avg_quality'] >= min_quality_score
    )

    return {
        "is_sufficient": is_sufficient,
        "branch_status": branch_status,
        "quality_check": quality_check,
        "status_summary": f"åˆ†æ”¯å®Œæˆåº¦ï¼š{branch_status['completion_rate']:.0%}ï¼Œå¹³å‡è´¨é‡ï¼š{quality_check['avg_quality']:.0%}"
    }

def _dynamic_quality_check() -> dict:
    """åŠ¨æ€è´¨é‡æ£€æŸ¥ - åŸºäºå†…å®¹è´¨é‡è€Œéæ•°é‡"""

    # è®¡ç®—å„ç±»å‹éœ€æ±‚çš„å¹³å‡è´¨é‡
    type_qualities = {}
    total_quality = 0
    total_count = 0

    for req_type, reqs in [
        ("project_overview", current_requirements["project_overview"]),
        ("functional_requirements", current_requirements["functional_requirements"]),
        ("technical_requirements", current_requirements["technical_requirements"]),
        ("design_requirements", current_requirements["design_requirements"])
    ]:
        if reqs:
            # åŸºäºå†…å®¹é•¿åº¦å’Œå…·ä½“æ€§è¯„ä¼°è´¨é‡
            quality_scores = [_evaluate_requirement_quality(req) for req in reqs]
            avg_quality = sum(quality_scores) / len(quality_scores)
            type_qualities[req_type] = avg_quality
            total_quality += avg_quality * len(reqs)
            total_count += len(reqs)
        else:
            type_qualities[req_type] = 0.0

    avg_quality = total_quality / total_count if total_count > 0 else 0.0

    return {
        "avg_quality": avg_quality,
        "type_qualities": type_qualities,
        "total_requirements": total_count
    }

def _evaluate_requirement_quality(requirement: str) -> float:
    """è¯„ä¼°å•ä¸ªéœ€æ±‚çš„è´¨é‡"""
    if not requirement or len(requirement.strip()) < 10:
        return 0.2

    # åŸºäºé•¿åº¦åˆç†æ€§
    length = len(requirement)
    length_score = 1.0 if 20 <= length <= 200 else 0.6

    # åŸºäºå…·ä½“æ€§ï¼ˆåŒ…å«å…·ä½“è¯æ±‡ï¼‰
    specific_words = ["å…·ä½“", "åŒ…æ‹¬", "æ”¯æŒ", "å®ç°", "æä¾›", "ç®¡ç†", "å¤„ç†"]
    specificity_score = min(sum(1 for word in specific_words if word in requirement) * 0.2, 1.0)

    return (length_score + specificity_score) / 2

def _generate_customized_architecture_design(design_focus: str, analysis: dict, tech_recs: dict, modules: dict) -> str:
    """ç”Ÿæˆå®šåˆ¶åŒ–æ¶æ„è®¾è®¡æ–‡æ¡£"""

    return f"""# ğŸ—ï¸ æ™ºèƒ½å®šåˆ¶æ¶æ„è®¾è®¡æ–¹æ¡ˆ

## ğŸ¯ è®¾è®¡æ¦‚è§ˆ
- **è®¾è®¡é‡ç‚¹**: {design_focus}
- **é¡¹ç›®ç±»å‹**: {analysis['project_type']}
- **å¤æ‚åº¦ç‰¹å¾**: {', '.join(analysis['complexity_indicators']) if analysis['complexity_indicators'] else 'æ ‡å‡†å¤æ‚åº¦'}
- **æ ¸å¿ƒåŠŸèƒ½**: {', '.join(analysis['key_features'])}

## ğŸ§  éœ€æ±‚åˆ†æé©±åŠ¨çš„è®¾è®¡å†³ç­–

### æ¶æ„å¤æ‚åº¦è¯„ä¼°
{_generate_complexity_analysis(analysis)}

### å…³é”®è®¾è®¡åŸåˆ™
1. **éœ€æ±‚é©±åŠ¨**: æ¯ä¸ªæ¶æ„å†³ç­–éƒ½åŸºäºæ˜ç¡®çš„éœ€æ±‚
2. **æ¸è¿›å¼æ‰©å±•**: æ”¯æŒåŠŸèƒ½çš„é€æ­¥å¢åŠ 
3. **AIå‹å¥½å¼€å‘**: æ¨¡å—æ¸…æ™°ï¼Œä¾¿äºAIè¾…åŠ©å¼€å‘
4. **ä½è€¦åˆé«˜å†…èš**: æ¨¡å—é—´ä¾èµ–æœ€å°åŒ–

## ğŸ”§ å®šåˆ¶åŒ–æŠ€æœ¯æ ˆæ¨è

### æ¨èæ–¹æ¡ˆåŠç†ç”±
{_format_tech_recommendations(tech_recs)}

## ğŸ“¦ æ™ºèƒ½æ¨¡å—åˆ’åˆ†

### æ ¸å¿ƒä¸šåŠ¡æ¨¡å—
{_format_module_structure(modules['core_modules'])}

### å¯é€‰æ‰©å±•æ¨¡å—
{_format_module_structure(modules['optional_modules'])}

## ğŸ›ï¸ æ¶æ„æ¨¡å¼å»ºè®®

{_generate_architecture_pattern_recommendation(analysis)}

## ğŸ“… åˆ†é˜¶æ®µå®æ–½è®¡åˆ’

{_generate_implementation_phases(modules)}

## ğŸ¤– AIå¼€å‘ä¼˜åŒ–å»ºè®®

### å¼€å‘é¡ºåºä¼˜åŒ–
1. **å…ˆæ ¸å¿ƒåæ‰©å±•**: ä¼˜å…ˆå®ç°æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
2. **æ¥å£å…ˆè¡Œ**: å…ˆå®šä¹‰æ¸…æ™°çš„æ¨¡å—æ¥å£
3. **æµ‹è¯•é©±åŠ¨**: æ¯ä¸ªæ¨¡å—éƒ½æœ‰å¯¹åº”çš„æµ‹è¯•

### ä»£ç ç»„ç»‡å»ºè®®
```
project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/          # æ ¸å¿ƒä¸šåŠ¡æ¨¡å—
â”‚   â”œâ”€â”€ modules/       # åŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ shared/        # å…±äº«ç»„ä»¶
â”‚   â””â”€â”€ config/        # é…ç½®æ–‡ä»¶
â”œâ”€â”€ tests/             # æµ‹è¯•æ–‡ä»¶
â””â”€â”€ docs/              # æ–‡æ¡£
```

## ğŸ¯ å®æ–½å»ºè®®ä¸é£é™©æé†’

### å…³é”®æˆåŠŸå› ç´ 
- ä¸¥æ ¼æŒ‰ç…§æ¨¡å—è¾¹ç•Œå¼€å‘ï¼Œé¿å…è€¦åˆ
- åŠæ—¶è¿›è¡Œé›†æˆæµ‹è¯•
- ä¿æŒæ–‡æ¡£ä¸ä»£ç åŒæ­¥

### æ½œåœ¨é£é™©ç‚¹
{_identify_potential_risks(analysis)}

---

**ğŸ‰ å®šåˆ¶åŒ–æ¶æ„è®¾è®¡å®Œæˆï¼**

æ­¤æ–¹æ¡ˆåŸºäºæ‚¨çš„å…·ä½“éœ€æ±‚ç”Ÿæˆï¼Œç¡®ä¿æŠ€æœ¯é€‰æ‹©ä¸ä¸šåŠ¡éœ€æ±‚å®Œç¾åŒ¹é…ã€‚

## ğŸ’¾ å­˜å‚¨ä¿¡æ¯
- **æ¶æ„è®¾è®¡å·²ä¿å­˜**: `{storage.requirements_file}`
- **å®Œæ•´æ–‡æ¡£å¯¼å‡º**: ä½¿ç”¨ `export_final_document` å·¥å…·
"""

def _generate_complexity_analysis(analysis: dict) -> str:
    """ç”Ÿæˆå¤æ‚åº¦åˆ†æ"""
    if not analysis['complexity_indicators']:
        return "- **æ ‡å‡†å¤æ‚åº¦**: é€‚åˆä¼ ç»Ÿçš„ä¸‰å±‚æ¶æ„æ¨¡å¼"

    complexity_desc = {
        "high_concurrency": "é«˜å¹¶å‘å¤„ç†éœ€æ±‚ï¼Œéœ€è¦å¼‚æ­¥æ¶æ„å’Œç¼“å­˜ç­–ç•¥",
        "data_intensive": "æ•°æ®å¯†é›†å‹åº”ç”¨ï¼Œéœ€è¦ä¼˜åŒ–æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢",
        "ai_integration": "AIåŠŸèƒ½é›†æˆï¼Œéœ€è¦è€ƒè™‘æ¨¡å‹æœåŠ¡åŒ–å’ŒAPIè®¾è®¡",
        "microservices": "å¾®æœåŠ¡æ¶æ„éœ€æ±‚ï¼Œéœ€è¦æœåŠ¡æ‹†åˆ†å’Œæ²»ç†"
    }

    return "\n".join(f"- **{indicator}**: {complexity_desc.get(indicator, 'éœ€è¦ç‰¹æ®Šè€ƒè™‘')}"
                    for indicator in analysis['complexity_indicators'])

def _format_tech_recommendations(tech_recs: dict) -> str:
    """æ ¼å¼åŒ–æŠ€æœ¯æ¨è"""
    sections = []

    for category, recommendations in tech_recs.items():
        if category == "reasoning" or not recommendations:
            continue

        sections.append(f"**{category.title()}**: {', '.join(recommendations)}")

    if tech_recs.get("reasoning"):
        sections.append("\n**é€‰æ‹©ç†ç”±**:")
        sections.extend(f"- {reason}" for reason in tech_recs["reasoning"])

    return "\n".join(sections)

def _format_module_structure(modules: list) -> str:
    """æ ¼å¼åŒ–æ¨¡å—ç»“æ„"""
    if not modules:
        return "- æš‚æ— ç‰¹å®šæ¨¡å—éœ€æ±‚"

    formatted = []
    for module in modules:
        formatted.append(f"**{module['name']}**")
        formatted.append(f"- èŒè´£: {', '.join(module['responsibilities'])}")
        if 'apis' in module:
            formatted.append(f"- æ¥å£: {', '.join(module['apis'])}")
        formatted.append("")

    return "\n".join(formatted)

def _generate_architecture_pattern_recommendation(analysis: dict) -> str:
    """ç”Ÿæˆæ¶æ„æ¨¡å¼æ¨è"""
    if "microservices" in analysis['complexity_indicators']:
        return """**æ¨èæ¨¡å¼**: å¾®æœåŠ¡æ¶æ„
- æœåŠ¡æŒ‰ä¸šåŠ¡åŸŸæ‹†åˆ†
- ä½¿ç”¨APIç½‘å…³ç»Ÿä¸€å…¥å£
- ç‹¬ç«‹éƒ¨ç½²å’Œæ‰©å±•"""
    elif len(analysis['key_features']) > 4:
        return """**æ¨èæ¨¡å¼**: æ¨¡å—åŒ–å•ä½“æ¶æ„
- æ¸…æ™°çš„æ¨¡å—è¾¹ç•Œ
- å…±äº«æ•°æ®åº“
- ç»Ÿä¸€éƒ¨ç½²"""
    else:
        return """**æ¨èæ¨¡å¼**: åˆ†å±‚æ¶æ„
- è¡¨ç°å±‚ã€ä¸šåŠ¡å±‚ã€æ•°æ®å±‚
- ç®€å•æ¸…æ™°çš„ä¾èµ–å…³ç³»
- æ˜“äºå¼€å‘å’Œç»´æŠ¤"""

def _generate_implementation_phases(modules: dict) -> str:
    """ç”Ÿæˆå®æ–½é˜¶æ®µè®¡åˆ’"""
    phases = []

    phases.append("**ç¬¬ä¸€é˜¶æ®µ (1-2å‘¨)**: åŸºç¡€æ¡†æ¶æ­å»º")
    phases.append("- é¡¹ç›®åˆå§‹åŒ–å’Œç¯å¢ƒé…ç½®")
    phases.append("- æ•°æ®åº“è®¾è®¡å’ŒåŸºç¡€è¡¨ç»“æ„")
    phases.append("- æ ¸å¿ƒæ¨¡å—æ¥å£å®šä¹‰")
    phases.append("")

    if modules['core_modules']:
        phases.append("**ç¬¬äºŒé˜¶æ®µ (2-4å‘¨)**: æ ¸å¿ƒåŠŸèƒ½å¼€å‘")
        for module in modules['core_modules']:
            phases.append(f"- {module['name']}å®ç°")
        phases.append("")

    if modules['optional_modules']:
        phases.append("**ç¬¬ä¸‰é˜¶æ®µ (1-3å‘¨)**: æ‰©å±•åŠŸèƒ½å¼€å‘")
        for module in modules['optional_modules']:
            phases.append(f"- {module['name']}å®ç°")
        phases.append("")

    phases.append("**ç¬¬å››é˜¶æ®µ (1å‘¨)**: é›†æˆæµ‹è¯•å’Œä¼˜åŒ–")
    phases.append("- ç«¯åˆ°ç«¯æµ‹è¯•")
    phases.append("- æ€§èƒ½ä¼˜åŒ–")
    phases.append("- éƒ¨ç½²å‡†å¤‡")

    return "\n".join(phases)

def _identify_potential_risks(analysis: dict) -> str:
    """è¯†åˆ«æ½œåœ¨é£é™©"""
    risks = []

    if "high_concurrency" in analysis['complexity_indicators']:
        risks.append("é«˜å¹¶å‘åœºæ™¯ä¸‹çš„æ€§èƒ½ç“¶é¢ˆ")

    if "ai_integration" in analysis['complexity_indicators']:
        risks.append("AIæ¨¡å‹æœåŠ¡çš„ç¨³å®šæ€§å’Œå“åº”æ—¶é—´")

    if len(analysis['key_features']) > 5:
        risks.append("åŠŸèƒ½å¤æ‚åº¦è¿‡é«˜ï¼Œå¼€å‘å‘¨æœŸå¯èƒ½å»¶é•¿")

    if not risks:
        risks.append("é¡¹ç›®é£é™©è¾ƒä½ï¼ŒæŒ‰è®¡åˆ’å®æ–½å³å¯")

    return "\n".join(f"- {risk}" for risk in risks)

def _save_architecture_design(design_focus: str, architecture_design: str):
    """ä¿å­˜æ¶æ„è®¾è®¡"""
    architecture_entry = {
        "timestamp": datetime.now().isoformat(),
        "design_focus": design_focus,
        "content": architecture_design
    }

    current_requirements["architecture_designs"].append(architecture_entry)

    storage.save_history_entry("architecture_design", architecture_design, {"design_focus": design_focus})
    storage.save_requirements()

# æ–°å¢ï¼šå¯¼å‡ºæœ€ç»ˆæ–‡æ¡£å·¥å…·
@mcp.tool()
def export_final_document() -> str:
    """å¯¼å‡ºå®Œæ•´çš„é¡¹ç›®éœ€æ±‚å’Œæ¶æ„æ–‡æ¡£"""

    export_path = storage.export_final_document()

    if export_path:
        # ç»Ÿè®¡ä¿¡æ¯
        total_clarifications = len(current_requirements.get("clarification_history", []))
        total_requirements = sum(len(current_requirements[key]) for key in [
            "project_overview", "functional_requirements", "technical_requirements",
            "design_requirements", "deployment_requirements", "ai_constraints"
        ])
        total_architectures = len(current_requirements.get("architecture_designs", []))

        result = f"""# ğŸ“„ é¡¹ç›®æ–‡æ¡£å¯¼å‡ºå®Œæˆ

## âœ… å¯¼å‡ºä¿¡æ¯
- **å¯¼å‡ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ–‡ä»¶è·¯å¾„**: `{export_path}`
- **Markdownç‰ˆæœ¬**: `{export_path.replace('.json', '.md')}`

## ğŸ“Š æ–‡æ¡£ç»Ÿè®¡
- **éœ€æ±‚æ¾„æ¸…æ¬¡æ•°**: {total_clarifications}
- **éœ€æ±‚æ¡ç›®æ€»æ•°**: {total_requirements}
- **æ¶æ„è®¾è®¡æ–¹æ¡ˆ**: {total_architectures}

## ğŸ“ å­˜å‚¨ç›®å½•ç»“æ„
```
{storage.storage_dir}/
â”œâ”€â”€ requirements.json      # å®æ—¶éœ€æ±‚æ–‡æ¡£
â”œâ”€â”€ history.json          # æ“ä½œå†å²è®°å½•
â”œâ”€â”€ final_document_*.json # å¯¼å‡ºçš„å®Œæ•´æ–‡æ¡£
â””â”€â”€ final_document_*.md   # Markdownæ ¼å¼æŠ¥å‘Š
```

## ğŸ¯ æ–‡æ¡£ç”¨é€”
- **requirements.json**: å®æ—¶æ›´æ–°çš„ç»“æ„åŒ–éœ€æ±‚æ•°æ®
- **history.json**: å®Œæ•´çš„æ“ä½œå†å²ï¼Œä¾¿äºè¿½æº¯
- **final_document_*.json**: å®Œæ•´é¡¹ç›®æ–‡æ¡£ï¼ŒåŒ…å«æ‰€æœ‰ä¿¡æ¯
- **final_document_*.md**: äººç±»å¯è¯»çš„MarkdownæŠ¥å‘Š

## ğŸ’¡ ä½¿ç”¨å»ºè®®
1. å°†å¯¼å‡ºçš„æ–‡æ¡£ä¿å­˜åˆ°é¡¹ç›®ä»“åº“ä¸­
2. ä½¿ç”¨Markdownæ–‡ä»¶ä½œä¸ºé¡¹ç›®READMEçš„åŸºç¡€
3. JSONæ–‡ä»¶å¯ç”¨äºåç»­çš„è‡ªåŠ¨åŒ–å¤„ç†

**ğŸ‰ é¡¹ç›®æ–‡æ¡£å·²å®Œæ•´ä¿å­˜ï¼Œå¯ä»¥å¼€å§‹å¼€å‘äº†ï¼**
"""
    else:
        result = """# âŒ æ–‡æ¡£å¯¼å‡ºå¤±è´¥

è¯·æ£€æŸ¥å­˜å‚¨ç›®å½•æƒé™å’Œç£ç›˜ç©ºé—´ã€‚

**å­˜å‚¨ç›®å½•**: `{storage.storage_dir}`
"""

    return result

# æ–°å¢ï¼šæŸ¥çœ‹å½“å‰éœ€æ±‚çŠ¶æ€å·¥å…·
@mcp.tool()
def view_requirements_status() -> str:
    """æŸ¥çœ‹å½“å‰éœ€æ±‚æ–‡æ¡£çš„è¯¦ç»†çŠ¶æ€å’Œå†…å®¹"""

    # ç»Ÿè®¡ä¿¡æ¯
    total_clarifications = len(current_requirements.get("clarification_history", []))
    total_requirements = sum(len(current_requirements[key]) for key in [
        "project_overview", "functional_requirements", "technical_requirements",
        "design_requirements", "deployment_requirements", "ai_constraints"
    ])
    total_architectures = len(current_requirements.get("architecture_designs", []))

    # æ„å»ºçŠ¶æ€æŠ¥å‘Š
    status_report = f"""# ğŸ“‹ å½“å‰éœ€æ±‚æ–‡æ¡£çŠ¶æ€

## ğŸ“Š æ€»ä½“ç»Ÿè®¡
- **æœ€åæ›´æ–°**: {current_requirements.get('last_updated', 'æœªæ›´æ–°')}
- **éœ€æ±‚æ¾„æ¸…æ¬¡æ•°**: {total_clarifications}
- **éœ€æ±‚æ¡ç›®æ€»æ•°**: {total_requirements}
- **æ¶æ„è®¾è®¡æ–¹æ¡ˆ**: {total_architectures}
- **å­˜å‚¨ä½ç½®**: `{storage.storage_dir}`

## ğŸ“ éœ€æ±‚åˆ†ç±»è¯¦æƒ…

### ğŸ¯ é¡¹ç›®æ¦‚è¿° ({len(current_requirements['project_overview'])} æ¡)
"""

    # æ·»åŠ é¡¹ç›®æ¦‚è¿°
    for i, item in enumerate(current_requirements['project_overview'], 1):
        content = item['content'] if isinstance(item, dict) else str(item)
        status_report += f"{i}. {content[:100]}{'...' if len(content) > 100 else ''}\n"

    status_report += f"""
### âš™ï¸ åŠŸèƒ½éœ€æ±‚ ({len(current_requirements['functional_requirements'])} æ¡)
"""

    # æ·»åŠ åŠŸèƒ½éœ€æ±‚
    for i, item in enumerate(current_requirements['functional_requirements'], 1):
        content = item['content'] if isinstance(item, dict) else str(item)
        status_report += f"{i}. {content[:100]}{'...' if len(content) > 100 else ''}\n"

    status_report += f"""
### ğŸ”§ æŠ€æœ¯éœ€æ±‚ ({len(current_requirements['technical_requirements'])} æ¡)
"""

    # æ·»åŠ æŠ€æœ¯éœ€æ±‚
    for i, item in enumerate(current_requirements['technical_requirements'], 1):
        content = item['content'] if isinstance(item, dict) else str(item)
        status_report += f"{i}. {content[:100]}{'...' if len(content) > 100 else ''}\n"

    status_report += f"""
### ğŸ—ï¸ æ¶æ„è®¾è®¡ ({len(current_requirements['architecture_designs'])} ä¸ª)
"""

    # æ·»åŠ æ¶æ„è®¾è®¡
    for i, design in enumerate(current_requirements['architecture_designs'], 1):
        focus = design.get('design_focus', 'æœªæŒ‡å®š') if isinstance(design, dict) else 'æœªæŒ‡å®š'
        timestamp = design.get('timestamp', 'æœªçŸ¥æ—¶é—´') if isinstance(design, dict) else 'æœªçŸ¥æ—¶é—´'
        status_report += f"{i}. è®¾è®¡é‡ç‚¹: {focus} (ç”Ÿæˆæ—¶é—´: {timestamp[:19]})\n"

    status_report += f"""
## ğŸ“ æ–‡ä»¶ä¿¡æ¯
- **éœ€æ±‚æ–‡æ¡£**: `{storage.requirements_file}`
- **å†å²è®°å½•**: `{storage.history_file}`
- **æ–‡ä»¶å¤§å°**: éœ€æ±‚æ–‡æ¡£ {storage.requirements_file.stat().st_size if storage.requirements_file.exists() else 0} å­—èŠ‚

## ğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®
"""

    if total_requirements < 3:
        status_report += "- ğŸ“ éœ€æ±‚ä¿¡æ¯è¾ƒå°‘ï¼Œå»ºè®®ç»§ç»­ä½¿ç”¨ requirement_clarifier æ¾„æ¸…æ›´å¤šéœ€æ±‚\n"

    if total_architectures == 0:
        status_report += "- ğŸ—ï¸ å°šæœªç”Ÿæˆæ¶æ„è®¾è®¡ï¼Œå»ºè®®ä½¿ç”¨ architecture_designer ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆ\n"

    if total_requirements >= 3 and total_architectures >= 1:
        status_report += "- ğŸ“„ éœ€æ±‚å’Œæ¶æ„å·²åŸºæœ¬å®Œå–„ï¼Œå¯ä»¥ä½¿ç”¨ export_final_document å¯¼å‡ºå®Œæ•´æ–‡æ¡£\n"
        status_report += "- ğŸš€ å¯ä»¥å¼€å§‹é¡¹ç›®å¼€å‘äº†ï¼\n"

    status_report += """
## ğŸ› ï¸ å¯ç”¨å·¥å…·
- `requirement_clarifier`: æ¾„æ¸…å’Œåˆ†æéœ€æ±‚
- `requirement_manager`: ç®¡ç†å’Œä¿å­˜éœ€æ±‚
- `architecture_designer`: ç”Ÿæˆæ¶æ„è®¾è®¡
- `export_final_document`: å¯¼å‡ºå®Œæ•´æ–‡æ¡£
- `view_requirements_status`: æŸ¥çœ‹å½“å‰çŠ¶æ€ï¼ˆå½“å‰å·¥å…·ï¼‰
"""

    return status_report

if __name__ == "__main__":
    logger.info("ğŸš€ å¯åŠ¨AIéœ€æ±‚åˆ†æå’Œè®¾è®¡åŠ©æ‰‹")
    mcp.run()