{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Started w/ circle_routing_11.ipynb -- consolidation & fixing it up\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy  as np\n",
    "import networkx as nx\n",
    "import random\n",
    "from rtsvg import *\n",
    "rt = RACETrack()\n",
    "my_df = pl.DataFrame({\n",
    "    'fm':'a b c d e f g h i j k l m n o a b c d e f g h i j k l m n o h h'.split(),\n",
    "    'to':'b c d e f g h i j k l m n o a c d d c b b k l k l l m n m m j k'.split()})\n",
    "my_pos = {'m': (4.756287622381761, -4.648929693706887),\n",
    " 'n': (5.8766434111262935, 3.9477905470719783),\n",
    " 'o': (2.8740898972909434, 3.8082334003060865),\n",
    " 'a': (1.6626394716232904, 2.0848839532480787),\n",
    " 'c': (-0.5933891572168369, 2.5998077658181966),\n",
    " 'd': (-4.654701003072322, 3.9198791177188),\n",
    " 'b': (-0.29669457860841847, 1.2999038829090983),\n",
    " 'h': (-6.006459119349462, -2.892558260783717),\n",
    " 'l': (-1.7193688365616442, -4.7605754111196),\n",
    " 'i': (-3.8928590667260394, -2.946332503163021),\n",
    " 'j': (-2.660467699107052, -3.4766496608734054),\n",
    " 'k': (-1.764183068111426, -2.3043696280399235),\n",
    " 'g': (-1.4952976788127375, -0.7692410136151269),\n",
    " 'e': (-5.618206981392621, 3.5849419654806614),\n",
    " 'f': (-1.2936336368387211, 0.45886187792471134)}\n",
    "#_rtg_ = rt.interactiveGraphLayout(df, {'draw_labels':True, 'pos':pos, 'relationships':[('fm','to')]})\n",
    "#_rtg_\n",
    "_my_link_ = rt.link(my_df, draw_labels=True, pos=my_pos, relationships=[('fm','to')], w=384, h=384, bounds_percent=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donutLinkNodeOverlap(df, relationships, pos, k=6, iters=100, w=384, h=384, bounds_percent=0.2):\n",
    "    # Create a link for transformation information\n",
    "    _link_ = rt.link(df, relationships=relationships, pos=pos, w=w, h=h, bounds_percent=bounds_percent)\n",
    "    _link_.renderSVG() # force the rendering and related transformations to occur\n",
    "\n",
    "    # Flatten the nodes out -- assumes that all nodes (and only nodes) are in the pos dictionary\n",
    "    _node_ls_  = list(pos.keys())\n",
    "    _node_to_i_ = {}\n",
    "    for i in range(len(_node_ls_)): _node_to_i_[_node_ls_[i]] = i\n",
    "    _node_sxy_ = []\n",
    "    for _node_ in _node_ls_: \n",
    "        sx, sy = _link_.xT(pos[_node_][0]), _link_.yT(pos[_node_][1])\n",
    "        _node_sxy_.append((sx, sy))\n",
    "    sx_min, sx_max, sy_min, sy_max = sx, sx, sy, sy\n",
    "    for _node_ in _node_ls_:\n",
    "        sx_min, sx_max = min(sx_min, sx), max(sx_max, sx)\n",
    "        sy_min, sy_max = min(sy_min, sy), max(sy_max, sy)\n",
    "\n",
    "    # Make random cluster centers\n",
    "    cluster_centers = {}\n",
    "    for i in range(k): \n",
    "        sx, sy = random.random() * (sx_max - sx_min) + sx_min, random.random() * (sy_max - sy_min) + sy_min\n",
    "        cluster_centers[i] = (sx, sy)\n",
    "\n",
    "    # Iterate K-Means\n",
    "    for _iter_ in range(iters):\n",
    "        # Assign nodes to their closest center\n",
    "        center_assignments = {}\n",
    "        for j in range(len(_node_ls_)):\n",
    "            _node_ = _node_ls_[j]\n",
    "            min_dist       = (_node_sxy_[j][0] - cluster_centers[0][0])**2 + (_node_sxy_[j][1] - cluster_centers[0][1])**2\n",
    "            closest_center = 0\n",
    "            for i in range(1, k):\n",
    "                dist = (_node_sxy_[j][0] - cluster_centers[i][0])**2 + (_node_sxy_[j][1] - cluster_centers[i][1])**2\n",
    "                if dist < min_dist:\n",
    "                    min_dist       = dist\n",
    "                    closest_center = i\n",
    "            if closest_center not in center_assignments: center_assignments[closest_center] = []\n",
    "            center_assignments[closest_center].append(_node_)\n",
    "        # If there are any centers without nodes, assign a random node to them\n",
    "        for i in range(k): \n",
    "            if i not in center_assignments: center_assignments[i] = [random.choice(_node_ls_)]\n",
    "        # Update centers\n",
    "        for i in range(k): \n",
    "            sx, sy = 0, 0\n",
    "            for _node_ in center_assignments[i]: \n",
    "                sx, sy = sx + _node_sxy_[_node_to_i_[_node_]][0], sy + _node_sxy_[_node_to_i_[_node_]][1]\n",
    "            cluster_centers[i] = (sx/len(center_assignments[i]), sy/len(center_assignments[i]))\n",
    "\n",
    "    # Track nodes to their cluster centers\n",
    "    node_to_cluster_center = {}\n",
    "    for i in center_assignments:\n",
    "        for _node_ in center_assignments[i]: \n",
    "            node_to_cluster_center[_node_] = i\n",
    "\n",
    "    # Create the Voronoi diagram from the cluster centers\n",
    "    voronoi_pts = []\n",
    "    for i in cluster_centers: voronoi_pts.append(cluster_centers[i])\n",
    "    nborhoods = rt.isedgarVoronoi(voronoi_pts, Box=[(0,_link_.h),(_link_.w,_link_.h),(_link_.w,0),(0,0)])\n",
    "\n",
    "    # Determine the degree information for each node (in and out degree)\n",
    "    _fm_, _to_         = relationships[0][0], relationships[0][1]\n",
    "    _fms_, _tos_       = df[_fm_], df[_to_]\n",
    "    _fm_ext_, _to_ext_ = [], []\n",
    "    _fm_ext_.extend(_fms_), _to_ext_.extend(_tos_)\n",
    "    _fm_ext_.extend(_tos_), _to_ext_.extend(_fms_)\n",
    "    df_degree = pl.DataFrame({_fm_:_fm_ext_, _to_:_to_ext_})\n",
    "    df_degree = df_degree.with_columns(pl.col(_to_).replace_strict(node_to_cluster_center).alias('to_cluster'))\n",
    "\n",
    "    df_cluster_counter = rt.polarsCounter(df_degree, [_fm_,'to_cluster'], _to_, count_by_set=True)\n",
    "\n",
    "    # Uniform color ordering\n",
    "    color_order = rt.colorRenderOrder(df_degree, 'to_cluster', _to_, count_by_set=True)\n",
    "\n",
    "    _svg_ = [f'<svg x=\"0\" y=\"0\" width=\"{_link_.w}\" height=\"{_link_.h}\">']\n",
    "    _svg_.append('<g opacity=\"0.5\">')\n",
    "    for _poly_i_ in range(len(nborhoods)):\n",
    "        center_xy = cluster_centers[_poly_i_]\n",
    "        _poly_ = nborhoods[_poly_i_]\n",
    "        d = f'M {_poly_[0][0]} {_poly_[0][1]}  '\n",
    "        for i in range(1, len(_poly_)): d += f'L {_poly_[i][0]} {_poly_[i][1]} '\n",
    "        d += 'Z'\n",
    "        _svg_.append(f'<path d=\"{d}\" fill=\"{rt.co_mgr.getColor(_poly_i_)}\" />')\n",
    "        # _svg_.append(f'<text x=\"{center_xy[0]}\" y=\"{center_xy[1]}\" stroke=\"#ff0000\" text-anchor=\"middle\">{_poly_i_}</text>')\n",
    "    _svg_.append('</g>')\n",
    "\n",
    "    for i in center_assignments:\n",
    "        _nodes_ = set(center_assignments[i])\n",
    "        _df_    = df_cluster_counter.filter(pl.col(_fm_).is_in(_nodes_))\n",
    "        for _node_ in _nodes_: \n",
    "            sx, sy = _link_.xT(pos[_node_][0]), _link_.yT(pos[_node_][1])\n",
    "            _df_node_ = _df_.filter(pl.col(_fm_) == _node_)\n",
    "            _within_  = _df_node_.filter(pl.col('to_cluster') == i)\n",
    "            _without_ = _df_node_.filter(pl.col('to_cluster') != i)\n",
    "            _ratio_intras_ = 0.0\n",
    "            if len(_within_) > 0: _ratio_intras_ = float(_within_['__count__'][0]) / max(len(_nodes_)-1, 1)\n",
    "            glyph_svg = rt.concentricGlyph(_without_, sx, sy, 0.0, _ratio_intras_, order=color_order, nbor='to_cluster', count_by='__count__')\n",
    "            _svg_.append(glyph_svg)\n",
    "    _svg_.append('</svg>')\n",
    "    return ''.join(_svg_)\n",
    "\n",
    "rt.tile([donutLinkNodeOverlap(my_df, [('fm','to')], my_pos), _my_link_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pl.DataFrame({'fm':['n', 'n'], 'to_cluster':[3, 4], '__count__':[1, 2]})\n",
    "df_test = pl.DataFrame({'fm':['n'], 'to_cluster':[4], '__count__':[10]})\n",
    "rt.tile([\n",
    "'<svg x=\"0\" y=\"0\" width=\"128\" height=\"128\">' + \n",
    "'<rect width=\"128\" height=\"128\" x=\"0\" y=\"0\" fill=\"#101010\" stroke=\"#ffffff\" />' +\n",
    "rt.concentricGlyph(df_test, 64, 64, 0.6, 0.5, r_min=32.0, r_max=64.0, nbor='to_cluster', count_by='__count__') +\n",
    "'</svg>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_filename  = '../../data/stanford/facebook/348.edges'\n",
    "_lu_ = {'fm':[], 'to':[]}\n",
    "for _edge_ in open(edges_filename, 'rt').read().split('\\n'):\n",
    "    if _edge_ == '': continue\n",
    "    _split_     = _edge_.split()\n",
    "    _fm_, _to_  = int(_split_[0]), int(_split_[1])\n",
    "    _lu_['fm'].append(_fm_), _lu_['to'].append(_to_)\n",
    "df  = pl.DataFrame(_lu_)\n",
    "g   = rt.createNetworkXGraph(df, [('fm','to')])\n",
    "#pos = nx.spring_layout(g)\n",
    "#pos = rt.hyperTreeLayout(g)\n",
    "pos = nx.kamada_kawai_layout(g)\n",
    "params = {'df':df, 'relationships':[('fm','to')], 'pos':pos, 'w':512, 'h':512}\n",
    "rt.tile([donutLinkNodeOverlap(**params), rt.link(**params)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
