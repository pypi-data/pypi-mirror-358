{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy  as np\n",
    "import networkx as nx\n",
    "from math import pi, cos, sin, sqrt, atan2\n",
    "import random\n",
    "from os.path import exists\n",
    "from rtsvg import *\n",
    "rt = RACETrack()\n",
    "# Load the data\n",
    "edges_filename  = '../../data/stanford/facebook/1912.edges'\n",
    "_lu_ = {'fm':[], 'to':[]}\n",
    "for _edge_ in open(edges_filename, 'rt').read().split('\\n'):\n",
    "    if _edge_ == '': continue\n",
    "    _split_     = _edge_.split()\n",
    "    _fm_, _to_  = int(_split_[0]), int(_split_[1])\n",
    "    _lu_['fm'].append(_fm_), _lu_['to'].append(_to_)\n",
    "my_df             = pl.DataFrame(_lu_)\n",
    "\n",
    "_to_remove_ = set([428, 563, 1967]) # for 1912 graph\n",
    "my_df = my_df.filter(~pl.col('fm').is_in(_to_remove_) & ~pl.col('to').is_in(_to_remove_))\n",
    "\n",
    "g                 = rt.createNetworkXGraph(my_df, [('fm','to')])\n",
    "degree_sorter     = []\n",
    "for _node_ in g.nodes(): degree_sorter.append((g.degree[_node_], _node_))\n",
    "degree_sorter.sort(reverse=True)\n",
    "high_degree_nodes = set([_node_[1] for _node_ in degree_sorter[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the communities\n",
    "df_minus_high_degree_nodes = my_df.filter(~pl.col('fm').is_in(high_degree_nodes) & ~pl.col('to').is_in(high_degree_nodes))\n",
    "g_minus_high_degree_nodes  = rt.createNetworkXGraph(df_minus_high_degree_nodes, [('fm','to')])\n",
    "communities       = nx.community.louvain_communities(g_minus_high_degree_nodes)\n",
    "community_lu      = {}\n",
    "cluster_number    = max(max(my_df['fm']),max(my_df['to'])) + 1000 # needs to be different if nodes are strings\n",
    "for _node_ in high_degree_nodes: \n",
    "    community_lu[cluster_number] = set([_node_])\n",
    "    cluster_number += 1\n",
    "for _community_ in communities:\n",
    "    if len(_community_) <= 8: # if the community it too small, pull those nodes out\n",
    "        for _node_ in _community_:\n",
    "            community_lu[cluster_number] = set([_node_])\n",
    "            cluster_number += 1\n",
    "    else:\n",
    "        community_lu[cluster_number] = set(_community_)\n",
    "        cluster_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse the communities\n",
    "my_df_communities = rt.collapseDataFrameGraphByClusters(my_df, [('fm','to')], community_lu)\n",
    "g_communities     = rt.createNetworkXGraph(my_df_communities, [('__fm__','__to__')])\n",
    "communities_pos   = nx.spring_layout(g_communities)\n",
    "\n",
    "# Find the bounding box and determine the coordinate transforms\n",
    "x_min, y_min, x_max, y_max = rt.positionExtents(communities_pos)\n",
    "w, h         = 900, 900\n",
    "cd_r         = 64\n",
    "x_ins, y_ins = cd_r + 10, cd_r + 10\n",
    "wxToSx       = lambda x: 1.5*cd_r + 5 + (w - 3*cd_r)*(x-x_min)/(x_max-x_min)\n",
    "wyToSy       = lambda y: 1.5*cd_r + 5 + (h - 3*cd_r)*(y-y_min)/(y_max-y_min)\n",
    "\n",
    "# Crunch the circles\n",
    "communities_keys_ordered = sorted(list(community_lu.keys()))\n",
    "circles                  = []\n",
    "for i in range(len(communities_keys_ordered)):\n",
    "    _community_key_ = communities_keys_ordered[i]\n",
    "    sx, sy = wxToSx(communities_pos[_community_key_][0]), wyToSy(communities_pos[_community_key_][1])\n",
    "    if len(community_lu[_community_key_]) == 1: circles.append((sx, sy, 20.0))\n",
    "    else:                                       circles.append((sx, sy, cd_r))\n",
    "\n",
    "circles_adjusted  = rt.crunchCircles(circles)\n",
    "circles_finalized = []\n",
    "\n",
    "# And re-assign back into the pos array -- these again need to be normalized into the screen view\n",
    "for_extent_calculation = {}\n",
    "for i in range(len(circles_adjusted)): for_extent_calculation[i] = circles_adjusted[i][0], circles_adjusted[i][1]\n",
    "x_min, y_min, x_max, y_max = rt.positionExtents(for_extent_calculation)\n",
    "wxToSx       = lambda x: 1.5*cd_r + 5 + (w - 3*cd_r)*(x-x_min)/(x_max-x_min)\n",
    "wyToSy       = lambda y: 1.5*cd_r + 5 + (h - 3*cd_r)*(y-y_min)/(y_max-y_min)\n",
    "_pts_        = []\n",
    "for i in range(len(communities_keys_ordered)):\n",
    "    _community_key_ = communities_keys_ordered[i]\n",
    "    sx,sy = wxToSx(circles_adjusted[i][0]), wyToSy(circles_adjusted[i][1])\n",
    "    circles_finalized.append((sx, sy, circles_adjusted[i][2]))\n",
    "    communities_pos[_community_key_] = (sx,sy)\n",
    "    _pts_.append((sx,sy))\n",
    "\n",
    "# Voronoi\n",
    "voronoi_cells = rt.isedgarVoronoi(_pts_, Box=[(0,h),(w,h),(w,0),(0,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = [f'<svg x=\"0\" y=\"0\" width=\"{w}\" height=\"{h}\"><rect x=\"0\" y=\"0\" width=\"{w}\" height=\"{h}\" fill=\"white\" />']\n",
    "\n",
    "# Render the communities as chord diagrams\n",
    "dfs_rendered, _node_to_cd_, _cd_sxy_ = [], {}, {}\n",
    "for _community_ in community_lu:\n",
    "    _df_   = my_df.filter(pl.col('fm').is_in(community_lu[_community_]) & pl.col('to').is_in(community_lu[_community_]))\n",
    "    dfs_rendered.append(_df_)\n",
    "    if len(community_lu[_community_]) == 1:\n",
    "        # sx, sy = wxToSx(communities_pos[_community_][0]), wyToSy(communities_pos[_community_][1])\n",
    "        sx, sy = communities_pos[_community_][0], communities_pos[_community_][1]\n",
    "        _node_ = list(community_lu[_community_])[0]\n",
    "        _cd_sxy_[_node_] = (sx,sy)\n",
    "        svg.append(f'<circle cx=\"{sx}\" cy=\"{sy}\" r=\"4\" stroke=\"black\" stroke-width=\"1.5\" fill=\"black\" />')\n",
    "    else:\n",
    "        _opacity_ = max(0.8 - len(community_lu[_community_])/20.0, 0.02)\n",
    "        _cd_   = rt.chordDiagram(_df_, [('fm', 'to')], w=cd_r*2, h=cd_r*2, x_ins=0, y_ins=0, link_opacity=_opacity_, draw_border=False, node_h=4)\n",
    "        for _node_ in community_lu[_community_]: _node_to_cd_[_node_] = _cd_\n",
    "        # sx, sy = wxToSx(communities_pos[_community_][0]), wyToSy(communities_pos[_community_][1])\n",
    "        sx, sy = communities_pos[_community_][0], communities_pos[_community_][1]\n",
    "        _cd_sxy_[_cd_] = (sx,sy)\n",
    "        svg.append(f'<g transform=\"translate({sx-cd_r}, {sy-cd_r})\">{_cd_._repr_svg_()}</g>')\n",
    "\n",
    "# Determine the edges between the communities and render them\n",
    "df_rendered    = pl.concat(dfs_rendered)\n",
    "df_remaining   = my_df.join(df_rendered, on=['fm', 'to'], how='anti')\n",
    "for k, k_df in df_remaining.group_by(('fm', 'to')):\n",
    "    if k[0] in _node_to_cd_:\n",
    "        _cd_fm_            = _node_to_cd_[k[0]]\n",
    "        fm_cd_sx, fm_cd_sy = _cd_sxy_[_cd_fm_]\n",
    "        fm_eps             = _cd_fm_.entityPositions(k[0]) \n",
    "        fm_x, fm_y         = fm_eps[0].xy()\n",
    "        fm_cd_r            = cd_r\n",
    "    else:\n",
    "        fm_x, fm_y                    =  _cd_sxy_[k[0]]\n",
    "        fm_cd_r = fm_cd_sx = fm_cd_sy = 0.0\n",
    "\n",
    "    if k[1] in _node_to_cd_:\n",
    "        _cd_to_            = _node_to_cd_[k[1]]    \n",
    "        to_cd_sx, to_cd_sy = _cd_sxy_[_cd_to_]\n",
    "        to_eps             = _cd_to_.entityPositions(k[1])\n",
    "        to_x, to_y         = to_eps[0].xy()\n",
    "        to_cd_r            = cd_r\n",
    "    else:\n",
    "        to_x, to_y                    = _cd_sxy_[k[1]]\n",
    "        to_cd_r = to_cd_sx = to_cd_sy = 0.0\n",
    "    svg.append(f'<line x1=\"{fm_x+fm_cd_sx-fm_cd_r}\" y1=\"{fm_y+fm_cd_sy-fm_cd_r}\" x2=\"{to_x+to_cd_sx-to_cd_r}\" y2=\"{to_y+to_cd_sy-to_cd_r}\" stroke=\"#ff0000\" stroke-opacity=\"0.5\" stroke-width=\"0.1\" />')\n",
    "\n",
    "# Render the cells -- shrinking them when necessary\n",
    "min_from_r = 20.0\n",
    "first_cell = True\n",
    "for cell_i in range(len(voronoi_cells)):\n",
    "    _cell_ = voronoi_cells[cell_i]\n",
    "    _path_ = f'M {_cell_[0][0]} {_cell_[0][1]} '\n",
    "    for i in range(1, len(_cell_)): _path_ += f'L {_cell_[i][0]} {_cell_[i][1]} '\n",
    "    _path_ += 'z'\n",
    "    svg.append(f'<path d=\"{_path_}\" stroke=\"black\" stroke-opacity=\"0.5\" stroke-width=\"4.0\" fill=\"black\" fill-opacity=\"0.1\" />')\n",
    "\n",
    "svg.append('</svg>')\n",
    "rt.tile([''.join(svg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.link(my_df_communities, [('__fm__','__to__')], communities_pos, draw_labels=True, w=800, h=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test  = pl.DataFrame({'fm':\"a b c d\".split(),\n",
    "                         'to':\"b c d a\".split(),\n",
    "                         'ct':[99.0,0.1,99.0,0.1]})\n",
    "g_test   = rt.createNetworkXGraph(df_test, [('fm','to')], count_by='ct')\n",
    "pos_test = nx.spring_layout(g_test)\n",
    "rt.link(df_test, [('fm','to')], pos_test, draw_labels=True, w=800, h=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
