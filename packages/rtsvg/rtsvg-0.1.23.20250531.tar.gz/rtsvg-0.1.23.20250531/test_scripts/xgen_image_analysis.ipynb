{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# for future me -- here are some commands that may help if cairo backend is not working...\n",
    "#\n",
    "#1735  sudo apt-get install cmake\n",
    "#1739  sudo apt-get install python3-cairo\n",
    "#1741  sudo apt-get install libcairo2\n",
    "#1742  sudo apt-get install libcairo2-dev\n",
    "#1743  pip install pycairo\n",
    "#1744  pip install rlPyCairo\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import time\n",
    "from rtsvg import *\n",
    "rt = RACETrack()\n",
    "ts1 = time.time()\n",
    "df = pl.concat([pl.read_csv('../../data/2013_vast_challenge/mc3_netflow/nf/nf-chunk1.csv'),\n",
    "                pl.read_csv('../../data/2013_vast_challenge/mc3_netflow/nf/nf-chunk2.csv'),\n",
    "                pl.read_csv('../../data/2013_vast_challenge/mc3_netflow/nf/nf-chunk3.csv')])\n",
    "df = rt.columnsAreTimestamps(df, 'parsedDate')\n",
    "ts2 = time.time()\n",
    "print(f'Loading Time ... {ts2 - ts1:0.2} sec')\n",
    "\n",
    "df = df.drop(['TimeSeconds', #'parsedDate',\n",
    "              'dateTimeStr', #'ipLayerProtocol',\n",
    "              'ipLayerProtocolCode', #'firstSeenSrcIp', #'firstSeenDestIp', #'firstSeenSrcPort', #'firstSeenDestPort',\n",
    "              'moreFragments', 'contFragments', #'durationSeconds',\n",
    "              'firstSeenSrcPayloadBytes', 'firstSeenDestPayloadBytes', #'firstSeenSrcTotalBytes', #'firstSeenDestTotalBytes', #'firstSeenSrcPacketCount', #'firstSeenDestPacketCount',\n",
    "              'recordForceOut'])\n",
    "df = df.rename({'parsedDate':'ts', 'ipLayerProtocol':'pro', 'firstSeenSrcIp':'sip', 'firstSeenDestIp':'dip', 'firstSeenSrcPort':'spt',\n",
    "                'firstSeenDestPort':'dpt', 'durationSeconds':'dur', 'firstSeenSrcTotalBytes':'soct', 'firstSeenDestTotalBytes':'doct', \n",
    "                'firstSeenSrcPacketCount':'spkt', 'firstSeenDestPacketCount':'dpkt'})\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dot_size':'tiny', 'color_by':'dpt', 'w':512, 'h':256}\n",
    "_xy0_ = rt.xy(df, x_field='ts', y_field='sip', **params)\n",
    "_xy1_ = rt.xy(df, x_field='ts', y_field='dip', **params)\n",
    "rt.tile([_xy0_, _xy1_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_xy0_img_ = rt.displaySVGAsImage(_xy0_)\n",
    "_xy1_img_ = rt.displaySVGAsImage(_xy1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# From the following:\n",
    "# https://huggingface.co/Salesforce/xgen-mm-phi3-mini-instruct-interleave-r-v1.5/blob/main/demo.ipynb\n",
    "#\n",
    "from transformers import AutoModelForVision2Seq, AutoTokenizer, AutoImageProcessor, StoppingCriteria\n",
    "import torch\n",
    "import PIL\n",
    "import textwrap\n",
    "import IPython.display as display\n",
    "from IPython.display import Image\n",
    "\n",
    "model_name_or_path = \"Salesforce/xgen-mm-phi3-mini-instruct-interleave-r-v1.5\"\n",
    "model = AutoModelForVision2Seq.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, use_fast=False, legacy=False)\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "tokenizer = model.update_special_tokens(tokenizer)\n",
    "model = model.to('cuda')\n",
    "model.eval()\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.eos_token = '<|end|>'\n",
    "def apply_prompt_template(prompt):\n",
    "    s = (\n",
    "                '<|system|>\\nA chat between a curious user and an artificial intelligence assistant. '\n",
    "                \"The assistant gives helpful, detailed, and polite answers to the user's questions.<|end|>\\n\"\n",
    "                f'<|user|>\\n{prompt}<|end|>\\n<|assistant|>\\n'\n",
    "            )\n",
    "    return s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list  = [] # the image_processor converts it to a tensor (torch.Tensor)\n",
    "                 # the input that works in the example is PIL.JpegImagePlugin.JpegImageFile\n",
    "image_sizes = [] # tuples (w,h)\n",
    "image_list.append(image_processor([_xy0_img_], image_aspect_ratio='anyres')[\"pixel_values\"].cuda())\n",
    "image_sizes.append((_xy0_img_.width, _xy0_img_.height))\n",
    "inputs = { 'pixel_values': [image_list]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torchvision.transforms as transforms\n",
    "#transform = transforms.Compose([transforms.ToTensor()])\n",
    "#transform(_xy0_img_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
