{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the output from routing_3.ipynb and works on the routing portion of it\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from math import pi, cos, sin, sqrt, atan2\n",
    "import networkx as nx \n",
    "import random\n",
    "import os\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()\n",
    "\n",
    "file_no = 7\n",
    "df_collapsed    = pl.read_parquet(f'../../data/stanford/facebook/348.edges_collapsed_edges.{file_no}.parquet')\n",
    "df_edge_arc_pos = pl.read_parquet(f'../../data/stanford/facebook/348.edges_arc_pos.{file_no}.parquet')\n",
    "df_collapsed.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_arc_pos.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractCircles(_df_):\n",
    "    circles, circle_lu = [], {}\n",
    "    for k, k_df in _df_.group_by(['x_circle','y_circle','r_circle']):\n",
    "        circle_lu[k] = len(circles)\n",
    "        circles.append(k)\n",
    "    return circles, circle_lu\n",
    "\n",
    "def validatePositions(_df_, clearance=10): # edge_arc_pos\n",
    "    # Extract the circles first\n",
    "    circles, circle_lu = extractCircles(_df_)\n",
    "    # Then make sure the positions don't fall within a circle & that they have some clearance\n",
    "    for k, k_df in _df_.group_by(['x','y', 'x_circle', 'y_circle', 'r_circle']):\n",
    "        _xy_     = (k[0], k[1])\n",
    "        _uv_     = rt.unitVector((k[2:4], _xy_))\n",
    "        _xy_end_ = (_xy_[0]+ clearance*_uv_[0], _xy_[1]+ clearance*_uv_[1])\n",
    "        _my_circle_ = k[2:5]\n",
    "        for c in circles:\n",
    "            if c == _my_circle_: continue\n",
    "            _length_ = rt.segmentLength((_xy_,c))\n",
    "            if _length_ < c[2] + clearance:\n",
    "                raise Exception(f'node key \"{k_df[\"node_key\"]}\" with radius circle {c}')\n",
    "            _length_ = rt.segmentLength((_xy_end_, c))\n",
    "\n",
    "def extents(_df_): # edge_arc_pos -- assumes that the coordinates are already in screen space\n",
    "    xmin, ymin, xmax, ymax = 1e9, 1e9, -1e9, -1e9\n",
    "    for k, k_df in _df_.group_by(['x_circle','y_circle','r_circle']):\n",
    "        xmin, ymin = min(xmin, k[0]-k[2]), min(ymin, k[1]-k[2])\n",
    "        xmax, ymax = max(xmax, k[0]+k[2]), max(ymax, k[1]+k[2])\n",
    "    for k, k_df in _df_.group_by(['x','y']):\n",
    "        xmin, ymin = min(xmin, k[0]), min(ymin, k[1])\n",
    "        xmax, ymax = max(xmax, k[0]), max(ymax, k[1])\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "validatePositions(df_edge_arc_pos)\n",
    "_ext_ = extents(df_edge_arc_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h, x_ins, y_ins, border = 1000, 1000, 30.0, 30.0, 20.0\n",
    "x_canvas, y_canvas, w_canvas, h_canvas = _ext_[0]-x_ins, _ext_[1]-y_ins, 2*x_ins+_ext_[2]-_ext_[0], 2*y_ins+_ext_[3]-_ext_[1]\n",
    "# Base Circles\n",
    "svg_hdr =     [f'<svg  x=\"0\" y=\"0\" width=\"{w}\" height=\"{h}\" viewBox=\"{x_canvas} {y_canvas} {w_canvas} {h_canvas}\">']\n",
    "svg_hdr.append(f'<rect x=\"{x_canvas}\" y=\"{y_canvas}\" width=\"{w_canvas}\" height=\"{h_canvas}\" fill=\"#ffffff\" />')\n",
    "svg_hdr = ''.join(svg_hdr)\n",
    "svg_ftr = '</svg>'\n",
    "svg_base = []\n",
    "circles, circles_lu = extractCircles(df_edge_arc_pos)\n",
    "for i in range(len(circles)):\n",
    "    cx, cy, r = circles[i]\n",
    "    svg_base.append(f'<circle cx=\"{cx}\" cy=\"{cy}\" r=\"{r}\" fill=\"none\" stroke=\"{rt.co_mgr.getColor(i)}\" stroke-width=\"3\" />')\n",
    "\n",
    "# LaGuerre Voronoi\n",
    "_box_ = [(_ext_[0]-border,_ext_[1]-border),(_ext_[0]-border,_ext_[3]+border),(_ext_[2]+border,_ext_[3]+border),(_ext_[2]+border,_ext_[1]-border)]\n",
    "voronoi_polys = rt.laguerreVoronoi(circles, Box=_box_)\n",
    "svg_voronoi   = []\n",
    "for i in range(len(voronoi_polys)):\n",
    "    d = f'M {voronoi_polys[i][0][0]} {voronoi_polys[i][0][1]} '\n",
    "    for j in range(1, len(voronoi_polys[i])): d += f'L {voronoi_polys[i][j][0]} {voronoi_polys[i][j][1]} '\n",
    "    d += 'Z'\n",
    "    svg_voronoi.append(f'<path d=\"{d}\" fill=\"none\" stroke=\"{rt.co_mgr.getColor(i)}\" stroke-width=\"1\"/>')\n",
    "    svg_voronoi.append(f'<path d=\"{d}\" fill=\"none\" stroke=\"#000000\" stroke-width=\"0.1\"/>')\n",
    "_seen_ = set()\n",
    "svg_voronoi_circle_markers = []\n",
    "for i in range(len(voronoi_polys)):\n",
    "    for j in range(len(voronoi_polys[i])):\n",
    "        x, y = voronoi_polys[i][j]\n",
    "        if (x,y) not in _seen_: svg_voronoi_circle_markers.append(f'<circle cx=\"{x}\" cy=\"{y}\" r=\"{4.0+random.random()*4.0}\" stroke-width=\"0.1\" stroke=\"#000000\" fill=\"none\"/>')\n",
    "        _seen_.add((x,y))\n",
    "\n",
    "# (Uniquify) Segment To Poly\n",
    "def uniquifySegment(s):\n",
    "    _xy0_, _xy1_ = s[0], s[1]\n",
    "    if   _xy0_[0] <  _xy1_[0]: return s\n",
    "    elif _xy0_[0] >  _xy1_[0]: return (_xy1_, _xy0_)\n",
    "    elif _xy0_[1] <  _xy1_[1]: return s\n",
    "    else:                      return (_xy1_, _xy0_)\n",
    "\n",
    "#rt.tile([svg_hdr + ''.join(svg_base) + ''.join(svg_voronoi_circle_markers) + svg_ftr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_to_poly_is = {}\n",
    "for i in range(len(voronoi_polys)):\n",
    "    _poly_ = voronoi_polys[i]\n",
    "    for j in range(len(_poly_)):\n",
    "        _segment_    = (_poly_[j], _poly_[(j+1)%len(_poly_)])\n",
    "        _uniquified_ = uniquifySegment(_segment_)\n",
    "        if _uniquified_ not in segment_to_poly_is: segment_to_poly_is[_uniquified_] = []\n",
    "        segment_to_poly_is[_uniquified_].append(i)\n",
    "\n",
    "def addVertexAndUpdatePolygons(seg, xy, pixel_diff=4.0):\n",
    "    seg    = uniquifySegment(seg)\n",
    "    l      = rt.segmentLength(seg)\n",
    "    l0, l1 = rt.segmentLength((seg[0], xy)), rt.segmentLength((seg[1], xy))\n",
    "    if l0 < pixel_diff: return seg[0]\n",
    "    if l1 < pixel_diff: return seg[1]\n",
    "    polys_to_update = segment_to_poly_is[seg]\n",
    "    for i in polys_to_update:\n",
    "        _poly_ = voronoi_polys[i]\n",
    "        j      = 0\n",
    "        while _poly_[j] != seg[0] and _poly_[j] != seg[1]: j += 1\n",
    "        k      = (j+1)%len(_poly_)\n",
    "        if    _poly_[k] != seg[0] and _poly_[k] != seg[1]: k = len(_poly_)-1\n",
    "        if    _poly_[k] != seg[0] and _poly_[k] != seg[1]: raise Exception('can\\'t find k')\n",
    "        if j == 0 and k == len(_poly_)-1: _poly_.append(xy)\n",
    "        else:                             _poly_.insert(k,xy)\n",
    "    del segment_to_poly_is[seg]\n",
    "    seg0, seg1 = uniquifySegment((xy,seg[0])), uniquifySegment((xy,seg[1]))\n",
    "\n",
    "    if seg0 not in segment_to_poly_is: segment_to_poly_is[seg0] = []\n",
    "    if seg1 not in segment_to_poly_is: segment_to_poly_is[seg1] = []\n",
    "    segment_to_poly_is[seg0].extend(polys_to_update)\n",
    "    segment_to_poly_is[seg1].extend(polys_to_update)\n",
    "    return xy\n",
    "\n",
    "# Entry / Exit Points\n",
    "_large_distance_ = 1e9\n",
    "svg_pts, _edges_, _pos_, _pos_vertex_names_ = [], [], {}, {}\n",
    "def getOrCreateVertexName(xy):\n",
    "    if xy not in _pos_vertex_names_: _pos_vertex_names_[xy] = f'V_{len(_pos_vertex_names_)}'\n",
    "    return _pos_vertex_names_[xy]\n",
    "for k, k_df in df_edge_arc_pos.group_by(['node_key', 'x', 'y', 'x_circle', 'y_circle', 'r_circle']):\n",
    "    _xy_, _cxy_, _circle_ = k[1:3], k[3:5], k[3:6]\n",
    "    circle_i              = circles_lu[_circle_] # Validate circle exists\n",
    "    _uv_                  = rt.unitVector((_cxy_, _xy_))\n",
    "    if  k[0].endswith('_to_'): exit_pt, _color_ = False, '#ff0000' # Entry ... where something stops  (enters the circle)\n",
    "    else:                      exit_pt, _color_ = True,  '#0000ff' # Exit  ... where something starts (leaves the circle)\n",
    "    svg_pts.append(f'<circle cx=\"{_xy_[0]}\" cy=\"{_xy_[1]}\" r=\"2\" fill=\"{_color_}\" stroke=\"none\" />')\n",
    "    # Determine where the entry/exit point connects to the voronoi segments\n",
    "    entry_exit_ray = (_xy_, (_xy_[0] + _large_distance_*_uv_[0], _xy_[1] + _large_distance_*_uv_[1]))\n",
    "    xy_inter, _segment_ = None, None\n",
    "    _poly_ = voronoi_polys[circle_i]\n",
    "    for i in range(len(_poly_)):\n",
    "        _segment_          = (_poly_[i], _poly_[(i+1)%len(_poly_)])\n",
    "        _intersects_tuple_ = rt.segmentsIntersect(_segment_, entry_exit_ray)\n",
    "        if _intersects_tuple_[0]:\n",
    "            xy_inter = (_intersects_tuple_[1], _intersects_tuple_[2])\n",
    "            break\n",
    "        xy_inter = None\n",
    "    if xy_inter is None: raise Exception('xy_inter should not be none...')\n",
    "    xy_inter = addVertexAndUpdatePolygons(_segment_, xy_inter) # possibility that maybe the new vertex isn't that different from an existing vertex\n",
    "    _edges_.append((k[0], getOrCreateVertexName(xy_inter)))\n",
    "    _pos_[k[0]]                            = _xy_\n",
    "    _pos_[getOrCreateVertexName(xy_inter)] = xy_inter\n",
    "    svg_pts.append(f'<line x1=\"{_xy_[0]}\" y1=\"{_xy_[1]}\" x2=\"{xy_inter[0]}\" y2=\"{xy_inter[1]}\" stroke=\"{_color_}\" stroke-width=\"0.4\"/>')\n",
    "\n",
    "# Add the updated polys as edges to the edge list\n",
    "already_added = set()\n",
    "for i in range(len(voronoi_polys)):\n",
    "    _poly_ = voronoi_polys[i]\n",
    "    for j in range(len(_poly_)):\n",
    "        _xy0_, _xy1_ = _poly_[j], _poly_[(j+1)%len(_poly_)]\n",
    "        _seg_ = uniquifySegment((_xy0_, _xy1_))\n",
    "        if _seg_ not in already_added:\n",
    "            _edges_.append((getOrCreateVertexName(_seg_[0]), getOrCreateVertexName(_seg_[1])))\n",
    "            _pos_[getOrCreateVertexName(_seg_[0])], _pos_[getOrCreateVertexName(_seg_[1])] = _seg_[0], _seg_[1]\n",
    "            already_added.add(_seg_)\n",
    "\n",
    "#rt.tile([svg_hdr + ''.join(svg_base)+''.join(svg_pts)+''.join(svg_voronoi) + svg_ftr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_voronoi_connects, xys_seen = [], set()\n",
    "for i in range(len(voronoi_polys)):\n",
    "    _poly_ = voronoi_polys[i]\n",
    "    for j in range(len(_poly_)):\n",
    "        _xy0_, _xy1_ = _poly_[j], _poly_[(j+1)%len(_poly_)]\n",
    "        xys_seen.add(_xy0_), xys_seen.add(_xy1_)\n",
    "        svg_voronoi_connects.append(f'<line x1=\\\"{_xy0_[0]}\\\" y1=\\\"{_xy0_[1]}\\\" x2=\\\"{_xy1_[0]}\\\" y2=\\\"{_xy1_[1]}\\\" stroke=\\\"{rt.co_mgr.getColor(i)}\\\" stroke-width=\\\"0.5\\\"/>')\n",
    "for _xy_ in xys_seen: svg_voronoi_connects.append(f'<circle cx=\\\"{_xy_[0]}\\\" cy=\\\"{_xy_[1]}\\\" r=\\\"{3.0 + random.random()}\\\" fill=\\\"none\\\" stroke=\\\"#000000\\\" stroke-width=\\\"0.1\\\"/>')\n",
    "rt.tile([svg_hdr + ''.join(svg_base)+''.join(svg_pts)+''.join(svg_voronoi_connects) + svg_ftr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relates, g_lu = [('__fm__','__to__')], {'__fm__':[], '__to__':[],'__dist__':[]}\n",
    "for _edge_ in _edges_: \n",
    "    g_lu['__fm__'].append(_edge_[0])\n",
    "    g_lu['__to__'].append(_edge_[1])\n",
    "    xy0, xy1 = _pos_[_edge_[0]], _pos_[_edge_[1]]\n",
    "    g_lu['__dist__'].append(rt.segmentLength((xy0,xy1)))\n",
    "df_g = pl.DataFrame(g_lu)\n",
    "df_g = df_g.with_columns((1.0/(pl.col('__dist__')+0.1)).alias('inv_dist')) # invert it to match networkx's version of closeness\n",
    "g    = rt.createNetworkXGraph(df_g, relates, count_by='inv_dist')\n",
    "rt.tile([rt.link(df_g, relates, _pos_, node_size='small', count_by='__dist__', \n",
    "                 link_size='vary', link_size_max=8.0, link_size_min=1.0, w=680, h=680),\n",
    "         rt.histogram(df_collapsed, bin_by='__to__', count_by='__fm__', w=256, h=680)], spacer=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all \"To\"'s\n",
    "_tiles_, _edge_frequency_ = [], {}\n",
    "for k, k_df in df_collapsed.group_by(['__to__']):\n",
    "    _to_ = k[0]\n",
    "    # Calculate the shortest path to all other nodes\n",
    "    _weights_lu_, _paths_lu_ = nx.shortest_paths.single_source_bellman_ford(g, source=_to_, weight='weight')\n",
    "    # Get the list of \"From\"'s for this particular \"To\"\n",
    "    fms = set(df_collapsed.filter(pl.col('__to__') == _to_)['__fm__'])\n",
    "    # Create a subgraph of all the shortest paths and add it to a tile\n",
    "    fmto_lu = {'__fm__':[], '__to__':[]}\n",
    "    _edge_already_seen_ = set() # already seen filter is reset per every \"To\"\n",
    "    for _fm_ in fms:\n",
    "        _path_ = _paths_lu_[_fm_]\n",
    "        for i in range(len(_path_)-1):\n",
    "            fmto_lu['__fm__'].append(_path_[i])\n",
    "            fmto_lu['__to__'].append(_path_[i+1])\n",
    "            # Keep track of edge frequency counts\n",
    "            if _path_[i] < _path_[i+1]: _edge_ = (_path_[i],   _path_[i+1])\n",
    "            else:                       _edge_ = (_path_[i+1], _path_[i])\n",
    "            if _edge_ not in _edge_frequency_:      _edge_frequency_[_edge_]  = 0\n",
    "            if _edge_ not in _edge_already_seen_:   _edge_frequency_[_edge_] += 1\n",
    "            _edge_already_seen_.add(_edge_)\n",
    "    for _edge_ in _edge_already_seen_: g.add_edge(_edge_[0], _edge_[1], weight=g[_edge_[0]][_edge_[1]]['weight']*2.0)\n",
    "    _tiles_.append(rt.link(pl.DataFrame(fmto_lu), relates, _pos_, node_size='small', w=300, h=300))\n",
    "\n",
    "# Display the most often path edges were seen in the above algorithm\n",
    "_sorter_ = []\n",
    "for k in _edge_frequency_: _sorter_.append((_edge_frequency_[k], k))\n",
    "_sorter_.sort(reverse=True)\n",
    "for i in range(10): print(_sorter_[i])\n",
    "histo_lu = {'weight':[],'tuple':[]}\n",
    "for i in range(len(_sorter_)): histo_lu['weight'].append(_sorter_[i][0]), histo_lu['tuple'].append(str(_sorter_[i][1]))\n",
    "rt.histogram(pl.DataFrame(histo_lu),bin_by='tuple',count_by='weight',bar_h=10,w=1024,h=512, draw_distribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tiles\n",
    "#rt.table(_tiles_, per_row=5, spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lu_ = {'__fm__':[], '__to__':[], '__count__':[]}\n",
    "for _tuple_ in _sorter_: _lu_['__fm__'].append(_tuple_[1][0]), _lu_['__to__'].append(_tuple_[1][1]), _lu_['__count__'].append(_tuple_[0])\n",
    "df_edge_usage = pl.DataFrame(_lu_)\n",
    "rt.xy(df_edge_usage, x_field='__count__', y_field='__fm__')\n",
    "rt.link(df_edge_usage, relates, _pos_, count_by='__count__', link_size='vary', link_size_max=8.0, link_size_min=1.0, w=800, h=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_example = nx.Graph()\n",
    "g_example.add_edge('a','b',weight=1)\n",
    "g_example.add_edge('b','c',weight=1)\n",
    "g_example.add_edge('c','d',weight=1)\n",
    "g_example.add_edge('d','e',weight=1)\n",
    "g_example.add_edge('a','z',weight=1)\n",
    "g_example.add_edge('z','e',weight=1)\n",
    "print(nx.single_source_bellman_ford(g_example, 'a', weight='weight'))\n",
    "g_example.add_edge('a','z',weight=10)\n",
    "print(nx.single_source_bellman_ford(g_example, 'a', weight='weight')[0])\n",
    "print(nx.single_source_bellman_ford(g_example, 'a', weight='weight')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
