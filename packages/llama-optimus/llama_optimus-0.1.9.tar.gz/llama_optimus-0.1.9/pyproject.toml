[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "llama-optimus"
version = "0.1.9"
description = "llama-optimus is a lightweight Python tool to automatically optimize llama.cpp performance flags for maximum tg & pp token/s throughput. Powered by Bayesian optimization with Optuna"
authors = [
  { name = "Bruno Arsioli", email = "YOUR_EMAIL@yourdomain.com" }
]
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.8"
dependencies = [
  "optuna>=3.0",
  "pandas"
]
keywords = ["llama.cpp", "optimization", "AI", "Optuna", "performance"]
classifiers = [
  "Programming Language :: Python :: 3",
  "License :: OSI Approved :: MIT License",
  "Operating System :: OS Independent",
]

[project.urls]
Homepage = "https://github.com/BrunoArsioli/llama-optimus"
Repository = "https://github.com/BrunoArsioli/llama-optimus"
"Bug Tracker" = "https://github.com/BrunoArsioli/llama-optimus/issues"

[project.scripts]
llama-optimus = "llama_optimus.cli:main"

[tool.setuptools]
package-dir = {"" = "src"}




