Metadata-Version: 2.4
Name: pearl-rl
Version: 0.1.0
Summary: A reinforcement learning library with explainability features
Home-page: https://github.com/yourusername/pearl
Author: Your Name
Author-email: Your Name <your.email@example.com>
Maintainer-email: Your Name <your.email@example.com>
License: MIT
Project-URL: Homepage, https://github.com/yourusername/pearl
Project-URL: Documentation, https://github.com/yourusername/pearl#readme
Project-URL: Repository, https://github.com/yourusername/pearl.git
Project-URL: Bug Tracker, https://github.com/yourusername/pearl/issues
Keywords: reinforcement-learning,machine-learning,explainability,ai,rl
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.21.0
Requires-Dist: torch>=1.9.0
Requires-Dist: gymnasium>=0.26.0
Requires-Dist: matplotlib>=3.5.0
Requires-Dist: stable-baselines3>=1.5.0
Requires-Dist: opencv-python>=4.5.0
Requires-Dist: pandas>=1.3.0
Requires-Dist: tqdm>=4.62.0
Requires-Dist: tensorboard>=2.8.0
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-cov>=2.0; extra == "dev"
Requires-Dist: black>=21.0; extra == "dev"
Requires-Dist: flake8>=3.8; extra == "dev"
Requires-Dist: mypy>=0.800; extra == "dev"
Requires-Dist: pre-commit>=2.15.0; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# Pearl RL

A reinforcement learning library with explainability features for AI/ML research and development.

## Features

- **Reinforcement Learning Agents**: Implementation of various RL algorithms including DQN
- **Environment Wrappers**: Easy integration with Gymnasium environments
- **Explainability Methods**: Multiple explainability techniques including LIME, SHAP, and LMUT
- **Stability Analysis**: Tools for analyzing model stability
- **Pre-built Environments**: Support for Atari games and Lunar Lander

## Installation

```bash
pip install pearl-rl
```

## Quick Start

```python
from pearl import Pearl
from pearl.agents import SimpleDQN
from pearl.enviroments import GymRLEnv

# Create an environment
env = GymRLEnv("LunarLander-v2")

# Create an agent
agent = SimpleDQN(env.observation_space, env.action_space)

# Create Pearl instance
pearl = Pearl(agent, env)

# Train the agent
pearl.train(episodes=1000)

# Get explanations
explanations = pearl.explain(episode=0)
```

## Documentation

For detailed documentation and examples, please visit our [documentation page](https://github.com/yourusername/pearl).

## Contributing

We welcome contributions! Please see our [contributing guidelines](CONTRIBUTING.md) for details.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Citation

If you use Pearl in your research, please cite:

```bibtex
@software{pearl_rl,
  title={Pearl RL: A Reinforcement Learning Library with Explainability Features},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/pearl}
}
``` 
