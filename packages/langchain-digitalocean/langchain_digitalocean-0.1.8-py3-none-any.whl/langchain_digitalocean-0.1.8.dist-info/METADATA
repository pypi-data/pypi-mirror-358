Metadata-Version: 2.3
Name: langchain-digitalocean
Version: 0.1.8
Summary: An integration package connecting Digitalocean and LangChain
License: MIT
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: langchain-core (>=0.3.15,<0.4.0)
Requires-Dist: langchain-tests (>=0.3.20,<0.4.0)
Requires-Dist: python-digitalocean (>=1.17.0,<2.0.0)
Project-URL: Repository, https://github.com/langchain-ai/langchain
Project-URL: Release Notes, https://github.com/langchain-ai/langchain/releases?q=tag%3A%22digitalocean%3D%3D0%22&expanded=true
Project-URL: Source Code, https://github.com/langchain-ai/langchain/tree/master/libs/partners/digitalocean
Description-Content-Type: text/markdown

# langchain-digitalocean

This package contains the LangChain integration with Digitalocean

## Installation

```bash
pip install -U langchain-digitalocean
```

And you should configure credentials by setting the following environment variables:

export DIGITALOCEAN_MODEL_ACCESS_KEY=<DigitalOcean_Model_Access_Key>

## Chat Models

`ChatDigitalocean` class exposes chat models from langchain-digitalocean.

### Invoke

```python
from langchain_digitalocean import ChatDigitalocean

llm = ChatDigitalocean(
    model="llama3.3-70b-instruct",
    api_key=os.getenv("DIGITALOCEAN_MODEL_ACCESS_KEY")
)

result = llm.invoke("What is the capital of France?.")
print(result)
```

### Stream

```python
from langchain_digitalocean import ChatDigitalocean

llm = ChatDigitalocean(
    model="llama3.3-70b-instruct",
    api_key=os.getenv("DIGITALOCEAN_MODEL_ACCESS_KEY")
)

for chunk in llm.stream("Tell me what happened to the Dinosaurs?"):
    print(chunk.content, end="", flush=True)

```

More features coming soon.
