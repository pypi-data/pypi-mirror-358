Metadata-Version: 2.3
Name: semantic-chunker-langchain
Version: 0.1.4
Summary: Token-aware, LangChain-compatible semantic chunker with PDF and layout support
License: MIT
Author: Prajwal Shivaji Mandale
Author-email: prajwal.mandale333@gmail.com
Requires-Python: >=3.9,<3.13
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: faiss-cpu (>=1.11.0,<2.0.0)
Requires-Dist: langchain (>=0.3.25,<0.4.0)
Requires-Dist: langchain-community (>=0.3.26,<0.4.0)
Requires-Dist: openai (>=1.84.0,<2.0.0)
Requires-Dist: pdfplumber (>=0.11.6,<0.12.0)
Requires-Dist: tiktoken (>=0.9.0,<0.10.0)
Description-Content-Type: text/markdown

# Semantic Chunker for LangChain

Hitting limits on passing the larger context to your limited character token limit llm model not anymore this chunker solves the problem
It is a **token-aware**, **LangChain-compatible** chunker that splits text (from PDF, markdown, or plain text) into semantically coherent chunks while respecting model token limits.

---

## ğŸš€ Features

* ğŸ” **Model-Aware Token Limits**: Automatically adjusts chunking size for GPT-3.5, GPT-4, Claude, and others.
* ğŸ“„ **Multi-format Input Support**:

  * PDF via `pdfplumber`
  * Plain `.txt`
  * Markdown
  * (Extendable to `.docx` and `.html`)
* ğŸ” **Overlapping Chunks**: Smart overlap between paragraphs to preserve context.
* ğŸ§  **Smart Merging**: Merges chunks smaller than 300 tokens.
* ğŸ§© **Retriever-Ready**: Direct integration with `LangChain` retrievers via FAISS.
* ğŸ”§ **CLI Support**: Run from terminal with one command.

---

## ğŸ“† Installation

```bash
pip install semantic-chunker-langchain
```

> Requires Python 3.9 - 3.12

---

## ğŸ› ï¸ Usage

### ğŸ”¸ Chunk a PDF and Save to JSON/TXT

```bash
semantic-chunker sample.pdf --txt chunks.txt --json chunks.json
```

### ğŸ”¸ From Code

```python
from semantic_chunker_langchain.chunker import SemanticChunker, SimpleSemanticChunker
from semantic_chunker_langchain.extractors.pdf import extract_pdf
from semantic_chunker_langchain.outputs.formatter import write_to_txt

# Extract
docs = extract_pdf("sample.pdf")

# Using SemanticChunker
chunker = SemanticChunker(model_name="gpt-3.5-turbo")
chunks = chunker.split_documents(docs)

# Save to file
write_to_txt(chunks, "output.txt")

# Using SimpleSemanticChunker
simple_chunker = SimpleSemanticChunker(model_name="gpt-3.5-turbo")
simple_chunks = simple_chunker.split_documents(docs)
```

### ğŸ”¸ Convert to Retriever

```python
from langchain_community.embeddings import OpenAIEmbeddings
retriever = chunker.to_retriever(chunks, embedding=OpenAIEmbeddings())
```

---

## ğŸ“Š Testing

```bash
poetry run pytest tests/
```

---

## ğŸ‘¨â€ğŸ’» Authors

* Prajwal Shivaji Mandale
* Sudhnwa Ghorpade

---

## ğŸ“œ License

This project is licensed under the MIT License.

