import json
import os
import asyncio
import httpx
import hashlib
from datetime import datetime
from typing import Dict, List, Optional, Union
from pathlib import Path

from nonebot import on_command, get_bot, get_plugin_config, get_driver
from nonebot.adapters.onebot.v11 import Bot, MessageEvent, GroupMessageEvent, PrivateMessageEvent
from nonebot.matcher import Matcher
from nonebot.params import CommandArg
from nonebot.message import event_postprocessor
from nonebot.log import logger
from nonebot.permission import SUPERUSER
from nonebot.adapters.onebot.v11.message import Message, MessageSegment

from .config import Config

# è·å–é…ç½®
config = get_plugin_config(Config)

# å­˜å‚¨ç­‰å¾…çŠ¶æ€çš„ç”¨æˆ·
waiting_users: Dict[str, Dict] = {}

class LexiconManager:
    """è¯åº“ç®¡ç†å™¨"""
    
    def __init__(self, data_path: str):
        self.data_path = Path(data_path)
        self.ensure_data_dir()
    
    def ensure_data_dir(self):
        """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
        self.data_path.mkdir(parents=True, exist_ok=True)        # ç¡®ä¿å›¾ç‰‡å’Œè¯­éŸ³ç›®å½•å­˜åœ¨
        (self.data_path / "pic").mkdir(exist_ok=True)
        (self.data_path / "voice").mkdir(exist_ok=True)
    
    def get_group_file_path(self, group_id: int) -> Path:
        """è·å–ç¾¤è¯åº“æ–‡ä»¶è·¯å¾„"""
        return self.data_path / f"group{group_id}.json"
    
    def get_user_file_path(self, user_id: int) -> Path:
        """è·å–ç”¨æˆ·è¯åº“æ–‡ä»¶è·¯å¾„"""
        return self.data_path / f"uin{user_id}.json"
    
    def get_global_file_path(self) -> Path:
        """è·å–å…¨å±€è¯åº“æ–‡ä»¶è·¯å¾„"""
        return self.data_path / "global.json"
    
    def get_blacklist_file_path(self) -> Path:
        """è·å–é»‘åå•æ–‡ä»¶è·¯å¾„"""
        return self.data_path / "lexiconblacklist.json"
    
    async def download_media_file(self, url: str, file_type: str) -> Optional[str]:
        """ä¸‹è½½åª’ä½“æ–‡ä»¶å¹¶è¿”å›æœ¬åœ°æ–‡ä»¶å"""
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            url_hash = hashlib.md5(url.encode()).hexdigest()
            timestamp = int(datetime.now().timestamp())
            
            if file_type == "image":
                # ç›´æ¥ä½¿ç”¨é€šç”¨æ‰©å±•å
                filename = f"{timestamp}_{url_hash}.jpg"
                save_dir = self.data_path / "pic"
            elif file_type == "voice":
                # ç›´æ¥ä½¿ç”¨é€šç”¨æ‰©å±•å
                filename = f"{timestamp}_{url_hash}.silk"
                save_dir = self.data_path / "voice"
            else:
                return None
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            save_dir.mkdir(parents=True, exist_ok=True)
            file_path = save_dir / filename
            
            logger.info(f"å‡†å¤‡ä¸‹è½½åª’ä½“æ–‡ä»¶: {url} -> {file_path}")
              # æ£€æŸ¥URLæ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
            if url.startswith('file://') or Path(url).exists():
                # æœ¬åœ°æ–‡ä»¶ï¼Œç›´æ¥å¤åˆ¶
                source_path = Path(url.replace('file://', '')) if url.startswith('file://') else Path(url)
                if source_path.exists():
                    import shutil
                    shutil.copy2(source_path, file_path)
                    logger.info(f"æˆåŠŸå¤åˆ¶æœ¬åœ°åª’ä½“æ–‡ä»¶: {filename}")
                    return filename
                else:
                    logger.error(f"æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
                    return None
            
            # å¤„ç† base64 ç¼–ç çš„æ–‡ä»¶
            if url.startswith('base64://'):
                import base64
                base64_data = url.replace('base64://', '')
                try:
                    file_data = base64.b64decode(base64_data)
                    with open(file_path, 'wb') as f:
                        f.write(file_data)
                    logger.info(f"æˆåŠŸä¿å­˜base64åª’ä½“æ–‡ä»¶: {filename}")
                    return filename
                except Exception as e:
                    logger.error(f"ä¿å­˜base64æ–‡ä»¶å¤±è´¥: {e}")
                    return None
            
            # ç½‘ç»œæ–‡ä»¶ï¼Œä¸‹è½½
            async with httpx.AsyncClient() as client:
                response = await client.get(url)
                if response.status_code == 200:
                    content = response.content
                    with open(file_path, 'wb') as f:
                        f.write(content)
                    logger.info(f"æˆåŠŸä¸‹è½½åª’ä½“æ–‡ä»¶: {filename}")
                    return filename
                else:
                    logger.error(f"ä¸‹è½½åª’ä½“æ–‡ä»¶å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    return None
        except Exception as e:
            logger.error(f"ä¸‹è½½åª’ä½“æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return None
    
    def get_media_file_path(self, filename: str, file_type: str) -> Path:
        """è·å–åª’ä½“æ–‡ä»¶çš„å®Œæ•´è·¯å¾„"""
        if file_type == "image":
            return self.data_path / "pic" / filename
        elif file_type == "voice":
            return self.data_path / "voice" / filename
        else:
            return self.data_path / filename
    
    async def parse_message_content(self, message: Message) -> Dict:
        """è§£ææ¶ˆæ¯å†…å®¹ï¼Œæå–æ–‡æœ¬ã€å›¾ç‰‡å’Œè¯­éŸ³"""
        content = {
            "type": "text",
            "text": "",
            "media_files": []
        }
        
        text_parts = []
        has_media = False
        
        for segment in message:
            if segment.type == "text":
                text_parts.append(segment.data.get("text", ""))
            elif segment.type == "image":
                has_media = True
                url = segment.data.get("url") or segment.data.get("file")
                if url:
                    filename = await self.download_media_file(url, "image")
                    if filename:
                        content["media_files"].append({
                            "type": "image",
                            "filename": filename
                        })
            elif segment.type == "record":
                has_media = True
                url = segment.data.get("url") or segment.data.get("file")
                if url:
                    filename = await self.download_media_file(url, "voice")
                    if filename:
                        content["media_files"].append({
                            "type": "voice",
                            "filename": filename
                        })
        
        content["text"] = "".join(text_parts).strip()
        if has_media:
            content["type"] = "mixed" if content["text"] else "media"
        
        return content
    
    def load_data(self, file_path: Path) -> List[Dict]:
        """åŠ è½½è¯åº“æ•°æ®"""
        if not file_path.exists():
            return []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"åŠ è½½è¯åº“æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            return []
    
    def save_data(self, file_path: Path, data: List[Dict]):
        """ä¿å­˜è¯åº“æ•°æ®"""
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜è¯åº“æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
    
    def load_blacklist(self) -> List[int]:
        """åŠ è½½é»‘åå•"""
        file_path = self.get_blacklist_file_path()
        if not file_path.exists():
            return []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"åŠ è½½é»‘åå•æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def save_blacklist(self, blacklist: List[int]):
        """ä¿å­˜é»‘åå•"""
        file_path = self.get_blacklist_file_path()
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(blacklist, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜é»‘åå•æ–‡ä»¶å¤±è´¥: {e}")
    
    def is_blacklisted(self, user_id: int) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦è¢«æ‹‰é»‘"""
        blacklist = self.load_blacklist()
        return user_id in blacklist
    
    def add_to_blacklist(self, user_id: int):
        """æ·»åŠ ç”¨æˆ·åˆ°é»‘åå•"""
        blacklist = self.load_blacklist()
        if user_id not in blacklist:
            blacklist.append(user_id)
            self.save_blacklist(blacklist)
    
    async def add_lexicon(self, file_path: Path, keyword: str, reply_content: Union[str, Dict], user_id: int, is_group: bool = False):
        """æ·»åŠ è¯æ¡ï¼ˆæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€è¯­éŸ³ï¼‰"""
        data = self.load_data(file_path)
        
        # å¤„ç†å›å¤å†…å®¹
        if isinstance(reply_content, str):
            # çº¯æ–‡æœ¬å›å¤
            reply_data = {
                "type": "text",
                "content": reply_content
            }
        else:
            # åŒ…å«åª’ä½“çš„å›å¤
            reply_data = reply_content
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå…³é”®è¯
        for item in data:
            if item.get("keyword") == keyword:
                # æ›´æ–°ç°æœ‰è¯æ¡
                item["reply"] = reply_data
                item["uin"] = str(user_id)
                item["created_at"] = datetime.now().isoformat()
                self.save_data(file_path, data)
                return True
          # æ·»åŠ æ–°è¯æ¡
        new_item = {
            "keyword": keyword,
            "reply": reply_data,
            "created_at": datetime.now().isoformat()
        }
        
        if is_group:
            new_item["uin"] = str(user_id)
        
        data.append(new_item)
        self.save_data(file_path, data)
        return True
    
    def delete_lexicon(self, file_path: Path, keyword: str) -> bool:
        """åˆ é™¤è¯æ¡"""
        data = self.load_data(file_path)
        original_len = len(data)
        data = [item for item in data if item.get("keyword") != keyword]
        
        if len(data) < original_len:
            self.save_data(file_path, data)
            return True
        return False
    
    def search_reply(self, keyword: str, group_id: Optional[int] = None, user_id: Optional[int] = None) -> Optional[Union[str, Dict]]:
        """æœç´¢è¯æ¡å›å¤"""
        # ä¼˜å…ˆçº§ï¼šç¾¤è¯åº“ > ç”¨æˆ·è¯åº“ > å…¨å±€è¯åº“
        
        if group_id:
            # æœç´¢ç¾¤è¯åº“
            group_data = self.load_data(self.get_group_file_path(group_id))
            for item in group_data:
                if item.get("keyword") == keyword:
                    return item.get("reply")
        
        if user_id:
            # æœç´¢ç”¨æˆ·è¯åº“
            user_data = self.load_data(self.get_user_file_path(user_id))
            for item in user_data:
                if item.get("keyword") == keyword:
                    return item.get("reply")
        
        # æœç´¢å…¨å±€è¯åº“
        global_data = self.load_data(self.get_global_file_path())
        for item in global_data:
            if item.get("keyword") == keyword:
                return item.get("reply")
        
        return None
    
    async def build_reply_message(self, reply_data: Union[str, Dict]) -> Message:
        """æ„å»ºå›å¤æ¶ˆæ¯ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€è¯­éŸ³"""
        if isinstance(reply_data, str):
            # å‘åå…¼å®¹ï¼šçº¯æ–‡æœ¬å›å¤
            return Message(reply_data)
        
        if not isinstance(reply_data, dict):
            return Message("å›å¤æ•°æ®æ ¼å¼é”™è¯¯")
        
        reply_type = reply_data.get("type", "text")
        message = Message()
        
        if reply_type == "text":
            # çº¯æ–‡æœ¬
            content = reply_data.get("content", "")
            if content:
                message += MessageSegment.text(content)
        
        elif reply_type in ["media", "mixed"]:
            # åŒ…å«åª’ä½“å†…å®¹            # æ·»åŠ æ–‡æœ¬éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
            text_content = reply_data.get("content", "")
            if text_content:
                message += MessageSegment.text(text_content)
            
            # æ·»åŠ åª’ä½“æ–‡ä»¶
            media_files = reply_data.get("media_files", [])
            for media in media_files:
                media_type = media.get("type")
                filename = media.get("filename")
                
                if not filename:
                    continue
                
                if media_type == "image":
                    file_path = self.get_media_file_path(filename, "image")
                    if file_path.exists():
                        # ä½¿ç”¨ base64 ç¼–ç å‘é€å›¾ç‰‡
                        try:
                            import base64
                            with open(file_path, 'rb') as f:
                                image_data = f.read()
                            base64_data = base64.b64encode(image_data).decode()
                            message += MessageSegment.image(f"base64://{base64_data}")
                        except Exception as e:
                            logger.error(f"è¯»å–å›¾ç‰‡æ–‡ä»¶å¤±è´¥: {filename}, é”™è¯¯: {e}")
                    else:
                        logger.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
                
                elif media_type == "voice":
                    file_path = self.get_media_file_path(filename, "voice")
                    if file_path.exists():
                        # ä½¿ç”¨ base64 ç¼–ç å‘é€è¯­éŸ³
                        try:
                            import base64
                            with open(file_path, 'rb') as f:
                                voice_data = f.read()
                            base64_data = base64.b64encode(voice_data).decode()
                            message += MessageSegment.record(f"base64://{base64_data}")
                        except Exception as e:
                            logger.error(f"è¯»å–è¯­éŸ³æ–‡ä»¶å¤±è´¥: {filename}, é”™è¯¯: {e}")
                    else:
                        logger.warning(f"è¯­éŸ³æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        
        return message if message else Message("å›å¤å†…å®¹ä¸ºç©º")

# åˆå§‹åŒ–è¯åº“ç®¡ç†å™¨
lexicon_manager = LexiconManager(os.path.join(config.data_path, "lexicon"))

# è¯æ¡æ·»åŠ å‘½ä»¤
add_lexicon = on_command("æ·»åŠ è¯æ¡", priority=5, block=True)
add_global_lexicon = on_command("å…¨å±€æ·»åŠ è¯æ¡", priority=5, block=True, permission=SUPERUSER)
delete_lexicon_cmd = on_command("åˆ é™¤è¯æ¡", priority=5, block=True)
delete_global_lexicon = on_command("å…¨å±€åˆ é™¤è¯æ¡", priority=5, block=True, permission=SUPERUSER)
add_blacklist = on_command("æ·»åŠ è¯æ¡é»‘åå•", priority=5, block=True, permission=SUPERUSER)
view_lexicon = on_command("æŸ¥çœ‹è¯åº“", priority=5, block=True)
view_global_lexicon = on_command("æŸ¥çœ‹å…¨å±€è¯åº“", priority=5, block=True, permission=SUPERUSER)
lexicon_help = on_command("è¯åº“å¸®åŠ©", aliases={"è¯æ¡å¸®åŠ©"}, priority=10, block=True)

# ä½¿ç”¨äº‹ä»¶åå¤„ç†å™¨æ¥å¤„ç†è¯æ¡è§¦å‘
@event_postprocessor
async def lexicon_postprocessor(
    bot: Bot,
    event: MessageEvent,
):
    """è¯æ¡åå¤„ç†å™¨"""
    # å±è”½æœºå™¨äººè‡ªå·±å‘çš„æ¶ˆæ¯
    if event.user_id == int(bot.self_id):
        return
    
    user_id = event.user_id
    message_text = event.message.extract_plain_text().strip()
    
    # ç¡®å®šä¸Šä¸‹æ–‡ID
    if isinstance(event, GroupMessageEvent):
        context_id = f"group_{event.group_id}_{user_id}"
        global_context_id = f"global_group_{event.group_id}_{user_id}"
    else:
        context_id = f"user_{user_id}"
        global_context_id = f"global_user_{user_id}"    # å¤„ç†ç­‰å¾…çŠ¶æ€
    if context_id in waiting_users or global_context_id in waiting_users:
        wait_info = waiting_users.get(context_id) or waiting_users.get(global_context_id)
        current_context_id = context_id if context_id in waiting_users else global_context_id
        
        if wait_info and wait_info["user_id"] == user_id:  # åªå¤„ç†å¯¹åº”ç”¨æˆ·çš„æ¶ˆæ¯
            # æ£€æŸ¥æ˜¯å¦åˆšåˆšè®¾ç½®ç­‰å¾…çŠ¶æ€ï¼ˆé¿å…å¤„ç†æç¤ºæ¶ˆæ¯æœ¬èº«ï¼‰
            if "start_time" in wait_info:
                time_diff = (datetime.now() - wait_info["start_time"]).total_seconds()
                if time_diff < 2:  # 2ç§’å†…çš„æ¶ˆæ¯å¿½ç•¥ï¼Œé¿å…å¤„ç†æç¤ºæ¶ˆæ¯
                    return
              # æ£€æŸ¥å–æ¶ˆå‘½ä»¤
            if message_text == "/æˆ‘ä¸å†™äº†":
                # æ’¤å›æç¤ºæ¶ˆæ¯
                try:
                    if "message_id" in wait_info:
                        await bot.delete_msg(message_id=wait_info["message_id"])
                except:
                    pass
                
                del waiting_users[current_context_id]
                await bot.send(event, "æ“ä½œå·²å–æ¶ˆ")
                return
            
            # å¤„ç†ç­‰å¾…è¾“å…¥
            if wait_info["step"] == "keyword":
                # ç­‰å¾…å…³é”®è¯
                keyword = message_text
                waiting_users[current_context_id]["keyword"] = keyword
                waiting_users[current_context_id]["step"] = "reply"
                waiting_users[current_context_id]["start_time"] = datetime.now()  # é‡ç½®å¼€å§‹æ—¶é—´
                
                # å»¶è¿Ÿä¸€ä¸‹å†æ’¤å›ä¸Šä¸€æ¡æç¤ºæ¶ˆæ¯ï¼Œé¿å…å¤ªå¿«æ’¤å›
                await asyncio.sleep(0.5)
                try:
                    if "message_id" in wait_info:
                        await bot.delete_msg(message_id=wait_info["message_id"])
                except:
                    pass
                  # å‘é€æ–°æç¤º
                is_global = wait_info.get("is_global", False)
                msg = await bot.send(event, f"ä¸‹ä¸€æ­¥:è¯·åœ¨ä¸€åˆ†é’Ÿå†…å†™å‡ºå›å¤è¯(å¯ä»¥æ˜¯æ–‡æœ¬ã€å›¾ç‰‡æˆ–è¯­éŸ³)\næˆ–è€…è¯´:/æˆ‘ä¸å†™äº† å–æ¶ˆæ“ä½œ")
                waiting_users[current_context_id]["message_id"] = msg["message_id"]
                  # é‡æ–°è®¾ç½®è¶…æ—¶ä»»åŠ¡
                asyncio.create_task(timeout_task(current_context_id, config.lexicon_timeout))
                return
                
            elif wait_info["step"] == "reply":
                # ç­‰å¾…å›å¤è¯ï¼ˆæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€è¯­éŸ³ï¼‰
                reply_content = await lexicon_manager.parse_message_content(event.message)
                keyword = wait_info["keyword"]
                file_path = wait_info["file_path"]
                is_group = wait_info["is_group"]
                
                # å»¶è¿Ÿä¸€ä¸‹å†æ’¤å›æç¤ºæ¶ˆæ¯
                await asyncio.sleep(0.5)
                try:
                    if "message_id" in wait_info:
                        await bot.delete_msg(message_id=wait_info["message_id"])
                except:
                    pass
                
                # æ·»åŠ è¯æ¡
                await lexicon_manager.add_lexicon(file_path, keyword, reply_content, user_id, is_group)
                del waiting_users[current_context_id]
                await bot.send(event, "æ·»åŠ æˆåŠŸï¼")
                return
      # åªæœ‰åœ¨æ²¡æœ‰ç­‰å¾…çŠ¶æ€æ—¶æ‰è¿›è¡Œè¯æ¡è§¦å‘
    # å¹¶ä¸”ä¸æ˜¯å‘½ä»¤æ¶ˆæ¯æ—¶æ‰æ£€æŸ¥è¯æ¡
    if (not message_text.startswith('/') and 
        not lexicon_manager.is_blacklisted(user_id) and
        not (context_id in waiting_users or global_context_id in waiting_users)):
        
        group_id = event.group_id if isinstance(event, GroupMessageEvent) else None
        reply = lexicon_manager.search_reply(message_text, group_id, user_id)
        
        if reply:
            # æ„å»ºå¹¶å‘é€å›å¤æ¶ˆæ¯
            reply_message = await lexicon_manager.build_reply_message(reply)
            await bot.send(event, reply_message)

@add_lexicon.handle()
async def handle_add_lexicon(bot: Bot, event: MessageEvent, matcher: Matcher, args: Message = CommandArg()):
    """å¤„ç†æ·»åŠ è¯æ¡å‘½ä»¤"""
    user_id = event.user_id
    
    # æ£€æŸ¥é»‘åå•
    if lexicon_manager.is_blacklisted(user_id):
        return  # é™é»˜å¤„ç†ï¼Œä¸å‘é€ä»»ä½•æ¶ˆæ¯
    
    args_text = args.extract_plain_text().strip()
    
    # ç¡®å®šå­˜å‚¨è·¯å¾„
    if isinstance(event, GroupMessageEvent):
        file_path = lexicon_manager.get_group_file_path(event.group_id)
        context_id = f"group_{event.group_id}_{user_id}"
        is_group = True
    else:
        file_path = lexicon_manager.get_user_file_path(user_id)
        context_id = f"user_{user_id}"
        is_group = False
    
    if not args_text:
        # /æ·»åŠ è¯æ¡ - ç­‰å¾…å…³é”®è¯
        waiting_users[context_id] = {
            "step": "keyword",
            "user_id": user_id,
            "file_path": file_path,
            "is_group": is_group,
            "start_time": datetime.now()
        }
        msg = await matcher.send("ä½ å·²è§¦å‘æ·»åŠ è¯æ¡åŠŸèƒ½(ä»…æœ¬ç¾¤)\nè¯·åœ¨1åˆ†é’Ÿå†…å†™å‡ºå…³é”®è¯\næˆ–è€…è¯´:/æˆ‘ä¸å†™äº† å–æ¶ˆæ“ä½œ")
        waiting_users[context_id]["message_id"] = msg["message_id"]
        
        # è®¾ç½®è¶…æ—¶ä»»åŠ¡
        asyncio.create_task(timeout_task(context_id, config.lexicon_timeout))
        
    else:
        parts = args_text.split(None, 1)
        if len(parts) == 1:
            # /æ·»åŠ è¯æ¡ å…³é”®è¯ - ç­‰å¾…å›å¤è¯
            keyword = parts[0]
            waiting_users[context_id] = {
                "step": "reply",
                "keyword": keyword,
                "user_id": user_id,
                "file_path": file_path,
                "is_group": is_group,
                "start_time": datetime.now()
            }
            msg = await matcher.send("ä½ å·²è§¦å‘æ·»åŠ è¯æ¡åŠŸèƒ½(ä»…æœ¬ç¾¤)\nè¯·åœ¨1åˆ†é’Ÿå†…å†™å‡ºå›å¤æ¶ˆæ¯(å¯ä»¥æ˜¯æ–‡æœ¬ã€å›¾ç‰‡æˆ–è¯­éŸ³)\næˆ–è€…è¯´:/æˆ‘ä¸å†™äº† å–æ¶ˆæ“ä½œ")
            waiting_users[context_id]["message_id"] = msg["message_id"]
              # è®¾ç½®è¶…æ—¶ä»»åŠ¡
            asyncio.create_task(timeout_task(context_id, config.lexicon_timeout))
            
        elif len(parts) == 2:
            # /æ·»åŠ è¯æ¡ å…³é”®è¯ å›å¤è¯ - ç›´æ¥æ·»åŠ 
            keyword, reply = parts
            await lexicon_manager.add_lexicon(file_path, keyword, reply, user_id, is_group)
            await matcher.finish("æ·»åŠ æˆåŠŸï¼")

@add_global_lexicon.handle()
async def handle_add_global_lexicon(bot: Bot, event: MessageEvent, matcher: Matcher, args: Message = CommandArg()):
    """å¤„ç†å…¨å±€æ·»åŠ è¯æ¡å‘½ä»¤"""
    user_id = event.user_id
    
    # æ£€æŸ¥é»‘åå•
    if lexicon_manager.is_blacklisted(user_id):
        return  # é™é»˜å¤„ç†ï¼Œä¸å‘é€ä»»ä½•æ¶ˆæ¯
    
    args_text = args.extract_plain_text().strip()
    file_path = lexicon_manager.get_global_file_path()
    
    if isinstance(event, GroupMessageEvent):
        context_id = f"global_group_{event.group_id}_{user_id}"
    else:
        context_id = f"global_user_{user_id}"
    
    if not args_text:
        # /å…¨å±€æ·»åŠ è¯æ¡ - ç­‰å¾…å…³é”®è¯
        waiting_users[context_id] = {
            "step": "keyword",
            "user_id": user_id,
            "file_path": file_path,
            "is_group": False,
            "is_global": True,
            "start_time": datetime.now()
        }
        msg = await matcher.send("ä½ å·²è§¦å‘æ·»åŠ è¯æ¡åŠŸèƒ½(å…¨å±€æ¨¡å¼)\nè¯·åœ¨ä¸€åˆ†é’Ÿå†…å†™å‡ºå…³é”®è¯\næˆ–è€…è¯´:/æˆ‘ä¸å†™äº† å–æ¶ˆæ“ä½œ")
        waiting_users[context_id]["message_id"] = msg["message_id"]
        
        # è®¾ç½®è¶…æ—¶ä»»åŠ¡
        asyncio.create_task(timeout_task(context_id, config.lexicon_timeout))
        
    else:
        parts = args_text.split(None, 1)
        if len(parts) == 1:
            # /å…¨å±€æ·»åŠ è¯æ¡ å…³é”®è¯ - ç­‰å¾…å›å¤è¯
            keyword = parts[0]
            waiting_users[context_id] = {
                "step": "reply",
                "keyword": keyword,
                "user_id": user_id,
                "file_path": file_path,
                "is_group": False,
                "is_global": True,
                "start_time": datetime.now()
            }
            msg = await matcher.send("ä½ å·²è§¦å‘æ·»åŠ è¯æ¡åŠŸèƒ½(å…¨å±€æ¨¡å¼)\nè¯·åœ¨1åˆ†é’Ÿå†…å†™å‡ºå›å¤æ¶ˆæ¯(å¯ä»¥æ˜¯æ–‡æœ¬ã€å›¾ç‰‡æˆ–è¯­éŸ³)\næˆ–è€…è¯´:/æˆ‘ä¸å†™äº† å–æ¶ˆæ“ä½œ")
            waiting_users[context_id]["message_id"] = msg["message_id"]
              # è®¾ç½®è¶…æ—¶ä»»åŠ¡
            asyncio.create_task(timeout_task(context_id, config.lexicon_timeout))
            
        elif len(parts) == 2:
            # /å…¨å±€æ·»åŠ è¯æ¡ å…³é”®è¯ å›å¤è¯ - ç›´æ¥æ·»åŠ 
            keyword, reply = parts
            await lexicon_manager.add_lexicon(file_path, keyword, reply, user_id, False)
            await matcher.finish("æ·»åŠ æˆåŠŸï¼")

@delete_lexicon_cmd.handle()
async def handle_delete_lexicon(bot: Bot, event: MessageEvent, matcher: Matcher, args: Message = CommandArg()):
    """å¤„ç†åˆ é™¤è¯æ¡å‘½ä»¤"""
    user_id = event.user_id
    
    # æ£€æŸ¥é»‘åå•
    if lexicon_manager.is_blacklisted(user_id):
        return  # é™é»˜å¤„ç†ï¼Œä¸å‘é€ä»»ä½•æ¶ˆæ¯
    
    keyword = args.extract_plain_text().strip()
    if not keyword:
        await matcher.finish("è¯·è¾“å…¥è¦åˆ é™¤çš„å…³é”®è¯")
    
    # ç¡®å®šåˆ é™¤è·¯å¾„
    if isinstance(event, GroupMessageEvent):
        file_path = lexicon_manager.get_group_file_path(event.group_id)
    else:
        file_path = lexicon_manager.get_user_file_path(user_id)
    
    if lexicon_manager.delete_lexicon(file_path, keyword):
        await matcher.finish("åˆ é™¤æˆåŠŸï¼")
    else:
        await matcher.finish("æœªæ‰¾åˆ°è¯¥å…³é”®è¯")

@delete_global_lexicon.handle()
async def handle_delete_global_lexicon(bot: Bot, event: MessageEvent, matcher: Matcher, args: Message = CommandArg()):
    """å¤„ç†å…¨å±€åˆ é™¤è¯æ¡å‘½ä»¤"""
    user_id = event.user_id
    
    keyword = args.extract_plain_text().strip()
    if not keyword:
        await matcher.finish("è¯·è¾“å…¥è¦åˆ é™¤çš„å…³é”®è¯")
    
    file_path = lexicon_manager.get_global_file_path()
    
    if lexicon_manager.delete_lexicon(file_path, keyword):
        await matcher.finish("åˆ é™¤æˆåŠŸï¼")
    else:
        await matcher.finish("æœªæ‰¾åˆ°è¯¥å…³é”®è¯")

@add_blacklist.handle()
async def handle_add_blacklist(bot: Bot, event: MessageEvent, matcher: Matcher, args: Message = CommandArg()):
    """å¤„ç†æ·»åŠ è¯æ¡é»‘åå•å‘½ä»¤"""
    user_id = event.user_id
    
    target_qq = args.extract_plain_text().strip()
    if not target_qq.isdigit():
        await matcher.finish("è¯·è¾“å…¥æ­£ç¡®çš„QQå·")
    
    target_qq = int(target_qq)
    lexicon_manager.add_to_blacklist(target_qq)
    await matcher.finish(f"å·²å°† {target_qq} æ·»åŠ åˆ°è¯æ¡é»‘åå•")

@view_lexicon.handle()
async def handle_view_lexicon(bot: Bot, event: MessageEvent, matcher: Matcher):
    """å¤„ç†æŸ¥çœ‹è¯åº“å‘½ä»¤"""
    user_id = event.user_id
      # æ£€æŸ¥é»‘åå•
    if lexicon_manager.is_blacklisted(user_id):
        return  # é™é»˜å¤„ç†ï¼Œä¸å‘é€ä»»ä½•æ¶ˆæ¯
    
    # ç¡®å®šè¯åº“è·¯å¾„
    if isinstance(event, GroupMessageEvent):
        file_path = lexicon_manager.get_group_file_path(event.group_id)
        scope_text = f"ç¾¤ {event.group_id}"
    else:
        file_path = lexicon_manager.get_user_file_path(user_id)
        scope_text = "ä¸ªäºº"
      # åŠ è½½è¯åº“æ•°æ®
    data = lexicon_manager.load_data(file_path)
    
    if not data:
        await matcher.finish(f"ğŸ“š {scope_text}è¯åº“ä¸ºç©º")
    
    try:
        # æ„å»ºåˆå¹¶æ¶ˆæ¯ - æ¯ä¸ªè¯æ¡ä¸¤æ¡æ¶ˆæ¯
        messages = []
        
        for i, item in enumerate(data, 1):
            keyword = item.get("keyword", "æœªçŸ¥")
            reply_data = item.get("reply", {})
            
            # ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼šå…³é”®è¯ï¼ˆå¸¦åºå·ï¼‰
            keyword_text = f"{i}. {keyword}"
            messages.append(MessageSegment.node_custom(
                user_id=user_id,
                nickname="æŸšå­å¨",
                content=Message(keyword_text)
            ))
            
            # ç¬¬äºŒæ¡æ¶ˆæ¯ï¼šå›å¤å†…å®¹
            if isinstance(reply_data, str):
                # å…¼å®¹æ—§æ ¼å¼çš„çº¯æ–‡æœ¬å›å¤
                reply_content = reply_data
            elif isinstance(reply_data, dict):
                reply_type = reply_data.get("type", "text")
                if reply_type == "text":
                    reply_content = reply_data.get("content", "")
                elif reply_type == "media":
                    media_files = reply_data.get("media_files", [])
                    media_count = len(media_files)
                    media_types = [m.get("type", "æœªçŸ¥") for m in media_files]
                    type_text = "ã€".join(set(media_types))
                    reply_content = f"[åª’ä½“æ–‡ä»¶: {type_text} ({media_count}ä¸ª)]"
                elif reply_type == "mixed":
                    content = reply_data.get("content", "")
                    media_files = reply_data.get("media_files", [])
                    media_count = len(media_files)
                    reply_content = f"{content} [+{media_count}ä¸ªåª’ä½“æ–‡ä»¶]"
                else:
                    reply_content = "[æœªçŸ¥æ ¼å¼]"
            else:
                reply_content = "[æ ¼å¼é”™è¯¯]"
            
            messages.append(MessageSegment.node_custom(
                user_id=int(bot.self_id),
                nickname="Cialloï½(âˆ ãƒ»Ï‰< )âŒ’â˜…",
                content=Message(reply_content)
            ))
        
        # å‘é€åˆå¹¶æ¶ˆæ¯
        if isinstance(event, GroupMessageEvent):
            await bot.send_group_forward_msg(
                group_id=event.group_id,
                messages=messages
            )
        else:
            await bot.send_private_forward_msg(
                user_id=user_id,
                messages=messages
            )
        
    except Exception as e:
        logger.error(f"å‘é€è¯åº“ä¿¡æ¯å¤±è´¥: {e}")
        # å‘é€å¤±è´¥å°±é™é»˜å¤„ç†ï¼Œä¸å‘é€ä»»ä½•æ¶ˆæ¯

@view_global_lexicon.handle()
async def handle_view_global_lexicon(bot: Bot, event: MessageEvent, matcher: Matcher):
    """å¤„ç†æŸ¥çœ‹å…¨å±€è¯åº“å‘½ä»¤"""
    user_id = event.user_id
    
    # è·å–å…¨å±€è¯åº“è·¯å¾„
    file_path = lexicon_manager.get_global_file_path()
      # åŠ è½½è¯åº“æ•°æ®
    data = lexicon_manager.load_data(file_path)
    
    if not data:
        await matcher.finish("ğŸ“š å…¨å±€è¯åº“ä¸ºç©º")
    
    try:
        # æ„å»ºåˆå¹¶æ¶ˆæ¯ - æ¯ä¸ªè¯æ¡ä¸¤æ¡æ¶ˆæ¯
        messages = []
        
        for i, item in enumerate(data, 1):
            keyword = item.get("keyword", "æœªçŸ¥")
            reply_data = item.get("reply", {})
            
            # ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼šå…³é”®è¯ï¼ˆå¸¦åºå·ï¼‰
            keyword_text = f"{i}. {keyword}"
            messages.append(MessageSegment.node_custom(
                user_id=user_id,
                nickname="æŸšå­å¨",
                content=Message(keyword_text)
            ))
            
            # ç¬¬äºŒæ¡æ¶ˆæ¯ï¼šå›å¤å†…å®¹
            if isinstance(reply_data, str):
                # å…¼å®¹æ—§æ ¼å¼çš„çº¯æ–‡æœ¬å›å¤
                reply_content = reply_data
            elif isinstance(reply_data, dict):
                reply_type = reply_data.get("type", "text")
                if reply_type == "text":
                    reply_content = reply_data.get("content", "")
                elif reply_type == "media":
                    media_files = reply_data.get("media_files", [])
                    media_count = len(media_files)
                    media_types = [m.get("type", "æœªçŸ¥") for m in media_files]
                    type_text = "ã€".join(set(media_types))
                    reply_content = f"[åª’ä½“æ–‡ä»¶: {type_text} ({media_count}ä¸ª)]"
                elif reply_type == "mixed":
                    content = reply_data.get("content", "")
                    media_files = reply_data.get("media_files", [])
                    media_count = len(media_files)
                    reply_content = f"{content} [+{media_count}ä¸ªåª’ä½“æ–‡ä»¶]"
                else:
                    reply_content = "[æœªçŸ¥æ ¼å¼]"
            else:
                reply_content = "[æ ¼å¼é”™è¯¯]"
            
            messages.append(MessageSegment.node_custom(
                user_id=int(bot.self_id),
                nickname="Cialloï½(âˆ ãƒ»Ï‰< )âŒ’â˜…",
                content=Message(reply_content)
            ))
        
        # å‘é€åˆå¹¶æ¶ˆæ¯
        if isinstance(event, GroupMessageEvent):
            await bot.send_group_forward_msg(
                group_id=event.group_id,
                messages=messages
            )
        else:
            await bot.send_private_forward_msg(
                user_id=user_id,
                messages=messages
            )
        
    except Exception as e:
        logger.error(f"å‘é€å…¨å±€è¯åº“ä¿¡æ¯å¤±è´¥: {e}")
        # å‘é€å¤±è´¥å°±é™é»˜å¤„ç†ï¼Œä¸å‘é€ä»»ä½•æ¶ˆæ¯

@lexicon_help.handle()
async def handle_lexicon_help(bot: Bot, event: MessageEvent, matcher: Matcher):
    """æ˜¾ç¤ºè¯åº“åŠŸèƒ½å¸®åŠ©"""
    help_text = """ğŸ“š è¯åº“åŠŸèƒ½å¸®åŠ©
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ è¯æ¡ç®¡ç†ï¼š
  â”œ /æ·»åŠ è¯æ¡ [å…³é”®è¯] [å›å¤] - æ·»åŠ ç¾¤/ä¸ªäººè¯æ¡
  â”œ /å…¨å±€æ·»åŠ è¯æ¡ [å…³é”®è¯] [å›å¤] - æ·»åŠ å…¨å±€è¯æ¡(è¶…çº§ç”¨æˆ·)
  â”œ /åˆ é™¤è¯æ¡ å…³é”®è¯ - åˆ é™¤ç¾¤/ä¸ªäººè¯æ¡
  â”” /å…¨å±€åˆ é™¤è¯æ¡ å…³é”®è¯ - åˆ é™¤å…¨å±€è¯æ¡(è¶…çº§ç”¨æˆ·)

ğŸ“‹ è¯åº“æŸ¥çœ‹ï¼š
  â”œ /æŸ¥çœ‹è¯åº“ - æŸ¥çœ‹å½“å‰ç¾¤/ä¸ªäººè¯åº“(åˆå¹¶æ¶ˆæ¯)
  â”” /æŸ¥çœ‹å…¨å±€è¯åº“ - æŸ¥çœ‹å…¨å±€è¯åº“(è¶…çº§ç”¨æˆ·)

ğŸš« é»‘åå•ç®¡ç†ï¼š
  â”” /æ·»åŠ è¯æ¡é»‘åå• QQå· - ç¦ç”¨ç”¨æˆ·è¯æ¡åŠŸèƒ½(è¶…çº§ç”¨æˆ·)

ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š
  â€¢ æ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€è¯­éŸ³ã€æ··åˆæ¶ˆæ¯
  â€¢ ä¼˜å…ˆçº§ï¼šç¾¤è¯åº“ > ä¸ªäººè¯åº“ > å…¨å±€è¯åº“
  â€¢ æ·»åŠ è¯æ¡æ”¯æŒåˆ†æ­¥æ“ä½œå’Œä¸€æ¬¡æ€§è¾“å…¥
  â€¢ æŸ¥çœ‹è¯åº“ä½¿ç”¨åˆå¹¶æ¶ˆæ¯å±•ç¤ºï¼Œå¤±è´¥æ—¶è‡ªåŠ¨é™çº§
  â€¢ è¯æ¡è§¦å‘æ— éœ€æŒ‡ä»¤å¤´ï¼Œç›´æ¥å‘é€å…³é”®è¯å³å¯

ğŸ¯ æ·»åŠ ç¤ºä¾‹ï¼š
  â”œ /æ·»åŠ è¯æ¡ â†’ åˆ†æ­¥å¼•å¯¼æ·»åŠ 
  â”œ /æ·»åŠ è¯æ¡ ä½ å¥½ â†’ ç­‰å¾…å›å¤å†…å®¹
  â”œ /æ·»åŠ è¯æ¡ ä½ å¥½ Hello! â†’ ç›´æ¥æ·»åŠ 
  â”” æ”¯æŒå›¾ç‰‡ã€è¯­éŸ³ç­‰å¤šåª’ä½“å†…å®¹

ğŸ” æŸ¥çœ‹ç¤ºä¾‹ï¼š
  â€¢ /æŸ¥çœ‹è¯åº“ â†’ æ˜¾ç¤ºå½“å‰ç¾¤è¯åº“(2æ¡æ¶ˆæ¯)
    1ï¸âƒ£ å…³é”®è¯åˆ—è¡¨(å¸¦åºå·)
    2ï¸âƒ£ å¯¹åº”å›å¤å†…å®¹

âš ï¸ æ³¨æ„äº‹é¡¹ï¼š
  â€¢ å…¨å±€åŠŸèƒ½ä»…è¶…çº§ç”¨æˆ·å¯ç”¨
  â€¢ è¢«æ‹‰é»‘ç”¨æˆ·æ— æ³•ä½¿ç”¨è¯æ¡åŠŸèƒ½
  â€¢ åª’ä½“æ–‡ä»¶è‡ªåŠ¨ä¸‹è½½å­˜å‚¨åˆ°æœ¬åœ°
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Cialloï½(âˆ ãƒ»Ï‰< )âŒ’â˜…"""
    
    await matcher.finish(help_text)

async def timeout_task(context_id: str, timeout: int):
    """è¶…æ—¶ä»»åŠ¡"""
    await asyncio.sleep(timeout)
    
    if context_id in waiting_users:
        wait_info = waiting_users[context_id]
        
        # æ’¤å›æç¤ºæ¶ˆæ¯
        try:
            bot = get_bot()
            if "message_id" in wait_info:
                await bot.delete_msg(message_id=wait_info["message_id"])
        except:
            pass
        
        del waiting_users[context_id]
        logger.info(f"è¯æ¡æ·»åŠ è¶…æ—¶ï¼Œå·²æ¸…ç†ç­‰å¾…çŠ¶æ€: {context_id}")
