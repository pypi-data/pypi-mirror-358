{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import os\n",
    "\n",
    "# 1. å¯åŠ¨ H2O å¹¶è®¾ç½®æ—¥å¿—ç›®å½•\n",
    "h2o.init(log_dir=\"classifier_fast_logs\", log_level=\"INFO\")\n",
    "\n",
    "# 2. å¯¼å…¥æ•°æ®\n",
    "data = h2o.import_file(\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv\")\n",
    "x = data.columns[:-1]\n",
    "y = \"class\"\n",
    "data[y] = data[y].asfactor()\n",
    "\n",
    "# 3. åˆ’åˆ†æ•°æ®é›†\n",
    "train, test = data.split_frame(ratios=[0.8], seed=1234)\n",
    "\n",
    "# 4. è®­ç»ƒ AutoML\n",
    "aml = H2OAutoML(max_runtime_secs=60, max_models=5, seed=1, project_name=\"iris_classification\")\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# 7. æŸ¥çœ‹æ’è¡Œæ¦œ\n",
    "lb = aml.leaderboard\n",
    "print(lb.head(rows=lb.nrows))\n",
    "\n",
    "\n",
    "# æ—¥å¿—å·²è‡ªåŠ¨ä¿å­˜åœ¨ h2o_logs ç›®å½•\n"
   ],
   "id": "aa0b8c83a6229f99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# 8. ä¿å­˜æ‰€æœ‰æ¨¡å‹\n",
    "model_dir = \"h2o_classifier_fast_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# è·å–æ‰€æœ‰æ¨¡å‹ID\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "\n",
    "for mid in model_ids:\n",
    "    model = h2o.get_model(mid)\n",
    "    model_path = h2o.save_model(model=model, path=model_dir, force=True)\n",
    "    print(f\"Saved model {mid} to {model_path}\")\n",
    "\n",
    "# 5. è¯„ä¼°æ¨¡å‹\n",
    "print(aml.leaderboard)\n",
    "perf = aml.leader.model_performance(test)\n",
    "print(perf)\n",
    "\n",
    "# 6. ä¿å­˜æ¨¡å‹\n",
    "model_path = h2o.save_model(model=aml.leader, path=\"./saved_model\", force=True)\n",
    "print(f\"Model saved to: {model_path}\")"
   ],
   "id": "cdc3ceca244d943a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "aml.leaderboard",
   "id": "88a92fd470c71274"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "h2o.get_model(\"GLM_1_AutoML_1_20250508_154028\")",
   "id": "a0f3916decd4f07b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. è·å–æ’è¡Œæ¦œç¬¬ä¸€åæ¨¡å‹çš„ID\n",
    "model_id = lb.as_data_frame().iloc[0, 0]  # ç¬¬ä¸€è¡Œç¬¬ä¸€åˆ—æ˜¯ model_id\n",
    "\n",
    "# 2. åŠ è½½è¯¥æ¨¡å‹\n",
    "model = h2o.get_model(model_id)\n",
    "data1 = test.as_data_frame()\n",
    "# 3. ç”¨æ¨¡å‹å¯¹ test æ•°æ®é›†åšé¢„æµ‹\n",
    "pred = model.predict(data1)\n",
    "\n",
    "# 4. æŸ¥çœ‹é¢„æµ‹ç»“æœ\n",
    "print(pred.head())"
   ],
   "id": "77bb07c3cf41f57a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://9.134.212.179:5000\")\n",
    "mlflow.set_experiment(\"h2o_test_1\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.h2o.log_model(model, \"my_model\")\n",
    "\n"
   ],
   "id": "6420014188c9f654"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2. æ„é€ æ¨¡å‹ artifact è·¯å¾„\n",
    "model_uri = f\"runs:/4b78875831d8428faa510fa276df5719/my_model\"\n",
    "\n",
    "# 3. åŠ è½½æ¨¡å‹\n",
    "model1 = mlflow.h2o.load_model(model_uri)"
   ],
   "id": "64f6478c41ef0c45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model1.predict(test)",
   "id": "115cd46ae539b0f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test",
   "id": "70455c1f37f000ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import h2o\n",
    "from wedata.automl.h2o import WeDataH2oAutoML\n",
    "import os\n",
    "\n",
    "# 1. å¯åŠ¨ H2O å¹¶è®¾ç½®æ—¥å¿—ç›®å½•\n",
    "h2o.init(log_dir=\"classifier_fast_logs\", log_level=\"INFO\")\n",
    "\n",
    "# 2. å¯¼å…¥æ•°æ®\n",
    "data = h2o.import_file(\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv\")\n",
    "x = data.columns[:-1]\n",
    "y = \"class\"\n",
    "data[y] = data[y].asfactor()\n",
    "\n",
    "# 3. åˆ’åˆ†æ•°æ®é›†\n",
    "train, test = data.split_frame(ratios=[0.8], seed=1234)\n",
    "\n",
    "# 4. è®­ç»ƒ AutoML\n",
    "# aml = H2OAutoML(max_runtime_secs=60, max_models=5, seed=1, project_name=\"iris_classification\")\n",
    "# aml.train(x=x, y=y, training_frame=train)\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://9.134.212.179:5000\")\n",
    "mlflow.set_experiment(\"h2o_test_2\")\n",
    "\n",
    "waml = WeDataH2oAutoML(max_runtime_secs=60, max_models=5, seed=1, project_name=\"iris_classification\")\n",
    "waml.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "\n",
    "# 7. æŸ¥çœ‹æ’è¡Œæ¦œ\n",
    "lb = waml.leaderboard\n",
    "print(lb.head(rows=lb.nrows))\n",
    "\n",
    "\n",
    "# æ—¥å¿—å·²è‡ªåŠ¨ä¿å­˜åœ¨ h2o_logs ç›®å½•\n"
   ],
   "id": "c0c8d8d8db6279c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T07:54:45.423068Z",
     "start_time": "2025-06-26T07:54:12.417364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from wedata.ts_automl.flaml import WeDataTimeSeriesAutoML\n",
    "import mlflow\n",
    "import flaml\n",
    "from flaml import AutoML\n",
    "mlflow.set_tracking_uri(\"http://9.134.212.179:5000\")\n",
    "# æ„é€ æ—¶åºæ•°æ®\n",
    "X_train = np.arange(\"2014-01\", \"2022-01\", dtype=\"datetime64[M]\")\n",
    "y_train = np.random.random(size=84)\n",
    "# WeDataTimeSeriesAutoML è®­ç»ƒè®¾ç½®ï¼šæœ€å¤§è®­ç»ƒæ—¶é—´ä¸º 60sï¼Œè¯„ä»·æŒ‡æ ‡ä¸º accï¼Œæ¯ä¸ª Executor çš„å¹¶è¡Œåº¦ä¸º 2ï¼Œå¼€å¯å¼ºåˆ¶å–æ¶ˆï¼ˆå¼€å¯åï¼Œè¶…è¿‡æœ€å¤§è®­ç»ƒæ—¶é—´åå°†ç«‹å³åœæ­¢ï¼‰\n",
    "automl_settings = {\n",
    "    \"time_budget\": 10,\n",
    "    \"metric\": 'accuracy',\n",
    "    \"n_concurrent_trials\": 1,\n",
    "    \"use_spark\": True,\n",
    "    \"force_cancel\": False,  # Activating the force_cancel option can immediately halt Spark jobs once they exceed the allocated time_budget.\n",
    "}\n",
    "automl = WeDataTimeSeriesAutoML(settings=automl_settings)\n",
    "mlflow.set_experiment(\"wedata_demo\")\n",
    "\n",
    "# å¼€å§‹è®­ç»ƒï¼Œè¯·è®¾ç½® mlflow å®éªŒåå’Œä»»åŠ¡åï¼Œè®­ç»ƒä¸­å°†åŒæ­¥è®°å½•æ¨¡å‹å‚æ•°åˆ°å®éªŒç®¡ç†ï¼ŒåŒæ—¶è®°å½•æœ€ä¼˜æ¨¡å‹åˆ¶å“\n",
    "automl.fit(\n",
    "    X_train=X_train[:84],  # a single column of timestamp\n",
    "    y_train=y_train,  # value for each timestamp\n",
    "    period=12,  # time horizon to forecast, e.g., 12 months\n",
    "    task=\"ts_forecast\",\n",
    "    log_file_name=\"ts_forecast.log\",\n",
    "    eval_method=\"holdout\",\n",
    "    use_spark=True,\n",
    "    mlflow_experiment_name=\"wedata_demo\",\n",
    "    mlflow_run_name=\"test_ts_1\"\n",
    ")\n"
   ],
   "id": "a930265afab76e22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-26 15:54:12] {1728} INFO - task = ts_forecast\n",
      "[flaml.automl.logger: 06-26 15:54:12] {1739} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 06-26 15:54:12] {1838} INFO - Minimizing error metric: mape\n",
      "[flaml.automl.logger: 06-26 15:54:12] {1861} WARNING - No search budget is provided via time_budget or max_iter. Training only one model per estimator. Zero-shot AutoML is used for certain tasks and estimators. To tune hyperparameters for each estimator, please provide budget either via time_budget or max_iter.\n",
      "[flaml.automl.logger: 06-26 15:54:12] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'arima', 'sarimax', 'prophet']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-26 15:54:12,932] A new study created in memory with name: optuna\n",
      "2025/06/26 15:54:13 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run get_mlflow_log_latency at: http://9.134.212.179:5000/#/experiments/0/runs/12ed27d27c1e428f99775e63f7dadc25.\n",
      "2025/06/26 15:54:13 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://9.134.212.179:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-26 15:54:13] {2118} INFO - Estimated mlflow_log_latency: 0.8534200191497803 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-26 15:54:13,794] A new study created in memory with name: optuna\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 06-26 15:54:13] {796} INFO - Number of trials: 1/8, 1 RUNNING, 0 TERMINATED\n",
      "[flaml.tune.tune: 06-26 15:54:13] {819} INFO - Brief result: {'pred_time': 0.0015996893246968587, 'wall_clock_time': 0.9734647274017334, 'metric_for_logging': {'pred_time': 0.0015996893246968587}, 'val_loss': 2.979735271660923, 'trained_estimator': <flaml.automl.time_series.ts_model.LGBM_TS object at 0x7fa07c1e62b0>}\n",
      "[flaml.tune.tune: 06-26 15:54:13] {796} INFO - Number of trials: 2/8, 1 RUNNING, 1 TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 06-26 15:54:17] {819} INFO - Brief result: {'pred_time': 0.01662011941274007, 'wall_clock_time': 4.496348857879639, 'metric_for_logging': {'pred_time': 0.01662011941274007}, 'val_loss': 2.7281412126198443, 'trained_estimator': <flaml.automl.time_series.ts_model.RF_TS object at 0x7fa07c1ee2e0>}\n",
      "[flaml.tune.tune: 06-26 15:54:17] {796} INFO - Number of trials: 3/8, 1 RUNNING, 2 TERMINATED\n",
      "[flaml.tune.tune: 06-26 15:54:19] {819} INFO - Brief result: {'pred_time': 0.00552139679590861, 'wall_clock_time': 6.38783860206604, 'metric_for_logging': {'pred_time': 0.00552139679590861}, 'val_loss': 2.7611331939697266, 'trained_estimator': <flaml.automl.time_series.ts_model.XGBoost_TS object at 0x7fa07c160790>}\n",
      "[flaml.tune.tune: 06-26 15:54:19] {796} INFO - Number of trials: 4/8, 1 RUNNING, 3 TERMINATED\n",
      "[flaml.tune.tune: 06-26 15:54:21] {819} INFO - Brief result: {'pred_time': 0.01739680767059326, 'wall_clock_time': 8.193345069885254, 'metric_for_logging': {'pred_time': 0.01739680767059326}, 'val_loss': 3.1117818126383683, 'trained_estimator': <flaml.automl.time_series.ts_model.ExtraTrees_TS object at 0x7fa16e070c40>}\n",
      "[flaml.tune.tune: 06-26 15:54:21] {796} INFO - Number of trials: 5/8, 1 RUNNING, 4 TERMINATED\n",
      "[flaml.tune.tune: 06-26 15:54:25] {819} INFO - Brief result: {'pred_time': 0.042721172173817955, 'wall_clock_time': 12.26246166229248, 'metric_for_logging': {'pred_time': 0.042721172173817955}, 'val_loss': 3.963104009628296, 'trained_estimator': <flaml.automl.time_series.ts_model.XGBoostLimitDepth_TS object at 0x7fa07c10a730>}\n",
      "[flaml.tune.tune: 06-26 15:54:25] {796} INFO - Number of trials: 6/8, 1 RUNNING, 5 TERMINATED\n",
      "[flaml.tune.tune: 06-26 15:54:25] {819} INFO - Brief result: {'pred_time': 0.00023931264877319336, 'wall_clock_time': 12.982761859893799, 'metric_for_logging': {'pred_time': 0.00023931264877319336}, 'val_loss': 1.4077092345950828, 'trained_estimator': <flaml.automl.time_series.ts_model.ARIMA object at 0x7fa07c1100a0>}\n",
      "[flaml.tune.tune: 06-26 15:54:25] {796} INFO - Number of trials: 7/8, 1 RUNNING, 6 TERMINATED\n",
      "[flaml.tune.tune: 06-26 15:54:30] {819} INFO - Brief result: {'pred_time': 0.0002368291219075521, 'wall_clock_time': 17.664713859558105, 'metric_for_logging': {'pred_time': 0.0002368291219075521}, 'val_loss': 0.7034398663256596, 'trained_estimator': <flaml.automl.time_series.ts_model.SARIMAX object at 0x7fa07c0eb370>}\n",
      "[flaml.tune.tune: 06-26 15:54:30] {796} INFO - Number of trials: 8/8, 1 RUNNING, 7 TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:54:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:54:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 06-26 15:54:31] {819} INFO - Brief result: {'pred_time': 0.0839068094889323, 'wall_clock_time': 18.863497018814087, 'metric_for_logging': {'pred_time': 0.0839068094889323}, 'val_loss': 1.8494102139450683, 'trained_estimator': <flaml.automl.time_series.ts_model.Prophet object at 0x7fa07c121580>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 15:54:31 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run test_ts_1_child_0 at: http://9.134.212.179:5000/#/experiments/0/runs/77cbf48c1242422b83a58402b6fe3634.\n",
      "2025/06/26 15:54:31 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://9.134.212.179:5000/#/experiments/0.\n",
      "2025/06/26 15:54:31 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run test_ts_1_child_1 at: http://9.134.212.179:5000/#/experiments/0/runs/4bacf2b574914f37b3b4150a01617f10.\n",
      "2025/06/26 15:54:31 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://9.134.212.179:5000/#/experiments/0.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run test_ts_1_child_2 at: http://9.134.212.179:5000/#/experiments/0/runs/af25e7919f5c4f428809ea8174d543e9.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://9.134.212.179:5000/#/experiments/0.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run test_ts_1_child_3 at: http://9.134.212.179:5000/#/experiments/0/runs/1a729ba64ff94fb089d09d2cd0338724.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://9.134.212.179:5000/#/experiments/0.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run test_ts_1_child_4 at: http://9.134.212.179:5000/#/experiments/0/runs/4d4e94d79ef74c489952aae388b7728b.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://9.134.212.179:5000/#/experiments/0.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run test_ts_1_child_5 at: http://9.134.212.179:5000/#/experiments/0/runs/f0dc2bbe54c8472b970a9672de27d065.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://9.134.212.179:5000/#/experiments/0.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run test_ts_1_child_6 at: http://9.134.212.179:5000/#/experiments/0/runs/e0ffe4a6559d4fe9b8435aaa942df1dc.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://9.134.212.179:5000/#/experiments/0.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run test_ts_1_child_7 at: http://9.134.212.179:5000/#/experiments/0/runs/7173fcc6b8184c39be8e341ef40ee45f.\n",
      "2025/06/26 15:54:32 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://9.134.212.179:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-26 15:54:32] {49} INFO - logging best model sarimax\n",
      "[flaml.automl.logger: 06-26 15:54:33] {110} INFO - selected model: None\n",
      "[flaml.automl.logger: 06-26 15:54:37] {245} INFO - retrain sarimax for 4.7s\n",
      "[flaml.automl.logger: 06-26 15:54:37] {248} INFO - retrained model: <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x7fa0e42d6490>\n",
      "[flaml.automl.logger: 06-26 15:54:37] {250} INFO - Best MLflow run name: test_ts_1_child_6\n",
      "[flaml.automl.logger: 06-26 15:54:37] {251} INFO - Best MLflow run id: e0ffe4a6559d4fe9b8435aaa942df1dc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 15:54:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-26 15:54:45] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-26 15:54:45] {1986} INFO - Time taken to find the best model: 17.664713859558105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 15:54:45 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run test_ts_1 at: http://9.134.212.179:5000/#/experiments/0/runs/685c0895c545438691792838aba0796e.\n",
      "2025/06/26 15:54:45 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://9.134.212.179:5000/#/experiments/0.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f25463c13cf50d8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from wedata.ts_automl.flaml import WeDataTimeSeriesAutoML\n",
    "import mlflow\n",
    "import flaml\n",
    "from flaml import AutoML\n",
    "mlflow.set_tracking_uri(\"http://9.134.212.179:5000\")\n",
    "# æ„é€ æ—¶åºæ•°æ®\n",
    "X_train = np.arange(\"2014-01\", \"2022-01\", dtype=\"datetime64[M]\")\n",
    "y_train = np.random.random(size=84)\n",
    "# WeDataTimeSeriesAutoML è®­ç»ƒè®¾ç½®ï¼šæœ€å¤§è®­ç»ƒæ—¶é—´ä¸º 60sï¼Œè¯„ä»·æŒ‡æ ‡ä¸º accï¼Œæ¯ä¸ª Executor çš„å¹¶è¡Œåº¦ä¸º 2ï¼Œå¼€å¯å¼ºåˆ¶å–æ¶ˆï¼ˆå¼€å¯åï¼Œè¶…è¿‡æœ€å¤§è®­ç»ƒæ—¶é—´åå°†ç«‹å³åœæ­¢ï¼‰\n",
    "automl_settings = {\n",
    "    \"time_budget\": 10,\n",
    "    \"metric\": 'accuracy',\n",
    "    \"n_concurrent_trials\": 1,\n",
    "    \"use_spark\": True,\n",
    "    \"force_cancel\": False,  # Activating the force_cancel option can immediately halt Spark jobs once they exceed the allocated time_budget.\n",
    "}\n"
   ],
   "id": "17c1660c1964a9fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
