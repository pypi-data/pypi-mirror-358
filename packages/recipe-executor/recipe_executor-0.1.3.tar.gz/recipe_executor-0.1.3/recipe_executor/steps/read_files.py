# This file was generated by Codebase-Generator, do not edit directly
import os
import json
import logging
import glob
from typing import Any, Dict, List, Union

import yaml

from recipe_executor.protocols import ContextProtocol
from recipe_executor.steps.base import BaseStep, StepConfig
from recipe_executor.utils.templates import render_template


class ReadFilesConfig(StepConfig):
    """
    Configuration for ReadFilesStep.

    Fields:
        path (Union[str, List[str]]): Path, comma-separated string, or list of paths to the file(s) to read (may be templated).
        content_key (str): Name under which to store file content in the context (may be templated).
        optional (bool): Whether to continue if a file is not found (default: False).
        merge_mode (str): How to handle multiple files' content. Options:
            - "concat" (default): Concatenate all files with newlines between filename headers + content
            - "dict": Store a dictionary with file paths as keys and content as values
    """

    path: Union[str, List[str]]
    content_key: str
    optional: bool = False
    merge_mode: str = "concat"


class ReadFilesStep(BaseStep[ReadFilesConfig]):
    """
    Step that reads one or more files from disk and stores their content in the execution context.
    """

    def __init__(self, logger: logging.Logger, config: Dict[str, Any]) -> None:
        validated = ReadFilesConfig.model_validate(config)
        super().__init__(logger, validated)

    async def execute(self, context: ContextProtocol) -> None:
        cfg = self.config
        # Render the key to store content under
        rendered_key = render_template(cfg.content_key, context)

        # Normalize input paths
        raw_path = cfg.path
        paths: List[str] = []

        if isinstance(raw_path, str):
            rendered = render_template(raw_path, context)
            # split comma-separated
            parts = [p.strip() for p in rendered.split(",") if p.strip()]
            for part in parts:
                matches = glob.glob(part)
                if matches:
                    for m in sorted(matches):
                        paths.append(m)
                else:
                    paths.append(part)
        elif isinstance(raw_path, list):
            for entry in raw_path:
                if not isinstance(entry, str):
                    raise ValueError(f"Invalid path entry type: {entry!r}")
                rendered = render_template(entry, context)
                if not rendered:
                    continue
                matches = glob.glob(rendered)
                if matches:
                    for m in sorted(matches):
                        paths.append(m)
                else:
                    paths.append(rendered)
        else:
            raise ValueError(f"Invalid type for path: {type(raw_path)}")

        results: List[Any] = []
        result_map: Dict[str, Any] = {}

        for path in paths:
            self.logger.debug(f"Reading file at path: {path}")
            if not os.path.exists(path):
                msg = f"File not found: {path}"
                if cfg.optional:
                    self.logger.warning(f"Optional file missing, skipping: {path}")
                    continue
                raise FileNotFoundError(msg)

            try:
                with open(path, mode="r", encoding="utf-8") as f:
                    text = f.read()
            except Exception as exc:
                raise IOError(f"Error reading file {path}: {exc}")

            # Attempt structured parsing
            content: Any = text
            ext = os.path.splitext(path)[1].lower()
            if ext == ".json":
                try:
                    content = json.loads(text)
                except Exception as exc:
                    self.logger.warning(f"Failed to parse JSON from {path}: {exc}")
                    content = text
            elif ext in (".yaml", ".yml"):  # type: ignore
                try:
                    content = yaml.safe_load(text)
                except Exception as exc:
                    self.logger.warning(f"Failed to parse YAML from {path}: {exc}")
                    content = text

            self.logger.info(f"Successfully read file: {path}")
            results.append(content)
            result_map[path] = content

        # Determine final content based on merge mode and number of files
        if not results:
            if len(paths) <= 1:
                final_content: Any = ""
            elif cfg.merge_mode == "dict":
                final_content = {}
            else:
                final_content = ""
        elif len(results) == 1:
            final_content = results[0]
        else:
            if cfg.merge_mode == "dict":
                final_content = result_map
            else:
                segments: List[str] = []
                for p in paths:
                    if p in result_map:
                        raw = result_map[p]
                        segment = raw if isinstance(raw, str) else json.dumps(raw)
                        segments.append(f"{p}\n{segment}")
                final_content = "\n".join(segments)

        # Store in context
        context[rendered_key] = final_content
        self.logger.info(f"Stored file content under key '{rendered_key}'")
