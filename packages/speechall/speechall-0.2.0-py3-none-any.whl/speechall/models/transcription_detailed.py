# coding: utf-8

"""
    Speechall API

    The Speechall REST API provides powerful and flexible speech-to-text capabilities. It allows you to transcribe audio files using various underlying STT providers and models, optionally apply custom text replacement rules, and access results in multiple formats. The API includes standard endpoints for transcription and endpoints compatible with the OpenAI API structure. 

    The version of the OpenAPI document: 0.1.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json


from typing import Any, Dict, List, Optional, Union
from pydantic import BaseModel, Field, StrictFloat, StrictInt, StrictStr, conlist
from speechall.models.transcription_segment import TranscriptionSegment
from speechall.models.transcription_word import TranscriptionWord

class TranscriptionDetailed(BaseModel):
    """
    A detailed JSON response format containing the full text, detected language, duration, individual timed segments, and potentially speaker labels and provider-specific metadata. Returned when `output_format` is `json`.  # noqa: E501
    """
    id: StrictStr = Field(default=..., description="A unique identifier for the transcription job/request.")
    text: StrictStr = Field(default=..., description="The full transcribed text as a single string.")
    language: Optional[StrictStr] = Field(default=None, description="The detected or specified language of the audio (ISO 639-1 code).")
    duration: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="The total duration of the processed audio file in seconds. **Deprecated**: This property may be removed in future versions as duration analysis might occur asynchronously. Rely on segment end times for duration information if needed. ")
    segments: Optional[conlist(TranscriptionSegment)] = Field(default=None, description="An array of transcribed segments, providing time-coded chunks of the transcription. The level of detail (word vs. segment timestamps) depends on the `timestamp_granularity` request parameter. May include speaker labels if diarization was enabled.")
    words: Optional[conlist(TranscriptionWord)] = Field(default=None, description="An array of transcribed words, providing time-coded chunks of the transcription. The level of detail (word vs. segment timestamps) depends on the `timestamp_granularity` request parameter. May include speaker labels if diarization was enabled.")
    provider_metadata: Optional[Dict[str, Any]] = Field(default=None, description="An optional object containing additional metadata returned directly from the underlying STT provider. The structure of this object is provider-dependent.")
    __properties = ["id", "text", "language", "duration", "segments", "words", "provider_metadata"]

    class Config:
        """Pydantic configuration"""
        allow_population_by_field_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.dict(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> TranscriptionDetailed:
        """Create an instance of TranscriptionDetailed from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self):
        """Returns the dictionary representation of the model using alias"""
        _dict = self.dict(by_alias=True,
                          exclude={
                          },
                          exclude_none=True)
        # override the default output from pydantic by calling `to_dict()` of each item in segments (list)
        _items = []
        if self.segments:
            for _item in self.segments:
                if _item:
                    _items.append(_item.to_dict())
            _dict['segments'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in words (list)
        _items = []
        if self.words:
            for _item in self.words:
                if _item:
                    _items.append(_item.to_dict())
            _dict['words'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: dict) -> TranscriptionDetailed:
        """Create an instance of TranscriptionDetailed from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return TranscriptionDetailed.parse_obj(obj)

        _obj = TranscriptionDetailed.parse_obj({
            "id": obj.get("id"),
            "text": obj.get("text"),
            "language": obj.get("language"),
            "duration": obj.get("duration"),
            "segments": [TranscriptionSegment.from_dict(_item) for _item in obj.get("segments")] if obj.get("segments") is not None else None,
            "words": [TranscriptionWord.from_dict(_item) for _item in obj.get("words")] if obj.get("words") is not None else None,
            "provider_metadata": obj.get("provider_metadata")
        })
        return _obj


