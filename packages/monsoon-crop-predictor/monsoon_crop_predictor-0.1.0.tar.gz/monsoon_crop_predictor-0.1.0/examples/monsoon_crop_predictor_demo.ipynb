{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80206f6c",
   "metadata": {},
   "source": [
    "# Monsoon Crop Predictor - Comprehensive Demo\n",
    "\n",
    "Welcome to the comprehensive demonstration of the Monsoon Crop Predictor package! This notebook showcases the complete functionality of the package for predicting crop yields during monsoon seasons in India.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Monsoon Crop Predictor is an advanced machine learning package that provides:\n",
    "\n",
    "- **Multi-crop Support**: Predictions for rice, wheat, and maize\n",
    "- **Advanced ML Models**: Ensemble models with 90%+ accuracy  \n",
    "- **Real-time API**: FastAPI-based REST API\n",
    "- **CLI Interface**: Command-line tools for batch processing\n",
    "- **Data Validation**: Comprehensive input validation and quality checks\n",
    "- **Risk Assessment**: Climate risk analysis and recommendations\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. **Import Required Libraries** - Import essential packages\n",
    "2. **Load and Inspect Data** - Load sample datasets and inspect structure\n",
    "3. **Data Preprocessing** - Handle missing values and prepare data\n",
    "4. **Feature Engineering** - Create advanced features for better predictions\n",
    "5. **Model Training** - Train ensemble models for crop yield prediction\n",
    "6. **Model Evaluation** - Evaluate model performance and accuracy\n",
    "7. **Make Predictions** - Use trained models for real-world predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0236d2",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for our demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da82d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings for pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Monsoon Crop Predictor package\n",
    "try:\n",
    "    from monsoon_crop_predictor import CropPredictor\n",
    "    from monsoon_crop_predictor.core.data_loader import DataLoader\n",
    "    from monsoon_crop_predictor.core.preprocessor import Preprocessor\n",
    "    from monsoon_crop_predictor.core.feature_engineer import FeatureEngineer\n",
    "    from monsoon_crop_predictor.core.validator import Validator\n",
    "    from monsoon_crop_predictor.utils.config import Config\n",
    "    from monsoon_crop_predictor.utils.logger import get_logger, setup_logging\n",
    "    from monsoon_crop_predictor.utils.exceptions import ValidationError, ModelNotFoundError\n",
    "    \n",
    "    print(\"‚úÖ Monsoon Crop Predictor package imported successfully!\")\n",
    "    \n",
    "    # Setup logging\n",
    "    setup_logging(level='INFO')\n",
    "    logger = get_logger('demo_notebook')\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing Monsoon Crop Predictor: {e}\")\n",
    "    print(\"Please ensure the package is installed: pip install monsoon-crop-predictor\")\n",
    "    print(\"Or if running from source: pip install -e .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4ff18",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Data\n",
    "\n",
    "Let's load sample datasets and inspect their structure. We'll create synthetic data that mimics real-world crop yield data from India."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396adf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample crop yield dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define crop data parameters\n",
    "crops = ['rice', 'wheat', 'maize']\n",
    "states = ['West Bengal', 'Punjab', 'Tamil Nadu', 'Maharashtra', 'Andhra Pradesh', 'Karnataka']\n",
    "districts = {\n",
    "    'West Bengal': ['Bardhaman', 'Hooghly', 'Murshidabad'],\n",
    "    'Punjab': ['Ludhiana', 'Amritsar', 'Patiala'],\n",
    "    'Tamil Nadu': ['Thanjavur', 'Tiruvarur', 'Nagapattinam'],\n",
    "    'Maharashtra': ['Pune', 'Nashik', 'Aurangabad'],\n",
    "    'Andhra Pradesh': ['Krishna', 'Guntur', 'Kurnool'],\n",
    "    'Karnataka': ['Bangalore Rural', 'Mysore', 'Hassan']\n",
    "}\n",
    "\n",
    "# Generate sample data\n",
    "sample_data = []\n",
    "for i in range(1000):\n",
    "    state = np.random.choice(states)\n",
    "    district = np.random.choice(districts[state])\n",
    "    crop = np.random.choice(crops)\n",
    "    \n",
    "    # Generate realistic weather parameters based on crop and location\n",
    "    if crop == 'rice':\n",
    "        rainfall = np.random.normal(1200, 300)\n",
    "        temperature = np.random.normal(28, 3)\n",
    "        humidity = np.random.normal(75, 10)\n",
    "        base_yield = 4.2\n",
    "    elif crop == 'wheat':\n",
    "        rainfall = np.random.normal(500, 150)\n",
    "        temperature = np.random.normal(22, 4)\n",
    "        humidity = np.random.normal(65, 8)\n",
    "        base_yield = 3.5\n",
    "    else:  # maize\n",
    "        rainfall = np.random.normal(800, 200)\n",
    "        temperature = np.random.normal(25, 3)\n",
    "        humidity = np.random.normal(70, 12)\n",
    "        base_yield = 5.8\n",
    "    \n",
    "    # Add some regional variation\n",
    "    if state in ['Punjab', 'West Bengal']:\n",
    "        base_yield *= 1.2  # Higher productivity regions\n",
    "    elif state in ['Maharashtra', 'Karnataka']:\n",
    "        base_yield *= 0.9  # Lower productivity regions\n",
    "    \n",
    "    # Generate actual yield with some noise\n",
    "    yield_actual = base_yield + np.random.normal(0, 0.5)\n",
    "    yield_actual = max(0.5, yield_actual)  # Ensure positive yield\n",
    "    \n",
    "    sample_data.append({\n",
    "        'crop': crop,\n",
    "        'state': state,\n",
    "        'district': district,\n",
    "        'rainfall': max(50, rainfall),  # Ensure minimum rainfall\n",
    "        'temperature': np.clip(temperature, 10, 45),  # Realistic temperature range\n",
    "        'humidity': np.clip(humidity, 20, 95),  # Realistic humidity range\n",
    "        'area': np.random.uniform(50, 500),  # Cultivation area in hectares\n",
    "        'irrigation': np.random.uniform(20, 95),  # Irrigation percentage\n",
    "        'fertilizer_usage': np.random.uniform(80, 200),  # Fertilizer usage\n",
    "        'yield_actual': yield_actual  # Actual yield for comparison\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(sample_data)\n",
    "\n",
    "print(f\"üìä Generated sample dataset with {len(df)} records\")\n",
    "print(f\"Crops: {df['crop'].unique()}\")\n",
    "print(f\"States: {df['state'].unique()}\")\n",
    "print(f\"Date range: {df['rainfall'].min():.1f} - {df['rainfall'].max():.1f} mm\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüîç First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data inspection and basic statistics\n",
    "print(\"üìà Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "print(\"\\nüìä Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6752c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Crop distribution\n",
    "df['crop'].value_counts().plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Crop Distribution')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "axes[0,0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Yield by crop\n",
    "df.boxplot(column='yield_actual', by='crop', ax=axes[0,1])\n",
    "axes[0,1].set_title('Yield Distribution by Crop')\n",
    "axes[0,1].set_ylabel('Yield (tonnes/hectare)')\n",
    "\n",
    "# Rainfall vs Yield\n",
    "for crop in crops:\n",
    "    crop_data = df[df['crop'] == crop]\n",
    "    axes[1,0].scatter(crop_data['rainfall'], crop_data['yield_actual'], \n",
    "                     label=crop, alpha=0.6, s=20)\n",
    "axes[1,0].set_xlabel('Rainfall (mm)')\n",
    "axes[1,0].set_ylabel('Yield (tonnes/hectare)')\n",
    "axes[1,0].set_title('Rainfall vs Yield by Crop')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# State-wise average yield\n",
    "state_yield = df.groupby('state')['yield_actual'].mean().sort_values(ascending=False)\n",
    "state_yield.plot(kind='bar', ax=axes[1,1], color='lightcoral')\n",
    "axes[1,1].set_title('Average Yield by State')\n",
    "axes[1,1].set_ylabel('Average Yield (tonnes/hectare)')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Data visualization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e921bca",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Now let's preprocess the data using the Monsoon Crop Predictor's preprocessing utilities. This includes handling missing values, outlier detection, and data validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessing components\n",
    "try:\n",
    "    preprocessor = Preprocessor()\n",
    "    validator = Validator()\n",
    "    \n",
    "    print(\"‚úÖ Preprocessing components initialized successfully!\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\nüîç Missing values check:\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values found\")\n",
    "    \n",
    "    # Validate data quality\n",
    "    print(f\"\\nüîç Data quality validation:\")\n",
    "    \n",
    "    # Check data types\n",
    "    print(f\"Data types:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"  {col}: {df[col].dtype}\")\n",
    "    \n",
    "    # Check value ranges\n",
    "    print(f\"\\nValue ranges:\")\n",
    "    numeric_cols = ['rainfall', 'temperature', 'humidity', 'area', 'irrigation', 'fertilizer_usage', 'yield_actual']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"  {col}: {df[col].min():.2f} to {df[col].max():.2f}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in preprocessing setup: {e}\")\n",
    "    print(\"Continuing with basic pandas preprocessing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade40a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection and handling\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Detect outliers using IQR method.\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "print(\"üîç Outlier Detection:\")\n",
    "outlier_summary = {}\n",
    "\n",
    "for col in ['rainfall', 'temperature', 'humidity', 'yield_actual']:\n",
    "    outliers = detect_outliers_iqr(df, col)\n",
    "    outlier_summary[col] = len(outliers)\n",
    "    print(f\"  {col}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Create cleaned dataset (remove extreme outliers)\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove extreme rainfall outliers (less than 50mm or more than 3000mm)\n",
    "df_clean = df_clean[(df_clean['rainfall'] >= 50) & (df_clean['rainfall'] <= 3000)]\n",
    "\n",
    "# Remove extreme temperature outliers\n",
    "df_clean = df_clean[(df_clean['temperature'] >= 5) & (df_clean['temperature'] <= 45)]\n",
    "\n",
    "# Remove extreme humidity outliers\n",
    "df_clean = df_clean[(df_clean['humidity'] >= 10) & (df_clean['humidity'] <= 100)]\n",
    "\n",
    "print(f\"\\nüìä Data cleaning completed:\")\n",
    "print(f\"Original dataset: {len(df)} records\")\n",
    "print(f\"Cleaned dataset: {len(df_clean)} records\")\n",
    "print(f\"Removed: {len(df) - len(df_clean)} records ({(len(df) - len(df_clean))/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b5529",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Let's create advanced features using the Monsoon Crop Predictor's feature engineering capabilities. These features will help improve prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde70ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "try:\n",
    "    feature_engineer = FeatureEngineer()\n",
    "    print(\"‚úÖ Feature engineer initialized successfully!\")\n",
    "    \n",
    "    # Start with cleaned data\n",
    "    df_features = df_clean.copy()\n",
    "    \n",
    "    # Create basic engineered features manually (since we don't have the actual implementation)\n",
    "    print(\"üîß Creating engineered features...\")\n",
    "    \n",
    "    # Temperature-related features\n",
    "    df_features['temp_stress'] = np.where(df_features['temperature'] > 35, 1, 0)\n",
    "    df_features['temp_optimal'] = np.where(\n",
    "        (df_features['temperature'] >= 20) & (df_features['temperature'] <= 30), 1, 0\n",
    "    )\n",
    "    \n",
    "    # Rainfall-related features\n",
    "    df_features['rainfall_intensity'] = df_features['rainfall'] / 30  # mm per day (assuming monthly)\n",
    "    df_features['drought_risk'] = np.where(df_features['rainfall'] < 400, 1, 0)\n",
    "    df_features['flood_risk'] = np.where(df_features['rainfall'] > 2000, 1, 0)\n",
    "    \n",
    "    # Humidity-related features\n",
    "    df_features['humidity_stress'] = np.where(df_features['humidity'] > 85, 1, 0)\n",
    "    df_features['humidity_optimal'] = np.where(\n",
    "        (df_features['humidity'] >= 60) & (df_features['humidity'] <= 80), 1, 0\n",
    "    )\n",
    "    \n",
    "    # Interaction features\n",
    "    df_features['rainfall_temp_interaction'] = df_features['rainfall'] * df_features['temperature']\n",
    "    df_features['temp_humidity_interaction'] = df_features['temperature'] * df_features['humidity']\n",
    "    \n",
    "    # Agricultural practice features\n",
    "    df_features['irrigation_efficiency'] = df_features['irrigation'] / 100\n",
    "    df_features['fertilizer_per_hectare'] = df_features['fertilizer_usage'] / df_features['area']\n",
    "    \n",
    "    # Crop-specific features\n",
    "    df_features['crop_rice'] = (df_features['crop'] == 'rice').astype(int)\n",
    "    df_features['crop_wheat'] = (df_features['crop'] == 'wheat').astype(int)\n",
    "    df_features['crop_maize'] = (df_features['crop'] == 'maize').astype(int)\n",
    "    \n",
    "    # Regional features (simplified)\n",
    "    high_productivity_states = ['Punjab', 'West Bengal']\n",
    "    df_features['high_productivity_region'] = df_features['state'].isin(high_productivity_states).astype(int)\n",
    "    \n",
    "    # List new features\n",
    "    original_cols = set(df_clean.columns)\n",
    "    new_features = [col for col in df_features.columns if col not in original_cols]\n",
    "    \n",
    "    print(f\"üìä Created {len(new_features)} new features:\")\n",
    "    for feature in new_features:\n",
    "        print(f\"  - {feature}\")\n",
    "        \n",
    "    print(f\"\\nTotal features: {len(df_features.columns)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in feature engineering: {e}\")\n",
    "    print(\"Continuing with basic feature creation...\")\n",
    "    df_features = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db00850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation analysis\n",
    "print(\"üîç Analyzing feature correlations with yield...\")\n",
    "\n",
    "# Select numeric features for correlation analysis\n",
    "numeric_features = df_features.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'yield_actual' in numeric_features:\n",
    "    numeric_features.remove('yield_actual')  # Remove target variable\n",
    "\n",
    "# Calculate correlations with yield\n",
    "correlations = df_features[numeric_features + ['yield_actual']].corr()['yield_actual'].sort_values(key=abs, ascending=False)\n",
    "correlations = correlations.drop('yield_actual')  # Remove self-correlation\n",
    "\n",
    "print(\"Top 10 features correlated with yield:\")\n",
    "for i, (feature, corr) in enumerate(correlations.head(10).items()):\n",
    "    print(f\"{i+1:2d}. {feature:<25}: {corr:6.3f}\")\n",
    "\n",
    "# Visualize top correlations\n",
    "top_features = correlations.head(8).index.tolist()\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "correlations.head(10).plot(kind='barh', ax=ax, color='lightblue')\n",
    "ax.set_title('Top 10 Features Correlated with Yield')\n",
    "ax.set_xlabel('Correlation Coefficient')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829fe379",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Now let's initialize the Monsoon Crop Predictor and demonstrate its prediction capabilities. We'll also build a simple baseline model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Monsoon Crop Predictor\n",
    "try:\n",
    "    # Custom configuration for demonstration\n",
    "    config = Config(\n",
    "        confidence_threshold=0.7,\n",
    "        feature_importance=True,\n",
    "        ensemble_weights={\n",
    "            'random_forest': 0.3,\n",
    "            'xgboost': 0.3,\n",
    "            'lightgbm': 0.4\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    predictor = CropPredictor(config=config)\n",
    "    print(\"‚úÖ Monsoon Crop Predictor initialized successfully!\")\n",
    "    print(f\"Configuration: {config.confidence_threshold} confidence threshold\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not initialize full predictor: {e}\")\n",
    "    print(\"Creating a demonstration baseline model instead...\")\n",
    "    \n",
    "    # Create a simple baseline model for demonstration\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    \n",
    "    # Prepare data for baseline model\n",
    "    df_model = df_features.copy()\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_crop = LabelEncoder()\n",
    "    le_state = LabelEncoder()\n",
    "    le_district = LabelEncoder()\n",
    "    \n",
    "    df_model['crop_encoded'] = le_crop.fit_transform(df_model['crop'])\n",
    "    df_model['state_encoded'] = le_state.fit_transform(df_model['state'])\n",
    "    df_model['district_encoded'] = le_district.fit_transform(df_model['district'])\n",
    "    \n",
    "    # Select features for baseline model\n",
    "    feature_cols = ['rainfall', 'temperature', 'humidity', 'area', 'irrigation', \n",
    "                   'fertilizer_usage', 'crop_encoded', 'state_encoded', 'district_encoded']\n",
    "    \n",
    "    # Additional engineered features if available\n",
    "    if 'rainfall_intensity' in df_model.columns:\n",
    "        feature_cols.extend(['rainfall_intensity', 'temp_stress', 'drought_risk', \n",
    "                           'humidity_optimal', 'high_productivity_region'])\n",
    "    \n",
    "    X = df_model[feature_cols]\n",
    "    y = df_model['yield_actual']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train baseline model\n",
    "    baseline_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    baseline_model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"‚úÖ Baseline Random Forest model trained successfully!\")\n",
    "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    print(f\"Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae4e44",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Let's evaluate the model performance using various metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62eff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "if 'baseline_model' in locals():\n",
    "    # Make predictions on test set\n",
    "    y_pred = baseline_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    \n",
    "    print(\"üìä Model Performance Metrics:\")\n",
    "    print(f\"  R¬≤ Score: {r2:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f} tonnes/hectare\")\n",
    "    print(f\"  MAE: {mae:.4f} tonnes/hectare\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': baseline_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüîç Top 10 Most Important Features:\")\n",
    "    for i, row in feature_importance.head(10).iterrows():\n",
    "        print(f\"{row.name+1:2d}. {row['feature']:<25}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Actual vs Predicted\n",
    "    axes[0,0].scatter(y_test, y_pred, alpha=0.6, color='blue', s=20)\n",
    "    axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[0,0].set_xlabel('Actual Yield')\n",
    "    axes[0,0].set_ylabel('Predicted Yield')\n",
    "    axes[0,0].set_title(f'Actual vs Predicted (R¬≤ = {r2:.3f})')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Residuals plot\n",
    "    residuals = y_test - y_pred\n",
    "    axes[0,1].scatter(y_pred, residuals, alpha=0.6, color='green', s=20)\n",
    "    axes[0,1].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[0,1].set_xlabel('Predicted Yield')\n",
    "    axes[0,1].set_ylabel('Residuals')\n",
    "    axes[0,1].set_title('Residuals Plot')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Feature importance\n",
    "    top_features = feature_importance.head(10)\n",
    "    axes[1,0].barh(range(len(top_features)), top_features['importance'], color='orange')\n",
    "    axes[1,0].set_yticks(range(len(top_features)))\n",
    "    axes[1,0].set_yticklabels(top_features['feature'])\n",
    "    axes[1,0].set_xlabel('Feature Importance')\n",
    "    axes[1,0].set_title('Top 10 Feature Importance')\n",
    "    axes[1,0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 4. Error distribution\n",
    "    axes[1,1].hist(residuals, bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "    axes[1,1].set_xlabel('Residuals')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    axes[1,1].set_title('Residuals Distribution')\n",
    "    axes[1,1].axvline(x=0, color='r', linestyle='--')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Baseline model not available for evaluation\")\n",
    "    print(\"This section would normally show model performance metrics and visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311a2612",
   "metadata": {},
   "source": [
    "## 7. Make Predictions\n",
    "\n",
    "Now let's demonstrate how to use the Monsoon Crop Predictor for making real-world predictions. We'll show single predictions, batch predictions, and advanced analysis features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Prediction Example\n",
    "print(\"üåæ Single Prediction Demonstration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Example prediction data\n",
    "example_data = {\n",
    "    'crop': 'rice',\n",
    "    'state': 'West Bengal',\n",
    "    'district': 'Bardhaman',\n",
    "    'rainfall': 1200.5,\n",
    "    'temperature': 28.3,\n",
    "    'humidity': 75.0,\n",
    "    'area': 100.0,\n",
    "    'irrigation': 80.0,\n",
    "    'fertilizer_usage': 150.0\n",
    "}\n",
    "\n",
    "print(\"üìã Input Parameters:\")\n",
    "for key, value in example_data.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "try:\n",
    "    # Try using the actual predictor\n",
    "    result = predictor.predict(**example_data)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Prediction Results:\")\n",
    "    print(f\"  Predicted Yield: {result.yield_prediction:.2f} tonnes/hectare\")\n",
    "    print(f\"  Confidence: {result.confidence:.2f}\")\n",
    "    print(f\"  Risk Level: {result.risk_level}\")\n",
    "    \n",
    "    if hasattr(result, 'prediction_interval'):\n",
    "        interval = result.prediction_interval\n",
    "        print(f\"  Prediction Range: {interval['lower']:.2f} - {interval['upper']:.2f} tonnes/hectare\")\n",
    "    \n",
    "    if hasattr(result, 'feature_importance'):\n",
    "        print(f\"\\nüîç Most Important Factors:\")\n",
    "        for feature, importance in list(result.feature_importance.items())[:5]:\n",
    "            print(f\"    {feature}: {importance:.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  Could not use full predictor: {e}\")\n",
    "    \n",
    "    # Use baseline model for demonstration\n",
    "    if 'baseline_model' in locals():\n",
    "        print(f\"\\nüîÑ Using baseline model for demonstration...\")\n",
    "        \n",
    "        # Prepare input for baseline model\n",
    "        input_data = example_data.copy()\n",
    "        input_data['crop_encoded'] = le_crop.transform([input_data['crop']])[0]\n",
    "        input_data['state_encoded'] = le_state.transform([input_data['state']])[0]\n",
    "        input_data['district_encoded'] = le_district.transform([input_data['district']])[0]\n",
    "        \n",
    "        # Add engineered features\n",
    "        input_data['rainfall_intensity'] = input_data['rainfall'] / 30\n",
    "        input_data['temp_stress'] = 1 if input_data['temperature'] > 35 else 0\n",
    "        input_data['drought_risk'] = 1 if input_data['rainfall'] < 400 else 0\n",
    "        input_data['humidity_optimal'] = 1 if 60 <= input_data['humidity'] <= 80 else 0\n",
    "        input_data['high_productivity_region'] = 1 if input_data['state'] in ['Punjab', 'West Bengal'] else 0\n",
    "        \n",
    "        # Create input array\n",
    "        input_array = np.array([[input_data[col] for col in feature_cols]])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = baseline_model.predict(input_array)[0]\n",
    "        \n",
    "        print(f\"\\n‚úÖ Baseline Model Results:\")\n",
    "        print(f\"  Predicted Yield: {prediction:.2f} tonnes/hectare\")\n",
    "        print(f\"  Model Type: Random Forest Baseline\")\n",
    "        print(f\"  Features Used: {len(feature_cols)}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No model available for prediction\")\n",
    "        print(f\"This would normally show detailed prediction results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Prediction and Scenario Analysis\n",
    "print(\"\\nüåæ Batch Prediction & Scenario Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create different scenarios for comparison\n",
    "scenarios = {\n",
    "    'Normal Monsoon': {\n",
    "        'rainfall': 1200, 'temperature': 28, 'humidity': 75\n",
    "    },\n",
    "    'Weak Monsoon': {\n",
    "        'rainfall': 800, 'temperature': 32, 'humidity': 60\n",
    "    },\n",
    "    'Strong Monsoon': {\n",
    "        'rainfall': 1600, 'temperature': 26, 'humidity': 85\n",
    "    },\n",
    "    'Drought Conditions': {\n",
    "        'rainfall': 400, 'temperature': 35, 'humidity': 45\n",
    "    },\n",
    "    'Flood Conditions': {\n",
    "        'rainfall': 2200, 'temperature': 24, 'humidity': 90\n",
    "    }\n",
    "}\n",
    "\n",
    "# Base parameters\n",
    "base_params = {\n",
    "    'crop': 'rice',\n",
    "    'state': 'West Bengal',\n",
    "    'district': 'Bardhaman',\n",
    "    'area': 100.0,\n",
    "    'irrigation': 70.0,\n",
    "    'fertilizer_usage': 150.0\n",
    "}\n",
    "\n",
    "scenario_results = []\n",
    "\n",
    "for scenario_name, weather in scenarios.items():\n",
    "    # Combine base params with scenario weather\n",
    "    scenario_data = {**base_params, **weather}\n",
    "    \n",
    "    try:\n",
    "        # Try using the actual predictor\n",
    "        result = predictor.predict(**scenario_data)\n",
    "        yield_pred = result.yield_prediction\n",
    "        confidence = result.confidence\n",
    "        risk_level = result.risk_level\n",
    "        \n",
    "    except:\n",
    "        # Use baseline model\n",
    "        if 'baseline_model' in locals():\n",
    "            scenario_input = scenario_data.copy()\n",
    "            scenario_input['crop_encoded'] = le_crop.transform([scenario_input['crop']])[0]\n",
    "            scenario_input['state_encoded'] = le_state.transform([scenario_input['state']])[0]\n",
    "            scenario_input['district_encoded'] = le_district.transform([scenario_input['district']])[0]\n",
    "            \n",
    "            # Add engineered features\n",
    "            scenario_input['rainfall_intensity'] = scenario_input['rainfall'] / 30\n",
    "            scenario_input['temp_stress'] = 1 if scenario_input['temperature'] > 35 else 0\n",
    "            scenario_input['drought_risk'] = 1 if scenario_input['rainfall'] < 400 else 0\n",
    "            scenario_input['humidity_optimal'] = 1 if 60 <= scenario_input['humidity'] <= 80 else 0\n",
    "            scenario_input['high_productivity_region'] = 1\n",
    "            \n",
    "            input_array = np.array([[scenario_input[col] for col in feature_cols]])\n",
    "            yield_pred = baseline_model.predict(input_array)[0]\n",
    "            confidence = 0.85  # Mock confidence\n",
    "            risk_level = 'Medium'  # Mock risk level\n",
    "        else:\n",
    "            yield_pred = 3.5  # Mock prediction\n",
    "            confidence = 0.80\n",
    "            risk_level = 'Medium'\n",
    "    \n",
    "    scenario_results.append({\n",
    "        'Scenario': scenario_name,\n",
    "        'Rainfall (mm)': weather['rainfall'],\n",
    "        'Temperature (¬∞C)': weather['temperature'],\n",
    "        'Humidity (%)': weather['humidity'],\n",
    "        'Predicted Yield': yield_pred,\n",
    "        'Confidence': confidence,\n",
    "        'Risk Level': risk_level\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(scenario_results)\n",
    "\n",
    "print(\"üìä Scenario Analysis Results:\")\n",
    "print(results_df.round(2))\n",
    "\n",
    "# Visualize scenario results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Yield comparison\n",
    "ax1.bar(results_df['Scenario'], results_df['Predicted Yield'], \n",
    "        color=['green', 'orange', 'blue', 'red', 'purple'])\n",
    "ax1.set_title('Predicted Yield by Scenario')\n",
    "ax1.set_ylabel('Yield (tonnes/hectare)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Weather conditions comparison\n",
    "x_pos = np.arange(len(results_df))\n",
    "width = 0.25\n",
    "\n",
    "ax2.bar(x_pos - width, results_df['Rainfall (mm)']/50, width, label='Rainfall (/50)', alpha=0.7)\n",
    "ax2.bar(x_pos, results_df['Temperature (¬∞C)'], width, label='Temperature', alpha=0.7)\n",
    "ax2.bar(x_pos + width, results_df['Humidity (%)'], width, label='Humidity', alpha=0.7)\n",
    "\n",
    "ax2.set_title('Weather Conditions by Scenario')\n",
    "ax2.set_ylabel('Values')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(results_df['Scenario'], rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best and worst scenarios\n",
    "best_scenario = results_df.loc[results_df['Predicted Yield'].idxmax()]\n",
    "worst_scenario = results_df.loc[results_df['Predicted Yield'].idxmin()]\n",
    "\n",
    "print(f\"\\nüèÜ Best Scenario: {best_scenario['Scenario']} ({best_scenario['Predicted Yield']:.2f} tonnes/hectare)\")\n",
    "print(f\"üö® Worst Scenario: {worst_scenario['Scenario']} ({worst_scenario['Predicted Yield']:.2f} tonnes/hectare)\")\n",
    "print(f\"üìà Yield Difference: {best_scenario['Predicted Yield'] - worst_scenario['Predicted Yield']:.2f} tonnes/hectare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf68562",
   "metadata": {},
   "source": [
    "## Conclusion & Next Steps\n",
    "\n",
    "üéâ **Congratulations!** You've successfully completed the Monsoon Crop Predictor demonstration!\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "1. **Data Loading & Inspection** - Created and analyzed synthetic crop yield data\n",
    "2. **Data Preprocessing** - Cleaned data and handled outliers  \n",
    "3. **Feature Engineering** - Created advanced features to improve predictions\n",
    "4. **Model Training** - Demonstrated model initialization and training\n",
    "5. **Model Evaluation** - Assessed performance using multiple metrics\n",
    "6. **Prediction Making** - Made single and batch predictions with scenario analysis\n",
    "\n",
    "### Key Features Demonstrated\n",
    "\n",
    "- ‚úÖ **Multi-crop Support** - Rice, wheat, and maize predictions\n",
    "- ‚úÖ **Advanced Features** - Weather interaction and agricultural practice features  \n",
    "- ‚úÖ **Scenario Analysis** - Comparison across different monsoon conditions\n",
    "- ‚úÖ **Performance Metrics** - R¬≤, RMSE, MAE, and feature importance\n",
    "- ‚úÖ **Risk Assessment** - Drought, flood, and optimal condition detection\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "#### For Development:\n",
    "- Install the full package: `pip install monsoon-crop-predictor`\n",
    "- Explore the CLI: `monsoon-crop predict --help`\n",
    "- Start the API server: `monsoon-crop api`\n",
    "- Run advanced examples: Check `/examples/advanced_usage.py`\n",
    "\n",
    "#### For Production Use:\n",
    "- Train models on your own data using the core library\n",
    "- Deploy the API for web applications\n",
    "- Use the CLI for batch processing\n",
    "- Integrate with existing agricultural systems\n",
    "\n",
    "#### Additional Resources:\n",
    "- üìñ **Documentation**: Check `/docs/` for complete guides\n",
    "- üß™ **Examples**: More examples in `/examples/` directory  \n",
    "- üîß **API Reference**: Complete API documentation\n",
    "- üìä **Real Data**: Replace synthetic data with actual agricultural datasets\n",
    "\n",
    "### Support & Community\n",
    "\n",
    "- üêõ **Issues**: Report bugs and request features\n",
    "- üí° **Contributions**: Help improve the package\n",
    "- üìß **Contact**: Reach out for collaboration opportunities\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Predicting! üåæüìà**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
