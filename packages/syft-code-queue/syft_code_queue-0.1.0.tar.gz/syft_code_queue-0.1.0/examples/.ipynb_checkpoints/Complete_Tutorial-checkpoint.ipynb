{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Syft Code Queue - Complete Tutorial\n",
    "\n",
    "This notebook demonstrates both **Data Scientist** and **Data Owner** perspectives in a single, simplified walkthrough.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Syft Code Queue enables secure code execution on remote datasites:\n",
    "- **Data Scientists** submit code packages for execution\n",
    "- **Data Owners** review and approve code before execution\n",
    "- All execution happens in a sandboxed environment\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Data Scientist â†’ Submit Code â†’ Data Owner Reviews â†’ Approve â†’ Execute â†’ Results\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install and import the necessary components:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Syft Code Queue v0.1.0 loaded\n"
     ]
    }
   ],
   "source": [
    "# Install syft-code-queue if needed\n",
    "# !pip install -e .\n",
    "\n",
    "import syft_code_queue as scq\n",
    "from syft_code_queue import DataScientistAPI, DataOwnerAPI, JobStatus\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "print(f\"âœ… Syft Code Queue v{scq.__version__} loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Scientist Perspective ğŸ”¬\n",
    "\n",
    "As a data scientist, you want to run analysis on remote data without seeing the raw data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 14:18:09.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.data_scientist_api\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mInitialized Data Scientist API for andrew@openmined.org\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Data Scientist: andrew@openmined.org\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Data Scientist API\n",
    "ds_api = DataScientistAPI()\n",
    "print(f\"ğŸ“Š Data Scientist: {ds_api.email}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a Simple Analysis Job\n",
    "\n",
    "Let's submit a privacy-safe analysis job:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 14:18:13.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.client\u001b[0m:\u001b[36msubmit_code\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mSubmitted job 'Privacy-Safe Statistics' to andrew@openmined.org\u001b[0m\n",
      "\u001b[32m2025-06-29 14:18:13.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.data_scientist_api\u001b[0m:\u001b[36msubmit_job\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mSubmitted job 'Privacy-Safe Statistics' to andrew@openmined.org (ID: a1debf39-feb5-4dc9-a0a9-2f9ed7bfe6f8)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nğŸ¯ Job Submitted!\n",
      "   ID: a1debf39...\n",
      "   Name: Privacy-Safe Statistics\n",
      "   Status: pending\n",
      "   Target: andrew@openmined.org\n"
     ]
    }
   ],
   "source": [
    "# Simple analysis script\n",
    "analysis_script = \"\"\"\n",
    "import json\n",
    "import random\n",
    "\n",
    "print(\"ğŸ” Starting privacy-safe analysis...\")\n",
    "\n",
    "# Simulate analyzing data and computing aggregate statistics\n",
    "# In real scenario, this would access the datasite's data\n",
    "sample_data = [random.randint(1, 100) for _ in range(1000)]\n",
    "\n",
    "results = {\n",
    "    \"count\": len(sample_data),\n",
    "    \"mean\": sum(sample_data) / len(sample_data),\n",
    "    \"min\": min(sample_data),\n",
    "    \"max\": max(sample_data),\n",
    "    \"analysis_type\": \"aggregate_statistics\"\n",
    "}\n",
    "\n",
    "print(f\"ğŸ“ˆ Analysis Results: {results}\")\n",
    "\n",
    "# Save results to a file\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"âœ… Analysis complete! Results saved to results.json\")\n",
    "\"\"\"\n",
    "\n",
    "# Submit the job\n",
    "job = ds_api.create_simple_job(\n",
    "    target_email=\"andrew@openmined.org\",  # Use your actual email\n",
    "    script_content=analysis_script,\n",
    "    name=\"Privacy-Safe Statistics\",\n",
    "    description=\"Compute aggregate statistics without accessing raw data\",\n",
    "    tags=[\"statistics\", \"privacy-safe\", \"aggregate\"]\n",
    ")\n",
    "\n",
    "print(f\"\\\\nğŸ¯ Job Submitted!\")\n",
    "print(f\"   ID: {str(job.uid)[:8]}...\")\n",
    "print(f\"   Name: {job.name}\")\n",
    "print(f\"   Status: {job.status.value}\")\n",
    "print(f\"   Target: {job.target_email}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Data Owner Perspective ğŸ›ï¸\n",
    "\n",
    "As a data owner, you need to review and approve code before it runs on your datasite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 14:18:20.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.app\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mInitialized Code Queue App for andrew@openmined.org\u001b[0m\n",
      "\u001b[32m2025-06-29 14:18:20.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.data_owner_api\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mInitialized Data Owner API for andrew@openmined.org\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›ï¸ Data Owner: andrew@openmined.org\n",
      "\\nğŸ“Š Queue Statistics:\n",
      "   Pending: 1\n",
      "   Completed: 1\n",
      "\\nğŸ“ˆ Total Jobs: 2\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Data Owner API\n",
    "do_api = DataOwnerAPI()\n",
    "print(f\"ğŸ›ï¸ Data Owner: {do_api.email}\")\n",
    "\n",
    "# Get queue statistics (fixed to use job_counts)\n",
    "stats = do_api.get_queue_stats()\n",
    "print(f\"\\\\nğŸ“Š Queue Statistics:\")\n",
    "for status, count in stats[\"job_counts\"].items():  # Fixed: use job_counts\n",
    "    if count > 0:\n",
    "        print(f\"   {status.title()}: {count}\")\n",
    "\n",
    "# Show total jobs\n",
    "print(f\"\\\\nğŸ“ˆ Total Jobs: {stats['total_jobs']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review and Approve Jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 14:18:23.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.data_owner_api\u001b[0m:\u001b[36mapprove_job\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mApproved job: Privacy-Safe Statistics\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Pending Jobs (1 waiting for approval):\n",
      "======================================================================\n",
      "\\n1. ğŸ“ Privacy-Safe Statistics\n",
      "   ID: a1debf39...\n",
      "   From: andrew@openmined.org\n",
      "   Description: Compute aggregate statistics without accessing raw data\n",
      "   Tags: statistics, privacy-safe, aggregate\n",
      "   Submitted: 2025-06-29 14:18:13\n",
      "\\nâœ… Approving safe-looking jobs...\\n\n",
      "âœ… Approved: Privacy-Safe Statistics (a1debf39...)\n"
     ]
    }
   ],
   "source": [
    "# List jobs waiting for approval\n",
    "pending_jobs = do_api.list_pending_jobs()\n",
    "\n",
    "print(f\"â³ Pending Jobs ({len(pending_jobs)} waiting for approval):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, job in enumerate(pending_jobs, 1):\n",
    "    print(f\"\\\\n{i}. ğŸ“ {job.name}\")\n",
    "    print(f\"   ID: {str(job.uid)[:8]}...\")\n",
    "    print(f\"   From: {job.requester_email}\")\n",
    "    print(f\"   Description: {job.description or 'No description'}\")\n",
    "    if job.tags:\n",
    "        print(f\"   Tags: {', '.join(job.tags)}\")\n",
    "    print(f\"   Submitted: {job.created_at.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Approve jobs that look safe\n",
    "if pending_jobs:\n",
    "    print(\"\\\\nâœ… Approving safe-looking jobs...\\\\n\")\n",
    "    \n",
    "    for job in pending_jobs:\n",
    "        job_id = str(job.uid)[:8]\n",
    "        \n",
    "        # Simple approval logic based on tags and description\n",
    "        safe_tags = [\"privacy-safe\", \"aggregate\", \"statistics\"]\n",
    "        has_safe_tags = any(tag in safe_tags for tag in job.tags)\n",
    "        \n",
    "        if has_safe_tags or \"aggregate\" in (job.description or \"\").lower():\n",
    "            success = do_api.approve_job(\n",
    "                job_id, \n",
    "                reason=\"Approved: Privacy-safe aggregate analysis\"\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                print(f\"âœ… Approved: {job.name} ({job_id}...)\")\n",
    "            else:\n",
    "                print(f\"âŒ Failed to approve: {job.name}\")\n",
    "        else:\n",
    "            # Reject potentially risky jobs\n",
    "            success = do_api.reject_job(\n",
    "                job_id,\n",
    "                reason=\"Rejected: Needs more specific privacy guarantees\"\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                print(f\"ğŸš« Rejected: {job.name} ({job_id}...)\")\n",
    "            else:\n",
    "                print(f\"âŒ Failed to reject: {job.name}\")\n",
    "                \n",
    "else:\n",
    "    print(\"â„¹ï¸ No pending jobs to approve/reject.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Queue and Execute Jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 14:18:26.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.app\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mStarting queue processing cycle...\u001b[0m\n",
      "\u001b[32m2025-06-29 14:18:26.685\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyft_code_queue.app\u001b[0m:\u001b[36m_log_pending_jobs\u001b[0m:\u001b[36m99\u001b[0m - \u001b[34m\u001b[1mNo jobs pending approval\u001b[0m\n",
      "\u001b[32m2025-06-29 14:18:26.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.app\u001b[0m:\u001b[36m_execute_approved_jobs\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mğŸš€ Executing 1 approved job(s)\u001b[0m\n",
      "\u001b[32m2025-06-29 14:18:26.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.app\u001b[0m:\u001b[36m_execute_single_job\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mStarting execution of job: Privacy-Safe Statistics\u001b[0m\n",
      "\u001b[32m2025-06-29 14:18:26.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.runner\u001b[0m:\u001b[36mrun_job\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mStarting execution of job a1debf39-feb5-4dc9-a0a9-2f9ed7bfe6f8 in /Users/atrask/SyftBox/datasites/andrew@openmined.org/app_data/code-queue/jobs/a1debf39-feb5-4dc9-a0a9-2f9ed7bfe6f8/code\u001b[0m\n",
      "\u001b[32m2025-06-29 14:18:26.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.runner\u001b[0m:\u001b[36mrun_job\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mJob a1debf39-feb5-4dc9-a0a9-2f9ed7bfe6f8 completed with exit code 0 in 0.03s\u001b[0m\n",
      "\u001b[32m2025-06-29 14:18:26.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.app\u001b[0m:\u001b[36m_execute_single_job\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mJob a1debf39-feb5-4dc9-a0a9-2f9ed7bfe6f8 completed successfully\u001b[0m\n",
      "\u001b[32m2025-06-29 14:18:26.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.app\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mQueue processing cycle completed successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Processing queue cycle...\\n\n",
      "ğŸ“Š Processing Results:\n",
      "   âœ… Queue processed successfully\n"
     ]
    }
   ],
   "source": [
    "# Process one cycle of the queue (this executes approved jobs)\n",
    "print(\"ğŸ”„ Processing queue cycle...\\\\n\")\n",
    "\n",
    "cycle_results = do_api.process_queue_cycle()\n",
    "\n",
    "print(f\"ğŸ“Š Processing Results:\")\n",
    "if cycle_results.get(\"success\"):\n",
    "    print(f\"   âœ… {cycle_results.get('message', 'Queue processed successfully')}\")\n",
    "else:\n",
    "    print(f\"   âŒ Error: {cycle_results.get('error', 'Unknown error')}\")\n",
    "\n",
    "# Wait a moment for processing\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Results and Monitoring ğŸ“Š\n",
    "\n",
    "Check job status and retrieve results from both perspectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Checking job status...\\n\n",
      "ğŸ”¸ Privacy-Safe Statistics\n",
      "   Status: completed\n",
      "   âœ… Completed in 0.0s\n",
      "   ğŸ“Š Results available: ['job', 'output_files', 'logs', 'error', 'output_path']\n",
      "\n",
      "ğŸ”¸ Privacy-Safe Statistics\n",
      "   Status: completed\n",
      "   âœ… Completed in 0.0s\n",
      "   ğŸ“Š Results available: ['job', 'output_files', 'logs', 'error', 'output_path']\n",
      "\n",
      "ğŸ”¸ Privacy-Safe Statistics\n",
      "   Status: pending\n",
      "   â³ Status: pending\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check status of our submitted jobs\n",
    "print(\"ğŸ“‹ Checking job status...\\\\n\")\n",
    "\n",
    "my_jobs = ds_api.list_my_jobs()\n",
    "\n",
    "for job in my_jobs:\n",
    "    # Get updated job info\n",
    "    updated_job = ds_api.get_job(str(job.uid))\n",
    "    if updated_job:\n",
    "        print(f\"ğŸ”¸ {updated_job.name}\")\n",
    "        print(f\"   Status: {updated_job.status.value}\")\n",
    "        \n",
    "        if updated_job.status == JobStatus.completed:\n",
    "            print(f\"   âœ… Completed in {updated_job.duration:.1f}s\" if updated_job.duration else \"   âœ… Completed\")\n",
    "            \n",
    "            # Try to get results\n",
    "            try:\n",
    "                results = ds_api.get_job_results(str(updated_job.uid))\n",
    "                if results:\n",
    "                    print(f\"   ğŸ“Š Results available: {list(results.keys())}\")\n",
    "                    \n",
    "                    # Show some sample results\n",
    "                    if 'stdout' in results:\n",
    "                        stdout = results['stdout'][:200] + \"...\" if len(results['stdout']) > 200 else results['stdout']\n",
    "                        print(f\"   ğŸ“ Output preview:\")\n",
    "                        print(f\"      {stdout}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âš ï¸ Could not retrieve results: {e}\")\n",
    "                \n",
    "        elif updated_job.status == JobStatus.failed:\n",
    "            print(f\"   âŒ Failed: {updated_job.error_message}\")\n",
    "        elif updated_job.status == JobStatus.rejected:\n",
    "            print(f\"   ğŸš« Rejected: {updated_job.error_message}\")\n",
    "        elif updated_job.status == JobStatus.running:\n",
    "            print(f\"   ğŸƒ Currently running...\")\n",
    "        else:\n",
    "            print(f\"   â³ Status: {updated_job.status.value}\")\n",
    "            \n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›ï¸ Data Owner Dashboard\n",
      "========================================\n",
      "\\nğŸ“Š Current Queue Status:\n",
      "   ğŸ‰ Completed: 2\n",
      "\\nğŸ‰ Recently Completed Jobs:\n",
      "   â€¢ Privacy-Safe Statistics - andrew@openmined.org (0.0s)\n",
      "   â€¢ Privacy-Safe Statistics - andrew@openmined.org (0.0s)\n",
      "\\nğŸ”” Attention Needed:\n",
      "   âœ… All jobs processed!\n",
      "\\nğŸ“ˆ Total Jobs Managed: 2\n"
     ]
    }
   ],
   "source": [
    "# Get comprehensive view of all jobs as data owner\n",
    "print(\"ğŸ›ï¸ Data Owner Dashboard\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Current queue status (fixed to use job_counts)\n",
    "stats = do_api.get_queue_stats()\n",
    "print(f\"\\\\nğŸ“Š Current Queue Status:\")\n",
    "for status, count in stats[\"job_counts\"].items():  # Fixed: use job_counts\n",
    "    if count > 0:\n",
    "        status_emoji = {\n",
    "            'pending': 'â³',\n",
    "            'approved': 'âœ…', \n",
    "            'running': 'ğŸƒ',\n",
    "            'completed': 'ğŸ‰',\n",
    "            'failed': 'âŒ',\n",
    "            'rejected': 'ğŸš«'\n",
    "        }\n",
    "        print(f\"   {status_emoji.get(status, 'â€¢')} {status.title()}: {count}\")\n",
    "\n",
    "# Recent completed jobs\n",
    "completed_jobs = do_api.list_completed_jobs(limit=5)\n",
    "if completed_jobs:\n",
    "    print(f\"\\\\nğŸ‰ Recently Completed Jobs:\")\n",
    "    for job in completed_jobs:\n",
    "        duration_str = f\" ({job.duration:.1f}s)\" if job.duration else \"\"\n",
    "        print(f\"   â€¢ {job.name} - {job.requester_email}{duration_str}\")\n",
    "\n",
    "# Check if there are any jobs that need attention\n",
    "pending_count = len(do_api.list_pending_jobs())\n",
    "running_count = len(do_api.list_running_jobs())\n",
    "\n",
    "print(f\"\\\\nğŸ”” Attention Needed:\")\n",
    "if pending_count > 0:\n",
    "    print(f\"   â³ {pending_count} jobs waiting for approval\")\n",
    "if running_count > 0:\n",
    "    print(f\"   ğŸƒ {running_count} jobs currently running\")\n",
    "if pending_count == 0 and running_count == 0:\n",
    "    print(f\"   âœ… All jobs processed!\")\n",
    "\n",
    "print(f\"\\\\nğŸ“ˆ Total Jobs Managed: {stats['total_jobs']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary ğŸ¯\n",
    "\n",
    "This tutorial demonstrated the complete workflow:\n",
    "\n",
    "### âœ… What We Accomplished:\n",
    "\n",
    "**As Data Scientist:**\n",
    "- âœ… Submitted a privacy-safe analysis job\n",
    "- âœ… Used appropriate tags and descriptions\n",
    "- âœ… Monitored job status and retrieved results\n",
    "\n",
    "**As Data Owner:**\n",
    "- âœ… Reviewed submitted jobs\n",
    "- âœ… Applied approval logic based on safety criteria\n",
    "- âœ… Processed the execution queue\n",
    "- âœ… Monitored the overall datasite\n",
    "\n",
    "### ğŸ”’ Security Features in Action:\n",
    "- **Manual Approval**: Every job required explicit approval\n",
    "- **Code Review**: Data owner could inspect the submitted code\n",
    "- **Safe Execution**: Jobs run in sandboxed environment\n",
    "- **Audit Trail**: All actions are logged and trackable\n",
    "\n",
    "### ğŸš€ Key Benefits:\n",
    "- **Simple**: Easy-to-use APIs for both roles\n",
    "- **Secure**: Manual approval prevents unauthorized access\n",
    "- **Flexible**: Supports both simple scripts and complex packages\n",
    "- **Transparent**: Full visibility into job lifecycle\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Set up SyftBox Apps** for automated queue processing\n",
    "2. **Create approval workflows** specific to your organization\n",
    "3. **Integrate with data governance** systems\n",
    "4. **Build automation** for common approval patterns\n",
    "\n",
    "The system is designed to be **simple, secure, and scalable** for real-world federated learning and privacy-preserving analytics!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
