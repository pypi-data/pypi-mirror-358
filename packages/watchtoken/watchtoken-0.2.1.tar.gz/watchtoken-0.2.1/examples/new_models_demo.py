#!/usr/bin/env python3
"""
Przyk≈Çad wykorzystania nowych modeli w WatchToken
Demonstracja najnowszych modeli OpenAI, Anthropic i Google
"""

from watchtoken import TokenCounter

def compare_latest_models():
    """Por√≥wnanie najnowszych modeli pod kƒÖtem koszt√≥w i wydajno≈õci."""
    
    print("üöÄ Por√≥wnanie najnowszych modeli AI")
    print("=" * 60)
    
    test_prompt = """
    Jeste≈õ ekspertem od analizy danych. Przeanalizuj nastƒôpujƒÖce dane sprzeda≈ºowe:
    - Stycze≈Ñ: 120,000 PLN
    - Luty: 135,000 PLN  
    - Marzec: 128,000 PLN
    
    Napisz szczeg√≥≈Çowy raport z wnioskami i rekomendacjami dla zespo≈Çu zarzƒÖdzajƒÖcego.
    """
    
    models_to_compare = [
        # OpenAI - najnowsze
        ("gpt-4o", "OpenAI GPT-4o (multimodal)"),
        ("gpt-4o-mini", "OpenAI GPT-4o Mini (ekonomiczny)"),
        ("gpt-4.1", "OpenAI GPT-4.1 (najnowszy)"),
        
        # Anthropic - najnowsze
        ("claude-sonnet-4", "Claude Sonnet 4"),
        ("claude-3-haiku", "Claude 3 Haiku (szybki)"),
        
        # Google - najnowsze  
        ("gemini-1.5-pro", "Gemini 1.5 Pro (du≈ºy kontekst)"),
        ("gemini-2.5-flash", "Gemini 2.5 Flash (szybki)"),
    ]
    
    results = []
    
    for model_id, model_name in models_to_compare:
        try:
            tc = TokenCounter(model_id)
            
            input_tokens = tc.count(test_prompt)
            estimated_output = 500  # Zak≈Çadamy 500 token√≥w odpowiedzi
            
            cost = tc.estimate_cost(test_prompt, output_tokens=estimated_output)
            info = tc.get_model_info()
            
            results.append({
                'name': model_name,
                'model_id': model_id,
                'input_tokens': input_tokens,
                'total_cost': cost,
                'context_length': info['context_length'],
                'provider': info['provider']
            })
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd dla {model_name}: {e}")
    
    # Sortuj po kosztach
    results.sort(key=lambda x: x['total_cost'])
    
    print(f"\nüìä Wyniki (prompt: {len(test_prompt)} znak√≥w, zak≈Çadane {estimated_output} token√≥w odpowiedzi):")
    print(f"{'Model':<30} {'Provider':<10} {'Tokeny':<7} {'Koszt':<12} {'Kontekst':<10}")
    print("-" * 75)
    
    for result in results:
        print(f"{result['name']:<30} "
              f"{result['provider']:<10} "
              f"{result['input_tokens']:<7} "
              f"${result['total_cost']:<11.6f} "
              f"{result['context_length']:>9,}")

def test_large_context_capabilities():
    """Test mo≈ºliwo≈õci modeli z du≈ºymi kontekstami."""
    
    print("\n\nüéØ Test modeli z du≈ºymi kontekstami")
    print("=" * 60)
    
    large_context_models = [
        ("gpt-4.1", "1M token√≥w"),
        ("gemini-1.5-pro", "1M token√≥w"), 
        ("gemini-1.5-flash", "1M token√≥w"),
        ("claude-sonnet-4", "200K token√≥w"),
    ]
    
    # Stw√≥rz bardzo d≈Çugi prompt
    base_text = "To jest przyk≈Çad bardzo d≈Çugiego tekstu. " * 1000  # ~8000 token√≥w
    
    print(f"üìù Test z d≈Çugim promptem (~{len(base_text)} znak√≥w)")
    print("-" * 50)
    
    for model_id, context_desc in large_context_models:
        try:
            tc = TokenCounter(model_id)
            tokens = tc.count(base_text)
            
            # Sprawd≈∫ ile miejsca zosta≈Ço w kontek≈õcie
            remaining = tc.get_remaining_tokens(base_text)
            context_usage = (tokens / tc.get_model_info()['context_length']) * 100
            
            print(f"‚úÖ {model_id:<20} | "
                  f"U≈ºyte: {tokens:>6,} | "
                  f"Zosta≈Ço: {remaining:>8,} | "
                  f"Wykorzystanie: {context_usage:>5.1f}%")
            
        except Exception as e:
            print(f"‚ùå {model_id:<20} | B≈ÇƒÖd: {e}")

def demo_cost_optimization():
    """Demonstracja optymalizacji koszt√≥w."""
    
    print("\n\nüí∞ Optymalizacja koszt√≥w - wyb√≥r modelu")
    print("=" * 60)
    
    scenarios = [
        ("Kr√≥tkie zapytania (<100 token√≥w)", "Jak dzia≈Ça AI?"),
        ("≈örednie analizy (200-500 token√≥w)", "Przeanalizuj trendy rynkowe w bran≈ºy technologicznej w 2024 roku."),
        ("D≈Çugie zadania (1000+ token√≥w)", "Napisz szczeg√≥≈Çowy biznesplan dla startup'u AI " * 10),
    ]
    
    for scenario_name, prompt in scenarios:
        print(f"\nüìã {scenario_name}")
        print("-" * 40)
        
        # Wybierz reprezentatywne modele dla ka≈ºdej kategorii cenowej
        models = [
            ("gpt-4o-mini", "Ekonomiczny"),
            ("gpt-4o", "≈öredni"),  
            ("claude-3-haiku", "Szybki"),
            ("gemini-2.5-flash", "Flash"),
        ]
        
        costs = []
        for model_id, category in models:
            try:
                tc = TokenCounter(model_id)
                cost = tc.estimate_cost(prompt, output_tokens=200)
                costs.append((model_id, category, cost))
            except:
                continue
        
        # Sortuj po kosztach
        costs.sort(key=lambda x: x[2])
        
        cheapest_cost = costs[0][2] if costs else 0
        
        for model_id, category, cost in costs:
            savings = ((cost - cheapest_cost) / cheapest_cost * 100) if cheapest_cost > 0 else 0
            marker = "ü•á" if cost == cheapest_cost else f"+{savings:.0f}%"
            print(f"   {model_id:<20} ({category:<10}) ${cost:.6f} {marker}")

def main():
    """G≈Ç√≥wna funkcja demonstracyjna."""
    try:
        compare_latest_models()
        test_large_context_capabilities() 
        demo_cost_optimization()
        
        print("\n\n‚úÖ Demo zako≈Ñczone pomy≈õlnie!")
        print("\nüí° Wnioski:")
        print("   ‚Ä¢ GPT-4o-mini to ≈õwietny wyb√≥r ekonomiczny")
        print("   ‚Ä¢ Modele z du≈ºymi kontekstami nadajƒÖ siƒô do z≈Ço≈ºonych zada≈Ñ")
        print("   ‚Ä¢ Claude Haiku to najszybsza opcja")
        print("   ‚Ä¢ Gemini Flash oferuje dobry stosunek ceny do wydajno≈õci")
        
    except Exception as e:
        print(f"\n‚ùå B≈ÇƒÖd: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
