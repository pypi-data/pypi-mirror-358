# WatchToken

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Biblioteka Pythona do Å›ledzenia i kontroli liczby tokenÃ³w w promptach wysyÅ‚anych do rÃ³Å¼nych modeli jÄ™zykowych (LLM), bez koniecznoÅ›ci ich uruchamiania.

## ğŸš€ Funkcje

- **ObsÅ‚uga wielu modeli**: OpenAI GPT-3.5/4/4-turbo, Claude 3, Gemini, Mistral i inne
- **Tokenizacja bez uruchamiania modelu**: Wykorzystuje tiktoken, sentencepiece lub estymacje
- **Elastyczne limity**: Definiowanie limitÃ³w tokenÃ³w per model lub globalnie
- **Inteligentne ostrzeganie**: Powiadomienia o przekroczeniu limitÃ³w
- **Estymacja kosztÃ³w**: Obliczanie szacunkowych kosztÃ³w na podstawie liczby tokenÃ³w
- **Logowanie uÅ¼ycia**: Åšledzenie uÅ¼ycia tokenÃ³w i kosztÃ³w
- **Modularna architektura**: Åatwa rozbudowa o wÅ‚asne tokenizery i modele
- **Typowanie**: PeÅ‚ne wsparcie dla type hints

## ğŸ“¦ Instalacja

```bash
pip install watchtoken
```

Dodatkowe zaleÅ¼noÅ›ci:
```bash
# Dla modeli uÅ¼ywajÄ…cych SentencePiece
pip install watchtoken[sentencepiece]

# Dla modeli Hugging Face
pip install watchtoken[transformers]

# Wszystkie dodatkowe zaleÅ¼noÅ›ci
pip install watchtoken[sentencepiece,transformers]
```

## ğŸ”§ Szybki start

```python
from watchtoken import TokenCounter

# Podstawowe uÅ¼ycie
tc = TokenCounter(model="gpt-4-turbo", limit=8000)

prompt = "Napisz streszczenie 'Pana Tadeusza' w formie opisu filmowego..."

# Sprawdzenie czy prompt przekracza limit
if tc.is_over(prompt):
    print("Zbyt dÅ‚ugi prompt!")
else:
    print(f"ZuÅ¼yto {tc.count(prompt)} tokenÃ³w.")

# Estymacja kosztu (zakÅ‚adajÄ…c 200 tokenÃ³w odpowiedzi)
cost = tc.estimate_cost(prompt, output_tokens=200)
print(f"Szacowany koszt: ${cost:.4f}")
```

## ğŸ“– SzczegÃ³Å‚owe przykÅ‚ady

### RÃ³Å¼ne modele

```python
from watchtoken import TokenCounter

# OpenAI modele - najnowsze
gpt4o_counter = TokenCounter("gpt-4o", limit=128000)  # Multimodal
gpt4o_mini_counter = TokenCounter("gpt-4o-mini", limit=128000)  # Ekonomiczny
gpt41_counter = TokenCounter("gpt-4.1", limit=1000000)  # Najnowszy z duÅ¼ym kontekstem

# Claude modele - najnowsze
claude_sonnet4_counter = TokenCounter("claude-sonnet-4", limit=200000)
claude_haiku_counter = TokenCounter("claude-3-haiku", limit=200000)  # Najszybszy

# Gemini modele
gemini25_pro_counter = TokenCounter("gemini-2.5-pro", limit=1048576)  # Najnowszy Pro
gemini25_flash_counter = TokenCounter("gemini-2.5-flash", limit=1048576)  # Szybki 2.5
gemini25_lite_counter = TokenCounter("gemini-2.5-flash-lite", limit=1000000)  # Ultra-ekonomiczny
```

### Callbacki i obsÅ‚uga przekroczeÅ„

```python
from watchtoken import TokenCounter

def on_limit_exceeded(tokens: int, limit: int, model: str) -> None:
    print(f"âš ï¸ Przekroczono limit! {tokens}/{limit} tokenÃ³w dla {model}")

tc = TokenCounter(
    model="gpt-4-turbo",
    limit=1000,
    on_limit_exceeded=on_limit_exceeded
)

# Automatyczne wywoÅ‚anie callbacka przy przekroczeniu
tc.check_limit("Very long prompt...")
```

### Estymacja kosztÃ³w z rÃ³Å¼nymi parametrami

```python
from watchtoken import TokenCounter

tc = TokenCounter("gpt-4-turbo")

prompt = "Analyze this data..."

# Podstawowa estymacja
cost = tc.estimate_cost(prompt, output_tokens=500)

# Z uwzglÄ™dnieniem dodatkowych parametrÃ³w
cost_detailed = tc.estimate_cost(
    prompt,
    output_tokens=500,
    input_multiplier=1.0,  # Standardowa cena za input
    output_multiplier=2.0  # 2x cena za output (typowe dla GPT-4)
)
```

### Logowanie uÅ¼ycia

```python
from watchtoken import TokenCounter, FileLogger

# Logowanie do pliku
logger = FileLogger("token_usage.log")
tc = TokenCounter("gpt-4-turbo", logger=logger)

# KaÅ¼de uÅ¼ycie zostanie zalogowane
tokens = tc.count("Hello world!")
cost = tc.estimate_cost("Hello world!", output_tokens=10)
```

## ğŸ—ï¸ Architektura

### ObsÅ‚ugiwane modele

| Provider | Model | Tokenizer | Status |
|----------|-------|-----------|--------|
| OpenAI | gpt-3.5-turbo, gpt-4, gpt-4-turbo, gpt-4o, gpt-4o-mini, gpt-4.1* | tiktoken | âœ… |
| Anthropic | claude-3-haiku, claude-3-sonnet, claude-3-opus, claude-sonnet-4* | Estymacja | âœ… |
| Google | gemini-2.5-pro, gemini-2.5-flash, gemini-2.5-flash-lite, gemini-1.5-pro | Estymacja | âœ… |
| Mistral | mistral-7b, mixtral-8x7b | SentencePiece | âœ… |
| Custom | WÅ‚asne modele | Pluginy | âœ… |

*Najnowsze modele z szacowanymi cenami

### WÅ‚asne adaptery

```python
from watchtoken.adapters import BaseAdapter
from watchtoken import TokenCounter

class CustomAdapter(BaseAdapter):
    def count_tokens(self, text: str) -> int:
        # Twoja implementacja tokenizacji
        return len(text.split())
    
    def get_cost_per_token(self) -> tuple[float, float]:
        # (input_cost, output_cost) per token
        return (0.00001, 0.00002)

# Rejestracja wÅ‚asnego adaptera
TokenCounter.register_adapter("my-model", CustomAdapter)

# UÅ¼ycie
tc = TokenCounter("my-model")
```

## ğŸ§ª RozwÃ³j

```bash
# Klonowanie repozytorium
git clone https://github.com/yourusername/watchtoken.git
cd watchtoken

# Instalacja w trybie deweloperskim
pip install -e .[dev]

# Uruchomienie testÃ³w
pytest

# Formatowanie kodu
black watchtoken tests
isort watchtoken tests

# Sprawdzenie typÃ³w
mypy watchtoken
```

## ğŸ“‹ Roadmapa

- [x] **v0.2.0**: âœ… Wsparcie dla najnowszych modeli (GPT-4o, Claude Sonnet 4, Gemini 2.5)
- [ ] **v0.3.0**: CLI interface
- [ ] **v0.4.0**: Asynchroniczne API
- [ ] **v0.5.0**: Integracje z popularnymi frameworkami (LangChain, LlamaIndex)
- [ ] **v0.6.0**: Wsparcie dla wiÄ™cej modeli (LLaMA, xAI Grok)
- [ ] **v1.0.0**: Stabilne API, peÅ‚na dokumentacja

## ğŸ¤ WspÃ³Å‚praca

ZachÄ™camy do wspÃ³Å‚pracy! Zobacz [CONTRIBUTING.md](CONTRIBUTING.md) dla szczegÃ³Å‚Ã³w.

## ğŸ“„ Licencja

MIT License - zobacz [LICENSE](LICENSE) dla szczegÃ³Å‚Ã³w.

## ğŸ™ PodziÄ™kowania

- [tiktoken](https://github.com/openai/tiktoken) - tokenizacja OpenAI
- [sentencepiece](https://github.com/google/sentencepiece) - tokenizacja Google
- SpoÅ‚ecznoÅ›Ä‡ open-source za inspiracjÄ™

---

**WatchToken** - Kontroluj swoje tokeny, zanim one kontrolujÄ… TwÃ³j budÅ¼et! ğŸ’°
