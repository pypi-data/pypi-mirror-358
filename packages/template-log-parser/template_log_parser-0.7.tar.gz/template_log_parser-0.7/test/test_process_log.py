import unittest

import pandas as pd
from parse import parse

from template_log_parser.log_functions import (
    process_log,
    event_type_column,
    event_data_column,
)
from template_log_parser.log_type_classes import built_in_log_file_types

# Eight possible combinations between column functions, merge events, and drop columns for each type
config_combinations = {
    built_in: {
        "column functions; merge events; drop columns": [
            built_in.column_functions,
            built_in.merge_events,
            True,
        ],
        "column functions; no merge events; drop columns": [
            built_in.column_functions,
            None,
            True,
        ],
        "column functions; merge events; no drop columns": [
            built_in.column_functions,
            built_in.merge_events,
            False,
        ],
        "column functions; no merge events; no drop columns": [
            built_in.column_functions,
            None,
            False,
        ],
        "no column functions; merge events; no drop columns": [
            None,
            built_in.merge_events,
            False,
        ],
        "no column functions; merge events; drop columns": [
            None,
            built_in.merge_events,
            True,
        ],
        "no column functions; no merge events; drop columns": [
            None,
            None,
            True,
        ],
        "no column functions; no merge events; no drop columns": [
            None,
            None,
            False,
        ],
    }
    for built_in in built_in_log_file_types
}


class TestProcessLog(unittest.TestCase):
    """Defines a class to test the process_log function"""

    def test_dict_format_true(self):
        """Test function to determine that instances where dict_format=True contain the correct keys (event_types) and accounts for all log file lines"""

        print("\nChecking process_log() where dict_format=True")

        for built_in, configurations in config_combinations.items():
            print("\n")
            print("--------------------")
            print(built_in.name)
            print("--------------------")

            with open(built_in.sample_log_file, "r") as raw_log:
                lines_in_log_file = len(raw_log.readlines())
                print(f"Total Lines in log file: {lines_in_log_file}")

            for configuration, (col_funcs, merges, drop_cols) in configurations.items():
                print(f"\n##### Configuration: {configuration} #####")
                output = process_log(
                    file=built_in.sample_log_file,
                    template_dictionary=built_in.templates,
                    additional_column_functions=col_funcs,
                    merge_dictionary=merges,
                    drop_columns=drop_cols,
                    dict_format=True,
                )

                expected_keys = sorted(
                    list(set([value[-1] for value in built_in.templates.values()]))
                )
                print(
                    f"Base keys in template dictionary ({len(expected_keys)}): {expected_keys}"
                )

                # KEYS
                if merges:  # Merge events
                    new_merge_events = [key for key in merges]
                    print(
                        f"New keys generated by merge_events ({len(new_merge_events)}): {new_merge_events}"
                    )
                    keys_to_delete = []
                    # The values of the merge_event dict is a list of event_types that were merged (and deleted)
                    for deleted_column_list in merges.values():
                        keys_to_delete.extend(deleted_column_list)
                    print(
                        f"Keys to be dropped ({len(keys_to_delete)}): {keys_to_delete}"
                    )
                    expected_keys = [
                        column
                        for column in expected_keys
                        if column not in keys_to_delete
                    ]
                    expected_keys.extend(new_merge_events)

                expected_keys = sorted(list(set(expected_keys)))
                print(f"Expected keys {len(expected_keys)}: ", expected_keys)

                actual_keys = sorted(list(output.keys()))
                print(f"Actual keys {len(actual_keys)}: ", actual_keys)

                self.assertEqual(expected_keys, actual_keys)
                print("---MATCHING KEYS OK---")

                # COLUMNS PER MINI DF
                # Running parse on individual templates against template dictionary in a comprehension
                # to return {'event_type': [column1, column2,...], ...}
                # Every event_type now has a list of columns associated with it, adding 'event_type' at the end of list
                expected_columns_by_template = {
                    value[-1]: list(parse(value[0], value[0]).named.keys())
                    + [event_type_column]
                    for value in built_in.templates.values()
                }

                expected_columns_by_event_type = {}

                print("\nGenerating expected columns by event type")
                for event_type in expected_keys:
                    print("")
                    print(f"Event type: {event_type}")
                    expected_columns = []
                    columns_to_add = []
                    columns_to_drop = []
                    standard_drop_columns = [event_data_column]

                    if merges is None:
                        print("No merge Events")
                        expected_columns = expected_columns_by_template[event_type]

                    elif merges:
                        if event_type in merges.keys():
                            merged_events = sorted(list(set(merges[event_type])))
                            print(
                                f"Events to be merged ({len(merged_events)}): {merged_events}"
                            )

                            for event in merged_events:
                                individual_event_columns = sorted(
                                    expected_columns_by_template[event]
                                )
                                print(
                                    f'Columns associated with "{event}":',
                                    individual_event_columns,
                                )
                                expected_columns.extend(individual_event_columns)
                        else:
                            expected_columns = expected_columns_by_template[event_type]
                            print("Not listed in merge events")

                    print(
                        f"Initial expected columns ({len(expected_columns)}): {expected_columns}"
                    )

                    if col_funcs:
                        print("Checking column functions")
                        drops = sorted(list(col_funcs.keys()))
                        columns_to_drop.extend(drops)
                        print(f"Adding ({len(drops)}) {drops} to columns_to_drop")
                        for original_column, function_attributes in col_funcs.items():
                            if original_column in expected_columns:
                                to_add = function_attributes[1]
                                if type(to_add) is str:
                                    columns_to_add.append(to_add)
                                    print(f'Adding "{to_add}" to columns_to_add')
                                elif type(to_add) is list:
                                    columns_to_add.extend(to_add)
                                    print(
                                        f"Adding ({len(to_add)}) {to_add} to columns_to_add"
                                    )

                    elif col_funcs is None:
                        print("No columns functions for this event type")

                    expected_columns.extend(columns_to_add)
                    print("Adding columns:", columns_to_add)

                    if drop_cols is True:
                        expected_columns = [
                            column
                            for column in expected_columns
                            if column not in columns_to_drop
                        ]
                        print("Dropping columns:", columns_to_drop)
                        expected_columns = [
                            column
                            for column in expected_columns
                            if column not in standard_drop_columns
                        ]
                        print("Dropping columns:", standard_drop_columns)

                    elif drop_cols is False:
                        expected_columns.extend(standard_drop_columns)
                        print(
                            "Drop columns is False. Adding standard drop columns:",
                            standard_drop_columns,
                        )

                    expected_columns = sorted(list(set(expected_columns)))
                    expected_columns_by_event_type[event_type] = expected_columns

                    print(
                        f"Final expected columns ({len(expected_columns)}): {expected_columns}"
                    )

                total_log_lines_accounted_for = 0

                for event_type, df in output.items():
                    print("")
                    print("Event type: ", event_type)
                    self.assertIsInstance(event_type, str)
                    self.assertIsInstance(df, pd.DataFrame)
                    total_log_lines_accounted_for += df.shape[0]
                    actual_columns = sorted(df.columns.tolist())
                    print(f"Actual columns {len(actual_columns)}: ", actual_columns)
                    expected_columns = expected_columns_by_event_type[event_type]
                    print(
                        f"Expected columns {len(expected_columns)}: ", expected_columns
                    )
                    self.assertEqual(expected_columns, actual_columns)
                    print("---ALL EXPECTED COLUMNS ARE PRESENT---")

                print("")
                print(
                    f"Expecting {lines_in_log_file} lines, found {total_log_lines_accounted_for}"
                )
                self.assertEqual(lines_in_log_file, total_log_lines_accounted_for)
                print("---ALL LINES IN LOG FILE ARE ACCOUNTED FOR---")

    def test_dict_format_false(self):
        """Test function to determine that instances where dict_format=False contain the correct columns in the main df"""

        print("\nChecking process_log() where dict_format=False")

        for built_in, configurations in config_combinations.items():
            print("\n")
            print("--------------------")
            print(built_in.name)
            print("--------------------")

            with open(built_in.sample_log_file, "r") as raw_log:
                lines_in_log_file = len(raw_log.readlines())
                print(f"Total Lines in log file: {lines_in_log_file}")

            for configuration, (col_funcs, merges, drop_cols) in configurations.items():
                print(f"\n##### Configuration: {configuration} #####")
                output = process_log(
                    file=built_in.sample_log_file,
                    template_dictionary=built_in.templates,
                    additional_column_functions=col_funcs,
                    merge_dictionary=merges,
                    drop_columns=drop_cols,
                    dict_format=False,
                )

                columns_accounted_for_by_templates = [
                    list(parse(value[0], value[0]).named.keys())
                    for value in built_in.templates.values()
                ]

                # Remove duplicates, unpack lists, this is a list of all possible columns
                columns_accounted_for_by_templates = list(
                    set(
                        [
                            column
                            for column_list in columns_accounted_for_by_templates
                            for column in column_list
                        ]
                        + [event_type_column]
                    )
                )

                standard_drop_columns = [event_data_column]
                columns_to_add = []
                columns_to_delete = []

                # New column or columns created by functions, add/extend accordingly
                # Second item in the function_info list will be either a string or list for new column(s)
                if col_funcs:
                    for old_column, function_info in col_funcs.items():
                        columns_to_delete.append(old_column)
                        if type(function_info[1]) is str:
                            columns_to_add.append(function_info[1])
                        if type(function_info[1]) is list:
                            columns_to_add.extend(function_info[1])

                if drop_cols is True:
                    columns_to_delete = columns_to_delete + standard_drop_columns

                elif drop_cols is False:
                    columns_to_add.extend(standard_drop_columns)
                    # If drop columns is False, re-define columns to delete as en empty list
                    columns_to_delete = []

                columns_accounted_for_by_templates.extend(columns_to_add)

                # Remove duplicates once again just to be safe and sort
                expected_columns = sorted(
                    list(
                        set(
                            [
                                column
                                for column in columns_accounted_for_by_templates
                                if column not in columns_to_delete
                            ]
                        )
                    )
                )

                actual_columns = sorted(output.columns.tolist())
                print(f"Actual columns {len(actual_columns)}: ", actual_columns)

                print(f"Expected columns {len(expected_columns)}: ", expected_columns)
                self.assertEqual(expected_columns, actual_columns)
                print("---ALL EXPECTED COLUMNS ARE PRESENT---")

                total_log_lines_accounted_for = output.shape[0]

                print("")
                print(
                    f"Expecting {lines_in_log_file} lines, found {total_log_lines_accounted_for}"
                )
                self.assertEqual(lines_in_log_file, total_log_lines_accounted_for)
                print("---ALL LINES IN LOG FILE ARE ACCOUNTED FOR---")
