# Medallion ETL

Una librerÃ­a modular para construir data pipelines con arquitectura medallion (Bronze-Silver-Gold).

## ğŸš€ CaracterÃ­sticas

- **Arquitectura Medallion**: ImplementaciÃ³n completa del patrÃ³n Bronze-Silver-Gold
- **CLI Integrado**: Comandos para inicializar proyectos y crear pipelines
- **Modular y Extensible**: Componentes reutilizables para cada capa del proceso
- **ValidaciÃ³n de Datos**: Esquemas con Pydantic para garantizar calidad de datos
- **Procesamiento Eficiente**: Powered by Polars para manejo de grandes volÃºmenes
- **OrquestaciÃ³n**: IntegraciÃ³n nativa con Prefect para workflows complejos
- **Conectores**: Soporte para mÃºltiples fuentes de datos (CSV, JSON, SQL, APIs)
- **Logging Avanzado**: Sistema de logging estructurado con Rich

## ğŸ“‹ Requisitos

- Python 3.11+
- polars >= 1.30
- pydantic >= 2.7
- sqlalchemy >= 2.0
- prefect >= 3.0
- requests >= 2.25.0
- rich >= 14.0.0

## ğŸ“¦ InstalaciÃ³n

```bash
pip install medallion-etl
```

O desde el cÃ³digo fuente:

```bash
git clone https://github.com/JuanManiglia/medallion-etl.git
cd medallion-etl
pip install -e .
```

## ğŸ› ï¸ Comandos CLI

### Inicializar un nuevo proyecto

```bash
medallion-etl init
```

O especificar un directorio:

```bash
medallion-etl init --project-dir mi_proyecto
```

Esto crearÃ¡ la siguiente estructura:

```
mi_proyecto/
â”œâ”€â”€ config.py              # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ main.py                 # Script principal
â”œâ”€â”€ README.md              # DocumentaciÃ³n del proyecto
â”œâ”€â”€ data/                  # Directorio para datos
â”‚   â”œâ”€â”€ bronze/           # Datos crudos (raw)
â”‚   â”œâ”€â”€ silver/           # Datos validados y limpios
â”‚   â””â”€â”€ gold/             # Datos transformados y agregados
â”œâ”€â”€ logs/                  # Logs del proyecto
â”œâ”€â”€ pipelines/             # Definiciones de pipelines
â””â”€â”€ schemas/               # Esquemas de datos (Pydantic)
```

### Crear un nuevo pipeline

```bash
medallion-etl create-pipeline MiPipeline
```

Esto generarÃ¡:
- `pipelines/mipipeline_pipeline.py` - DefiniciÃ³n del pipeline
- `schemas/mipipeline_schema.py` - Esquema de datos con Pydantic

## ğŸ—ï¸ Arquitectura Medallion

### ğŸ¥‰ Bronze Layer (Datos Crudos)
- **PropÃ³sito**: Ingesta de datos en su formato original
- **Extractores disponibles**:
  - `CSVExtractor` - Archivos CSV
  - `JSONExtractor` - Archivos JSON
  - `SQLExtractor` - Bases de datos SQL
  - `APIExtractor` - APIs REST

### ğŸ¥ˆ Silver Layer (Datos Validados)
- **PropÃ³sito**: ValidaciÃ³n, limpieza y normalizaciÃ³n
- **Componentes**:
  - `SchemaValidator` - ValidaciÃ³n con esquemas Pydantic
  - `DataCleaner` - Limpieza de datos (duplicados, nulos)
  - `DataNormalizer` - NormalizaciÃ³n de formatos

### ğŸ¥‡ Gold Layer (Datos Transformados)
- **PropÃ³sito**: Agregaciones y transformaciones para anÃ¡lisis
- **Transformadores**:
  - `Aggregator` - Agregaciones (sum, mean, count, etc.)
  - `DataJoiner` - UniÃ³n de datasets
  - `FeatureEngineer` - CreaciÃ³n de nuevas caracterÃ­sticas

## ğŸ”§ Uso BÃ¡sico

### 1. Crear un proyecto

```bash
medallion-etl init --project-dir mi_etl_project
cd mi_etl_project
```

### 2. Crear un pipeline personalizado

```bash
medallion-etl create-pipeline Ventas
```

### 3. Configurar el esquema de datos

Edita `schemas/ventas_schema.py`:

```python
from datetime import datetime
from typing import Optional
from medallion_etl.schemas import BaseSchema

class VentasSchema(BaseSchema):
    id: int
    producto: str
    cantidad: int
    precio: float
    fecha: datetime
    cliente: Optional[str] = None
```

### 4. Personalizar el pipeline

Edita `pipelines/ventas_pipeline.py` segÃºn tus necesidades.

### 5. Ejecutar el pipeline

```bash
python main.py --pipeline ventas --input data/ventas.csv
```

## ğŸ“Š Ejemplo de Pipeline Completo

```python
from medallion_etl.core import Pipeline
from medallion_etl.bronze import CSVExtractor
from medallion_etl.silver import SchemaValidator, DataCleaner
from medallion_etl.gold import Aggregator
from schemas.ventas_schema import VentasSchema

def create_sales_pipeline():
    pipeline = Pipeline(name="SalesPipeline")
    
    # Bronze: Extraer datos
    extractor = CSVExtractor(
        name="SalesExtractor",
        output_path=config.bronze_dir / "sales"
    )
    pipeline.add_task(extractor)
    
    # Silver: Validar y limpiar
    validator = SchemaValidator(
        schema_model=VentasSchema,
        name="SalesValidator"
    )
    pipeline.add_task(validator)
    
    cleaner = DataCleaner(
        name="SalesCleaner",
        drop_na=True,
        drop_duplicates=True
    )
    pipeline.add_task(cleaner)
    
    # Gold: Agregar datos
    aggregator = Aggregator(
        group_by=["producto"],
        aggregations={
            "cantidad": "sum",
            "precio": "mean"
        },
        name="SalesAggregator"
    )
    pipeline.add_task(aggregator)
    
    return pipeline

# Ejecutar pipeline
pipeline = create_sales_pipeline()
result = pipeline.run("data/ventas.csv")
```

## ğŸ”Œ Conectores Disponibles

### Extractores (Bronze)
- **CSVExtractor**: Archivos CSV con configuraciÃ³n flexible
- **JSONExtractor**: Archivos JSON y JSONL
- **SQLExtractor**: Bases de datos relacionales
- **APIExtractor**: APIs REST con autenticaciÃ³n
- **FileExtractor**: Extractor base para otros formatos

### Validadores (Silver)
- **SchemaValidator**: ValidaciÃ³n con esquemas Pydantic
- **DataCleaner**: Limpieza automÃ¡tica de datos
- **DataNormalizer**: NormalizaciÃ³n de tipos y formatos

### Transformadores (Gold)
- **Aggregator**: Agregaciones grupales
- **DataJoiner**: UniÃ³n de mÃºltiples datasets
- **FeatureEngineer**: CreaciÃ³n de caracterÃ­sticas derivadas

## ğŸ”§ ConfiguraciÃ³n

La configuraciÃ³n se maneja a travÃ©s de la clase `MedallionConfig`:

```python
from medallion_etl.config import MedallionConfig

config = MedallionConfig(
    bronze_dir="data/bronze",
    silver_dir="data/silver", 
    gold_dir="data/gold",
    log_dir="logs",
    log_level="INFO"
)
```

## ğŸš€ IntegraciÃ³n con Prefect

Convierte cualquier pipeline en un flow de Prefect:

```python
from prefect import serve

pipeline = create_sales_pipeline()
flow = pipeline.as_prefect_flow(name="sales-etl")

# Desplegar como servicio
serve(flow)
```

## ğŸ“ Logging

Sistema de logging estructurado con Rich:

```python
from medallion_etl.utils import logger

logger.info("Pipeline iniciado", extra={"pipeline": "sales"})
logger.error("Error en validaciÃ³n", extra={"records_failed": 10})
```

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ”— Enlaces

- **Repositorio**: [https://github.com/JuanManiglia/medallion-etl](https://github.com/JuanManiglia/medallion-etl)
- **DocumentaciÃ³n**: [En desarrollo]
- **Issues**: [https://github.com/JuanManiglia/medallion-etl/issues](https://github.com/JuanManiglia/medallion-etl/issues)

---

**Medallion ETL** - Construye pipelines de datos robustos y escalables con arquitectura medallion ğŸ…